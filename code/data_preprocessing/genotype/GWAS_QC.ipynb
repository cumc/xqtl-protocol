{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitting-blank",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Genotype PLINK File Quality Control\n",
    "\n",
    "This workflow implements some preliminary data QC steps for PLINK input files. VCF format of inputs will be converted to PLINK before performing QC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-approach",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acc1a9",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook includes workflow for\n",
    "\n",
    "- Compute kinship matrix in sample and estimate related individuals\n",
    "- Genotype and sample QC: by MAF, missing data and HWE\n",
    "- LD pruning for follow up PCA analysis on genotype, as needed\n",
    "\n",
    "A potential limitation is that the workflow requires all samples and chromosomes to be merged as one single file, in order to perform both sample and variant level QC. However, in our experience using this pipeline with 200K exomes with 15 million variants, this pipeline works on the single merged PLINK file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2277af",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods\n",
    "\n",
    "Depending on the context of your problem, the workflow can be executed in two ways:\n",
    "\n",
    "1. Run `qc` command to perform genotype data QC and LD pruning to generate a subset of variants in preparation for analysis such as PCA.\n",
    "2. Run `king` first on either the original or a subset of common variants to identify unrelated individuals. The `king` pipeline will split samples to related and unrelated individuals. Then you perform `qc` on these individuals only and finally extract the same set of QC-ed variants for related individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-testament",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Default Parameters: QC\n",
    "\n",
    "- Kinship coefficient for related individuals: 0.0625\n",
    "- MAF and MAC default: 0\n",
    "    - Above default includes both common and are variant\n",
    "    - Recommand MAF for PCA: 0.01, [we should stick to common variants](https://bmcgenomdata.biomedcentral.com/articles/10.1186/s12863-020-0833-x)\n",
    "    - Recommand MAC for single variant analysis: 5.\n",
    "- Variant level missingness threshold: 0.1\n",
    "- Sample level missingness threshold: 0.1\n",
    "- LD pruning via PLINK for PCA analysis:\n",
    "    - window 50 \n",
    "    - shift 10 \n",
    "    - r2 0.1\n",
    "- HWE default: 1E-15 which is very lenient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8349731",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "The whole genome PLINK bim/bed/fam bundle. For input in VCF format and/or per-chromosome VCF or PLINK format, please use `vcf_to_plink` and `merge_plink` in [genotype formatting](https://cumc.github.io/xqtl-protocol/code/data_preprocessing/genotype/genotype_formatting.html) pipeline to convert them to PLINK file bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-caution",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "Minimal working example data-set as well as the singularity container `bioinfo.sif` can be downloaded from [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/).\n",
    "\n",
    "The `chr1_chr6` data-set was merged from `chr1` and `chr6` data, using `merge_plink` command from [genotype formatting](https://cumc.github.io/xqtl-protocol/code/data_preprocessing/genotype/genotype_formatting.html) pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7ebf0",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Perform QC on both rare and common variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-saver",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run xqtl-protocol/pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "   --cwd Genotype \\\n",
    "   --genoFile Genotype/ROSMAP_NIA_WGS.leftnorm.bcftools_qc.bed \\\n",
    "   --geno-filter 0.1 \\\n",
    "   --mind-filter 0.1 \\\n",
    "   --hwe-filter 1e-08   \\\n",
    "   --mac-filter 0 \\\n",
    "   --container /mnt/vast/hpc/csg/containers/bioinfo.sif \\\n",
    "   -J 1 -q csg -c csg.yml --mem 150G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfbacd",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Sample match with genotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223604d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e8520",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb genotype_phenotype_sample_overlap \\\n",
    "        --cwd output/sample_meta \\\n",
    "        --genoFile input/protocol_example.genotype.chr21_22.fam  \\\n",
    "        --phenoFile input/protocol_example.protein.csv \\\n",
    "        --container containers/bioinfo.sif \\\n",
    "        --mem 5G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002e5df",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running genotype_phenotype_sample_overlap: This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "INFO: genotype_phenotype_sample_overlap is completed.\n",
    "INFO: genotype_phenotype_sample_overlap output:   /Users/alexmccreight/xqtl-protocol/output/sample_meta/protocol_example.protein.sample_overlap.txt /Users/alexmccreight/xqtl-protocol/output/sample_meta/protocol_example.protein.sample_genotypes.txt\n",
    "INFO: Workflow genotype_phenotype_sample_overlap (ID=w71b4e35979654867) is executed successfully with 1 completed step.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-tracy",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Kinship QC\n",
    "\n",
    "To accuratly estimate the PCs for the genotype. We split participants based on their kinship coefficients, estimated by KING.\n",
    "\n",
    "1. Variant level and sample level QC on unrelated individuals using missingness > 10%, and LD-prunning in preparation for PCA analysis.    \n",
    "2. There is no related samples in these ROSMAP samples, so there is an additional step to only keep those samples in `rosmap_pheno.sample_genotypes.txt` to do PCA.\n",
    "\n",
    "**Be aware:**    \n",
    "\n",
    "**If the message from `king_2` shown as `No related individuals detected from *.kin0`, this means no related individuals detected for the samples in `--keep_samples`. In this case, there will be no output for related individuals from this step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88289e87",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-documentary",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd output/kinship \\\n",
    "    --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "    --name pQTL \\\n",
    "    --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "    --container containers/bioinfo.sif \\\n",
    "    --no-maximize-unrelated \\\n",
    "    --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6cebc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running king_1: Inference of relationships in the sample to identify closely related individuals\n",
    "INFO: king_1 is completed.\n",
    "INFO: king_1 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.kin0\n",
    "INFO: Running king_2: Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data\n",
    "INFO: king_2 is completed.\n",
    "INFO: king_2 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.related_id\n",
    "INFO: Running king_3: Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "INFO: king_3 is completed.\n",
    "INFO: king_3 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.related.bed\n",
    "INFO: Workflow king (ID=w7fad1d8b027ec781) is executed successfully with 3 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c47aaa",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Prepare unrelated individuals data for PCA\n",
    "\n",
    "Here we write data to `cache` folder instead of `output` because this genotype data can be removed later after PCA. Also filter out minor allel accout < 5.\n",
    "\n",
    "**If your data has `*.unrelated.bed` generated, that means there are related individuals in your data. In cases, we will use output from the KING step for unrelated individuals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44866f9d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a3d37",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed \\\n",
    "   --mac-filter 5 \\\n",
    "   --container containers/bioinfo.sif \\\n",
    "   --mem 16G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b16679",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.bed /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=w3a34828bd2888342) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-stamp",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "**In other cases eg ROSMAP proteomics data, message `No related individuals detected from *.kin0` occured, there is no separate genotype data generated for unrelated individuals. In this case, we need to work from the original genotype data and must use `--keep-samples` to run `qc` to extract samples for PCA.** For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402b86a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-vacuum",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "   --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "   --name pQTL \\\n",
    "   --mac-filter 5 \\\n",
    "   --container containers/bioinfo.sif \\\n",
    "   --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce69aa2",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.bed /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=w3d8b01776519226f) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-receptor",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "[FIXME:] Extract previously selected variants from related individuals in preparation for PCA, only applying missingness filter at sample level,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-stable",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run GWAS_QC.ipynb qc_no_prune \\\n",
    "    --cwd output/genotype \\\n",
    "    --genoFile output/genotype/chr1_chr6.20220110.related.bed \\\n",
    "    --keep-variants output/genotype/chr1_chr6.20220110.unrelated.for_pca.filtered.prune.in \\\n",
    "    --maf-filter 0 --geno-filter 0 --mind-filter 0.1 \\\n",
    "    --name for_pca \\\n",
    "    --container container/bioinfo.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-louisiana",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prepared-national",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run GWAS_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  king\n",
      "  qc_no_prune\n",
      "  qc\n",
      "  genotype_phenotype_sample_overlap\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        the output directory for generated files\n",
      "  --name ''\n",
      "                        A string to identify your analysis run\n",
      "  --genoFile  paths\n",
      "\n",
      "                        PLINK binary files\n",
      "  --remove-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to remove (format FID, IID)\n",
      "  --keep-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "  --keep-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to keep\n",
      "  --exclude-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to exclude\n",
      "  --kinship 0.0625 (as float)\n",
      "                        Kinship coefficient threshold for related individuals\n",
      "                        (e.g first degree above 0.25, second degree above 0.125,\n",
      "                        third degree above 0.0625)\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "  --entrypoint ('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else \"\"\n",
      "\n",
      "\n",
      "Sections\n",
      "  king_1:               Inference of relationships in the sample to identify\n",
      "                        closely related individuals\n",
      "    Workflow Options:\n",
      "      --kin-maf 0.01 (as float)\n",
      "                        PLINK binary file\n",
      "  king_2:               Select a list of unrelated individual with an attempt to\n",
      "                        maximize the unrelated individuals selected from the\n",
      "                        data\n",
      "    Workflow Options:\n",
      "      --[no-]maximize-unrelated (default to False)\n",
      "                        If set to true, the unrelated individuals in a family\n",
      "                        will be kept without being reported. Otherwise (use\n",
      "                        `--no-maximize-unrelated`) the entire family will be\n",
      "                        removed Note that attempting to maximize unrelated\n",
      "                        individuals is computationally intensive on large data.\n",
      "  king_3:               Split genotype data into related and unrelated samples,\n",
      "                        if related individuals are detected\n",
      "  qc_no_prune, qc_1:    Filter SNPs and select individuals\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.0 (as float)\n",
      "                        minimum MAF filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --maf-max-filter 0.0 (as float)\n",
      "                        maximum MAF filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --mac-filter 0.0 (as float)\n",
      "                        minimum MAC filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --mac-max-filter 0.0 (as float)\n",
      "                        maximum MAC filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --geno-filter 0.1 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.1 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 1e-15 (as float)\n",
      "                        HWE filter -- a very lenient one\n",
      "      --other-args  (as list)\n",
      "                        Other PLINK arguments e.g snps_only, write-samples, etc\n",
      "      --[no-]meta-only (default to False)\n",
      "                        Only output SNP and sample list, rather than the PLINK\n",
      "                        binary format of subset data\n",
      "      --[no-]rm-dups (default to False)\n",
      "                        Remove duplicate variants\n",
      "  qc_2:                 LD prunning and remove related individuals (both ind of\n",
      "                        a pair) Plink2 has multi-threaded calculation for LD\n",
      "                        prunning\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "                        Window size\n",
      "      --shift 10 (as int)\n",
      "                        Shift window every 10 snps\n",
      "      --r2 0.1 (as float)\n",
      "  genotype_phenotype_sample_overlap: This workflow extracts overlapping samples\n",
      "                        for genotype data with phenotype data, and output the\n",
      "                        filtered sample genotype list as well as sample\n",
      "                        phenotype list\n",
      "    Workflow Options:\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        A phenotype file, can be bed.gz or tsv\n",
      "      --sample-participant-lookup . (as path)\n",
      "                        If this file is provided, a genotype/phenotype sample\n",
      "                        name match will be performed It must contain two column\n",
      "                        names: genotype_id, sample_id\n"
     ]
    }
   ],
   "source": [
    "sos run GWAS_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-syntax",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path(\"output\")\n",
    "# A string to identify your analysis run\n",
    "parameter: name = \"\"\n",
    "# PLINK binary files\n",
    "parameter: genoFile = paths\n",
    "# The path to the file that contains the list of samples to remove (format FID, IID)\n",
    "parameter: remove_samples = path('.')\n",
    "# The path to the file that contains the list of samples to keep (format FID, IID)\n",
    "parameter: keep_samples = path('.')\n",
    "# The path to the file that contains the list of variants to keep\n",
    "parameter: keep_variants = path('.')\n",
    "# The path to the file that contains the list of variants to exclude\n",
    "parameter: exclude_variants = path('.')\n",
    "# Kinship coefficient threshold for related individuals\n",
    "# (e.g first degree above 0.25, second degree above 0.125, third degree above 0.0625)\n",
    "parameter: kinship = 0.0625\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-planner",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Estimate kinship in the sample\n",
    "\n",
    "The output is a list of related individuals, as well as the kinship matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-attitude",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Inference of relationships in the sample to identify closely related individuals\n",
    "[king_1]\n",
    "# PLINK binary file\n",
    "parameter: kin_maf = 0.01\n",
    "input: genoFile\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.kin0'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      --make-king-table \\\n",
    "      --king-table-filter ${kinship} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      --min-af ${kin_maf} \\\n",
    "      --max-af ${1-kin_maf} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} \n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(cat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(cat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-scholar",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data \n",
    "[king_2: shared = \"related_id\" ]\n",
    "# If set to true, the unrelated individuals in a family will be kept without being reported. \n",
    "# Otherwise (use `--no-maximize-unrelated`) the entire family will be removed\n",
    "# Note that attempting to maximize unrelated individuals is computationally intensive on large data.\n",
    "parameter: maximize_unrelated = False\n",
    "related_id = [x.strip() for x in open(_input).readlines() if not x.startswith(\"#\")]\n",
    "output: f'{_input:n}.related_id'\n",
    "with open(_output, 'a'):\n",
    "    pass   ## This should create an empty output such that both the empty relateness and unrelated samples bed will be created. So we dont need to subset the samples manually.\n",
    "done_if(len(related_id) == 0, msg = f\"No related individuals detected from {_input}.\")\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R:  container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "    library(dplyr)\n",
    "    library(igraph)\n",
    "    # Remove related individuals while keeping maximum number of individuals\n",
    "    # this function is simplified from: \n",
    "    # https://rdrr.io/cran/plinkQC/src/R/utils.R\n",
    "    #' @param relatedness [data.frame] containing pair-wise relatedness estimates\n",
    "    #' (in column [relatednessRelatedness]) for individual 1 (in column\n",
    "    #' [relatednessIID1] and individual 2 (in column [relatednessIID1]). Columns\n",
    "    #' relatednessIID1, relatednessIID2 and relatednessRelatedness have to present,\n",
    "    #' while additional columns such as family IDs can be present. Default column\n",
    "    #' names correspond to column names in output of plink --genome\n",
    "    #' (\\url{https://www.cog-genomics.org/plink/1.9/ibd}). All original\n",
    "    #' columns for pair-wise highIBDTh fails will be returned in fail_IBD.\n",
    "    #' @param relatednessTh [double] Threshold for filtering related individuals.\n",
    "    #' Individuals, whose pair-wise relatedness estimates are greater than this\n",
    "    #' threshold are considered related.\n",
    "    relatednessFilter <- function(relatedness, \n",
    "                                  relatednessTh,\n",
    "                                  relatednessIID1=\"IID1\", \n",
    "                                  relatednessIID2=\"IID2\",\n",
    "                                  relatednessRelatedness=\"KINSHIP\") {\n",
    "        # format data\n",
    "        if (!(relatednessIID1 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessIID2 %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessIID1, \"for relatedness not found!\"))\n",
    "        }\n",
    "        if (!(relatednessRelatedness %in% names(relatedness))) {\n",
    "            stop(paste(\"Column\", relatednessRelatedness,\n",
    "                       \"for relatedness not found!\"))\n",
    "        }\n",
    "\n",
    "        iid1_index <- which(colnames(relatedness) == relatednessIID1)\n",
    "        iid2_index <- which(colnames(relatedness) == relatednessIID2)\n",
    "\n",
    "        relatedness[,iid1_index] <- as.character(relatedness[,iid1_index])\n",
    "        relatedness[,iid2_index] <- as.character(relatedness[,iid2_index])\n",
    "\n",
    "        relatedness_names <- names(relatedness)\n",
    "        names(relatedness)[iid1_index] <- \"IID1\"\n",
    "        names(relatedness)[iid2_index] <- \"IID2\"\n",
    "        names(relatedness)[names(relatedness) == relatednessRelatedness] <- \"M\"\n",
    "\n",
    "        # Remove symmetric IID rows\n",
    "        relatedness_original <- relatedness\n",
    "        relatedness <- dplyr::select_(relatedness, ~IID1, ~IID2, ~M)\n",
    "\n",
    "        sortedIDs <- data.frame(t(apply(relatedness, 1, function(pair) {\n",
    "            c(sort(c(pair[1], pair[2])))\n",
    "            })), stringsAsFactors=FALSE)\n",
    "        keepIndex <- which(!duplicated(sortedIDs))\n",
    "\n",
    "        relatedness_original <- relatedness_original[keepIndex,]\n",
    "        relatedness <- relatedness[keepIndex,]\n",
    "\n",
    "        # individuals with at least one pair-wise comparison > relatednessTh\n",
    "        # return NULL to failIDs if no one fails the relatedness check\n",
    "        highRelated <- dplyr::filter_(relatedness, ~M > relatednessTh)\n",
    "        if (nrow(highRelated) == 0) {\n",
    "            return(list(relatednessFails=NULL, failIDs=NULL))\n",
    "        }\n",
    "\n",
    "        # all samples with related individuals\n",
    "        allRelated <- c(highRelated$IID1, highRelated$IID2)\n",
    "        uniqueIIDs <- unique(allRelated)\n",
    "\n",
    "        # Further selection of samples with relatives in cohort\n",
    "        multipleRelative <- unique(allRelated[duplicated(allRelated)])\n",
    "        singleRelative <- uniqueIIDs[!uniqueIIDs %in% multipleRelative]\n",
    "\n",
    "        highRelatedMultiple <- highRelated[highRelated$IID1 %in% multipleRelative |\n",
    "                                            highRelated$IID2 %in% multipleRelative,]\n",
    "        highRelatedSingle <- highRelated[highRelated$IID1 %in% singleRelative &\n",
    "                                           highRelated$IID2 %in% singleRelative,]\n",
    "\n",
    "        # Only one related samples per individual\n",
    "        if(length(singleRelative) != 0) {\n",
    "          # randomly choose one to exclude\n",
    "          failIDs_single <- highRelatedSingle[,1]\n",
    "            \n",
    "        } else {\n",
    "          failIDs_single <- NULL\n",
    "        }\n",
    "  \n",
    "        # An individual has multiple relatives\n",
    "        if(length(multipleRelative) != 0) {\n",
    "            relatedPerID <- lapply(multipleRelative, function(x) {\n",
    "                tmp <- highRelatedMultiple[rowSums(\n",
    "                    cbind(highRelatedMultiple$IID1 %in% x,\n",
    "                          highRelatedMultiple$IID2 %in% x)) != 0,1:2]\n",
    "                rel <- unique(unlist(tmp))\n",
    "                return(rel)\n",
    "            })\n",
    "            names(relatedPerID) <- multipleRelative\n",
    "\n",
    "            keepIDs_multiple <- lapply(relatedPerID, function(x) {\n",
    "                pairwise <- t(combn(x, 2))\n",
    "                index <- (highRelatedMultiple$IID1 %in% pairwise[,1] &\n",
    "                              highRelatedMultiple$IID2 %in% pairwise[,2]) |\n",
    "                    (highRelatedMultiple$IID1 %in% pairwise[,2] &\n",
    "                         highRelatedMultiple$IID2 %in% pairwise[,1])\n",
    "                combination <- highRelatedMultiple[index,]\n",
    "                combination_graph <- igraph::graph_from_data_frame(combination,\n",
    "                                                                   directed=FALSE)\n",
    "                all_iv_set <- igraph::ivs(combination_graph)\n",
    "                length_iv_set <- sapply(all_iv_set, function(x) length(x))\n",
    "\n",
    "                if (all(length_iv_set == 1)) {\n",
    "                    # check how often they occurr elsewhere\n",
    "                    occurrence <- sapply(x, function(id) {\n",
    "                        sum(sapply(relatedPerID, function(idlist) id %in% idlist))\n",
    "                    })\n",
    "                    # if occurrence the same everywhere, pick the first, else keep\n",
    "                    # the one with minimum occurrence elsewhere\n",
    "                    if (length(unique(occurrence)) == 1) {\n",
    "                        nonRelated <- sort(x)[1]\n",
    "                    } else {\n",
    "                        nonRelated <- names(occurrence)[which.min(occurrence)]\n",
    "                    }\n",
    "                } else {\n",
    "                    nonRelated <- all_iv_set[which.max(length_iv_set)]\n",
    "                }\n",
    "                return(nonRelated)\n",
    "            })\n",
    "            keepIDs_multiple <- unique(unlist(keepIDs_multiple))\n",
    "            failIDs_multiple <- c(multipleRelative[!multipleRelative %in%\n",
    "                                                       keepIDs_multiple])\n",
    "        } else {\n",
    "            failIDs_multiple <- NULL\n",
    "        }\n",
    "        allFailIIDs <- c(failIDs_single, failIDs_multiple)\n",
    "        relatednessFails <- lapply(allFailIIDs, function(id) {\n",
    "            fail_inorder <- relatedness_original$IID1 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            fail_inreverse <- relatedness_original$IID2 == id &\n",
    "                relatedness_original$M > relatednessTh\n",
    "            if (any(fail_inreverse)) {\n",
    "                inreverse <- relatedness_original[fail_inreverse, ]\n",
    "                id1 <- iid1_index\n",
    "                id2 <- iid2_index\n",
    "                inreverse[,c(id1, id2)] <- inreverse[,c(id2, id1)]\n",
    "                names(inreverse) <- relatedness_names\n",
    "            } else {\n",
    "                inreverse <- NULL\n",
    "            }\n",
    "            inorder <- relatedness_original[fail_inorder, ]\n",
    "            names(inorder) <- relatedness_names\n",
    "            return(rbind(inorder, inreverse))\n",
    "        })\n",
    "        relatednessFails <- do.call(rbind, relatednessFails)\n",
    "        if (nrow(relatednessFails) == 0) {\n",
    "            relatednessFails <- NULL\n",
    "            failIDs <- NULL\n",
    "        } else {\n",
    "            names(relatednessFails) <- relatedness_names\n",
    "            rownames(relatednessFails) <- 1:nrow(relatednessFails)\n",
    "            uniqueFails <- relatednessFails[!duplicated(relatednessFails[,iid1_index]),]\n",
    "            failIDs <- uniqueFails[,iid1_index]\n",
    "        }\n",
    "        return(list(relatednessFails=relatednessFails, failIDs=failIDs))\n",
    "    }\n",
    "    \n",
    "  \n",
    "    # main code\n",
    "    kin0 <- read.table(${_input:r}, header=F, stringsAsFactor=F)\n",
    "    colnames(kin0) <- c(\"FID1\",\"ID1\",\"FID2\",\"ID2\",\"NSNP\",\"HETHET\",\"IBS0\",\"KINSHIP\")\n",
    "    if (${\"TRUE\" if maximize_unrelated else \"FALSE\"}) {\n",
    "        rel <- relatednessFilter(kin0, ${kinship}, \"ID1\", \"ID2\", \"KINSHIP\")$failIDs\n",
    "        tmp1 <- kin0[,1:2]\n",
    "        tmp2 <- kin0[,3:4]\n",
    "        colnames(tmp1) = colnames(tmp2) = c(\"FID\", \"ID\")\n",
    "        # Get the family ID for these rels so there are two columns FID and IID in the output\n",
    "        lookup <- dplyr::distinct(rbind(tmp1,tmp2))\n",
    "        dat <- lookup[which(lookup[,2] %in% rel),]\n",
    "    } else {\n",
    "        rel <- kin0 %>% filter(KINSHIP >= ${kinship})\n",
    "        dat = rbind(rel[,c(\"FID1\",\"ID1\")],setNames(rel[,c(\"FID2\",\"ID2\")],c(\"FID1\",\"ID1\")))\n",
    "        dat = dat[!duplicated(dat),] ## This is to remove duplicated FID and IID caused by one sample being related to multiple samples\n",
    "       }    \n",
    "\n",
    "    cat(\"There are\", nrow(dat),\"related individuals using a kinship threshold of ${kinship}\\n\")\n",
    "    write.table(dat,${_output:r}, quote=FALSE, row.names=FALSE, col.names=FALSE)\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(cat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(cat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-roommate",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "[king_3]\n",
    "depends: sos_variable(\"related_id\")\n",
    "input: output_from(2), genoFile\n",
    "output: unrelated_bed = f'{cwd}/{_input[0]:bn}.unrelated.bed',\n",
    "        related_bed = f'{cwd}/{_input[0]:bn}.related.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --remove ${_input[0]} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[0]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "\n",
    "    if [ ${len(related_id)} -ne 0 ] ; then\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --keep ${_input[0]} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[1]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "    else\n",
    "       touch ${_output[1]}\n",
    "    fi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-malaysia",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype and sample QC\n",
    "\n",
    "QC the genetic data based on MAF, sample and variant missigness and Hardy-Weinberg Equilibrium (HWE).\n",
    "\n",
    "In this step you may also provide a list of samples to keep, for example in the case when you would like to subset a sample based on their ancestries to perform independent analyses on each of these groups.\n",
    "\n",
    "The default parameters are set to reflect some suggestions in Table 1 of [this paper](https://dx.doi.org/10.1002%2Fmpr.1608)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "requested-stanley",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[qc_no_prune, qc_1 (basic QC filters)]\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0.0\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# minimum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_filter = 0.0\n",
    "# maximum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_max_filter = 0.0 \n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter -- a very lenient one\n",
    "parameter: hwe_filter = 1e-15\n",
    "# Other PLINK arguments e.g snps_only, write-samples, etc\n",
    "parameter: other_args = []\n",
    "# Only output SNP and sample list, rather than the PLINK binary format of subset data\n",
    "parameter: meta_only = False\n",
    "# Remove duplicate variants\n",
    "parameter: rm_dups = False\n",
    "\n",
    "fail_if(not (keep_samples.is_file() or keep_samples == path('.')), msg = f'Cannot find ``{keep_samples}``')\n",
    "fail_if(not (keep_variants.is_file() or keep_variants == path('.')), msg = f'Cannot find ``{keep_variants}``')\n",
    "fail_if(not (remove_samples.is_file() or remove_samples == path('.')), msg = f'Cannot find ``{remove_samples}``')\n",
    "\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.plink_qc{\".extracted\" if keep_variants.is_file() else \"\"}{\".bed\" if not meta_only else \".snplist\"}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "      ${('--mac %s' % mac_filter) if mac_filter > 0 else ''} \\\n",
    "      ${('--max-mac %s' % mac_max_filter) if mac_max_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--exclude %s' % exclude_variants) if exclude_variants.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % keep_variants) if keep_variants.is_file() else \"\"} \\\n",
    "      ${('--make-bed') if not meta_only else \"--write-snplist --write-samples\"} \\\n",
    "      ${(\"\") if not rm_dups else \"--rm-dup force-first 'list'\"} \\\n",
    "      ${paths([\"--%s\" % x for x in other_args]) if other_args else \"\"} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "        \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output:n}.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nuclear-semester",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning and remove related individuals (both ind of a pair)\n",
    "# Plink2 has multi-threaded calculation for LD prunning\n",
    "[qc_2 (LD pruning)]\n",
    "# Window size\n",
    "parameter: window = 50\n",
    "# Shift window every 10 snps\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "stop_if(r2==0)\n",
    "output: bed=f'{cwd}/{_input:bn}.prune.bed', prune=f'{cwd}/{_input:bn}.prune.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[\"prune\"]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "   \n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output['prune']} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output['bed']:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output[0]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output[0]:n}.stdout\n",
    "    i=\"${_output[1]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(zcat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(zcat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6) \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\" >> ${_output[1]}.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-condition",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extract genotype based on overlap with phenotype\n",
    "\n",
    "This is an auxiliary step to match genotype and phenotype based on the data and look-up table. The look up table should contain two columns: `sample_id`, `genotype_id`. If the look up table is not provided or look-up table file not found, then we will assume the names have already been matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-calibration",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "[genotype_phenotype_sample_overlap]\n",
    "# A genotype fam file\n",
    "parameter: genoFile = path\n",
    "# A phenotype file, can be bed.gz or tsv\n",
    "parameter: phenoFile = path\n",
    "# If this file is provided, a genotype/phenotype sample name match will be performed\n",
    "# It must contain two column names: genotype_id, sample_id\n",
    "parameter: sample_participant_lookup = path(\".\")\n",
    "input: genoFile, phenoFile\n",
    "output: f'{cwd:a}/{path(_input[1]):bn}.sample_overlap.txt', f'{cwd:a}/{path(_input[1]):bn}.sample_genotypes.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "    library(data.table)\n",
    "\n",
    "    # Read data files; let read_delim auto-determine the delimiter\n",
    "    genoFam <- fread(${_input[0]:ar}, header=FALSE)\n",
    "    phenoFile <- read_delim(${_input[1]:ar}, col_names=TRUE)\n",
    "    if (${\"TRUE\" if sample_participant_lookup.is_file() else \"FALSE\"}) {\n",
    "        sample_lookup <- fread(${sample_participant_lookup:ar}, header=TRUE)\n",
    "        colnames(sample_lookup) <- c(\"sample_id\", \"genotype_id\") # FIXME: This is for the old lookup table with columns c(\"sample_id\", \"participant_id\")\n",
    "        # rename phenotype file according to lookup file\n",
    "        colnames(phenoFile)[-c(1:4)] <- phenoFile %>%\n",
    "          colnames() %>%\n",
    "          .[-c(1:4)] %>%\n",
    "          match(sample_lookup$sample_id) %>%\n",
    "          sample_lookup$genotype_id[.]\n",
    "          fwrite(phenoFile, paste0(${phenoFile:nnr},'.rename_sample.bed.gz'), sep = '\\t')\n",
    "    } else {\n",
    "        sample_lookup <- cbind(genoFam[,2], genoFam[,2])\n",
    "        colnames(sample_lookup) <- c(\"genotype_id\", \"sample_id\")\n",
    "    }\n",
    "    sample_lookup <- sample_lookup %>%\n",
    "    filter(\n",
    "        genotype_id %in% genoFam$V2,\n",
    "        sample_id %in% colnames(phenoFile)\n",
    "    )\n",
    "    \n",
    "    genoFam %>%\n",
    "    filter(\n",
    "        V2 %in% sample_lookup$genotype_id,\n",
    "    ) %>%\n",
    "    select(V1, V2) %>%\n",
    "    fwrite(${_output[1]:r}, col.names=FALSE, sep=\"\\t\")\n",
    "\n",
    "    sample_lookup %>%\n",
    "    fwrite(${_output[0]:r}, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "0.22.4"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "sos",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "0.22.6"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "sos",
     "op": "patch"
    }
   ]
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
