{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a346b94-10ff-440b-9c28-9602ba7bbd73",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Meta analysis\n",
    "This note book document the process of meta analysis. The output of QTL association will firstly be grouped based on whether they could be conducted meta analysis. Those that were grouped together will be fed into METAL. The rest will be fed into MASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65cc69-495a-4f88-9ac3-8dac05bb0ba1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: wd = \"./\"\n",
    "# The filename name for output data\n",
    "parameter: container = 'gaow/twas'\n",
    "# name for the analysis output\n",
    "parameter: name = 'ROSMAP'\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Diretory to the executable\n",
    "parameter: exe_dir = path(\"~/GIT/ADSPFG-xQTL/workflow\")\n",
    "# yml template\n",
    "parameter: yml = f'{exe_dir:d}/code/csg.yml'\n",
    "# queue for analysis\n",
    "parameter: queue = \"csg\"\n",
    "# Number of submission\n",
    "parameter: J = 200\n",
    "# Mash Options\n",
    "parameter: vhat = 'simple'\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "## A multi column file, each row is 1 chr, first col is chr, each subsqeunt a theme. each cell is the path to a sumstat file, which with following column format: variant_id, alt, ref, pval, beta, se ; \n",
    "parameter: sumstat_list_path = path\n",
    "sumstat_list =  pd.read_csv(sumstat_list_path,delimiter=\"\\t\")\n",
    "## A comma sep str that indicates what are the themes that goes into metal\n",
    "parameter: METAL_theme_str = \".\"\n",
    "## Retain the chr column as well\n",
    "METAL_theme = METAL_theme_str.split(\",\")\n",
    "METAL_theme_prefix = \"-\".join(METAL_theme)\n",
    "METAL_theme.append(\"chr\")\n",
    "METAL_list = sumstat_list[METAL_theme].values.tolist()\n",
    "Non_METAL_list= sumstat_list.drop(METAL_theme_str.split(\",\"),axis = 1)\n",
    "chrom = sumstat_list[\"chr\"].values.tolist()\n",
    "METALed_sumstat_list = Non_METAL_list.assign(**{METAL_theme_prefix : [f'{wd}/METAL/{METAL_theme_prefix}.chr{x}.METAL.txt' for x in chrom ]})\n",
    "Theme = METALed_sumstat_list.drop([\"chr\"],axis = 1).columns.values.tolist()\n",
    "Theme_list = pd.DataFrame({\"#Theme\" : [f'{wd}/sumstat/{x}' for x in Theme]})\n",
    "Theme_prefix = \"_\".join(Theme)\n",
    "parameter: region_list = path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015bddd-a15a-4ace-969b-9bf387ccb81b",
   "metadata": {
    "kernel": "Markdown",
    "tags": []
   },
   "source": [
    "## METAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b418ac5-4cda-4df7-b307-4151196996d3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL]\n",
    "input: for_each = \"METAL_list\"\n",
    "output: METAL_output = f'{wd}/METAL/{METAL_theme_prefix}.chr{_METAL_list[-1]}.METAL.txt'\n",
    "task: trunk_workers = 1, trunk_size = 20, walltime = '4h',  mem = '6G', tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        sos run $[exe_dir]/Meta_Analysis/METAL/METAL.ipynb METAL \\\n",
    "            --wd $[wd]/METAL/ \\\n",
    "            --name $[METAL_theme_prefix].chr$[_METAL_list[-1]] \\\n",
    "            --sumstat_list $[\" \".join(_METAL_list[0:-1])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f4b99-8791-4833-80bc-8365087cfba7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57c3c559-b8c7-4293-99d0-4c9fcfa32eab",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Partitioning\n",
    "Partition into each gene first then merge, each input is a list of sumstat per chromosome, each output is sumstat in rds format per gene\n",
    "Input is n*p matrix where n is number of chr and p is number of theme not went through metal + 1.\n",
    "\n",
    "The idea is, turn the n*p mtr into p n*2 mtr with p and chr column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cbb98-0757-4fdf-a971-b6361d1f12ca",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Partition_1]\n",
    "depends: sos_step(\"METAL\")\n",
    "input: for_each = \"Theme\"\n",
    "output: f'{wd}/sumstat/{_Theme}/sumstat_list',\n",
    "        Partition_list = f'{wd}/sumstat/{_Theme}/analysis_unit.txt'\n",
    "import pandas as pd\n",
    "METALed_sumstat_list[[_Theme,\"chr\"]].to_csv(_output[0],index = 0,sep = \"\\t\" )\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/Reformatting/Partitioned.ipynb Sumstat_Annotation \\\n",
    "            --wd $[wd] \\\n",
    "            --container $[container] \\\n",
    "            --name $[_Theme] \\\n",
    "            --sumstat_list $[_output[0]] \\\n",
    "            --region_list $[region_list] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40432642-9df2-4d12-8a55-a2211158ca8a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532b427-4fb9-401a-a3d2-8b470fb3af27",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "## Get only the intersection\n",
    "[Partition_2]\n",
    "input: output_from(\"Partition_1\")[\"Partition_list\"], group_by = \"all\"\n",
    "output: f'{wd}/sumstat/Partition_analysis_unit.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import pandas as pd\n",
    "    au = [ pd.read_csv(x ,header = None).to_dict(\"list\")[0] for x in [$[_input:r,]] ]\n",
    "    intersect_list = list(set.intersection(*map(set,au)))\n",
    "    pd.DataFrame({\"#Analysis_Unit\":intersect_list }).to_csv(\"$[_output]\" , sep = \"\\t\", index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da550f4-f200-4c8c-8321-b4da4de668f5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6c6e9-70e8-4a85-8d3b-b7c0da2de221",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_and_alleleQC]\n",
    "depends: sos_step(\"METAL\")     \n",
    "Theme_list.to_csv(f'{wd}/Theme_list.txt',sep = \"\\t\",index = 0)\n",
    "input: output_from(\"Partition\")\n",
    "output: merged_analysis_unit = f'{wd}/sumstat/merged_analysis_unit.txt'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/Reformatting/Merged.ipynb merge_and_alleleQC \\\n",
    "            --wd $[wd]/sumstat/ \\\n",
    "            --container $[container] \\\n",
    "            --theme_list $[f'{wd}/Theme_list.txt'] \\\n",
    "            --analysis_units $[_input] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79bb2a-a06b-4519-9cf2-31e616d8c399",
   "metadata": {
    "kernel": "Markdown",
    "tags": []
   },
   "source": [
    "## Extract effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887439ba-61c0-4ebb-977b-a9d645803733",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[extract_effects]\n",
    "input: output_from(\"merge_and_alleleQC\")[\"merged_analysis_unit\"]\n",
    "output: extracted_effect = f'{wd}/sumstat/{Theme_prefix}.rds'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/Reformatting/Signal_Extraction.ipynb extract_effects \\\n",
    "            --cwd $[wd]/sumstat/ \\\n",
    "            --container $[container] \\\n",
    "            --name $[Theme_prefix] \\\n",
    "            --analysis_units $[_input] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343efc19-1a28-4f0b-9222-f8f90685db11",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Factor analysis and MASH Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dcced-c8ad-4b6a-90a8-336d98007b46",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[MASH_FLASH]\n",
    "parameter: effect_model = 'EZ'\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca',\"canonical\"]\n",
    "input: output_from(\"extract_effects\")[\"extracted_effect\"]\n",
    "output: MASH_model = f\"{wd}/sumstat/{Theme_prefix}.{effect_model}.V_{vhat}.mash_model.rds\",\n",
    "        resid_corr = f\"{wd}/sumstat/{Theme_prefix}.{effect_model}.V_{vhat}.rds\",\n",
    "        flash_output = [f\"{wd}/sumstat/{Theme_prefix}.{m}.rds\" for m in mixture_components]\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/MASH/mashr_flashr_workflow.ipynb mash \\\n",
    "            --cwd $[wd]/sumstat/ \\\n",
    "            --container $[container] \\\n",
    "            --effect_model $[effect_model] \\\n",
    "            --vhat $[vhat] \\\n",
    "            --output_prefix $[Theme_prefix] \\\n",
    "            --data $[_input] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865788f-fdd4-48f0-b697-27691d9d588c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77e7df73-bbcd-4030-a59c-dbce04f80613",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## MASH Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b31669-b7c7-4cd9-b953-06e2bb21eed7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[MASH_posterior]\n",
    "parameter: effect_model = 'EZ'\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca',\"canonical\"]\n",
    "analysis_units = f'{wd}/sumstat/merged_analysis_unit.txt'\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "gene = [x[0] for x in regions]\n",
    "input: output_from(\"MASH_FLASH\")[\"MASH_model\"], regions\n",
    "output: mash_output_list = f'{wd}/sumstat/mash_output_list'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/MASH/mash_posterior.ipynb  posterior \\\n",
    "            --cwd $[wd]/sumstat/ \\\n",
    "            --container $[container] \\\n",
    "            --mash_model $[_input[0]] \\\n",
    "            --vhat $[vhat] \\\n",
    "            --output_prefix $[Theme_prefix] \\\n",
    "            --posterior_input  $[\" \".join(gene)] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827ecad-53f6-485a-a16b-374b90eda224",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Mixture Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5381cd0-0fff-4cd4-a01f-57875350d0cf",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Mixture_prior]\n",
    "parameter: effect_model = 'EZ'\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca',\"canonical\"]\n",
    "parameter: mixture_prior_method = \"ed_bovy\"\n",
    "input: output_from(\"MASH_FLASH\")[\"MASH_model\"], output_from(\"extract_effects\")[\"extracted_effect\"]\n",
    "analysis_units = f'{wd}/sumstat/merged_analysis_unit.txt'\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "output: mixture_prior = f'{wd}/../Fine_Mapping/Mixture_Prior/{Theme_prefix}.{mixture_prior_method}.V_{vhat}.rds'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "            sos run $[exe_dir]/Meta_Analysis/MASH/mixture_prior.ipynb $[mixture_prior_method] \\\n",
    "            --cwd $[wd] \\\n",
    "            --container $[container] \\\n",
    "            --name $[Theme_prefix] \\\n",
    "            --vhat $[vhat] \\\n",
    "            --data  $[_input[1]] \\\n",
    "            --name $[Theme_prefix] \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc99da-42b3-46de-99cd-255fd1b4f3c9",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Recipe for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d1c75-e2e3-4685-894f-127ace5d50ba",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Recipe]\n",
    "depends: sos_step(\"RDS2VCF\")\n",
    "parameter: mixture_prior_method = \"ed_bovy\"\n",
    "input:  output_from(\"merge_and_alleleQC\")[\"merged_analysis_unit\"],output_from(\"MASH_FLASH\")[\"resid_corr\"], output_from(\"Mixture_prior\")[\"mixture_prior\"]\n",
    "output: f'{wd}/Fine_mapping_recipe.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import pandas as pd\n",
    "    mixture_prior = pd.DataFrame({\"mixture_prior_list\" : [$[_input[2]:r,]]})\n",
    "    prior = mixture_prior.query('mixture_prior_list.str.contains(\"$[mixture_prior_method]\")',engine = \"python\")[\"mixture_prior_list\"].values.tolist()\n",
    "    output_pd = pd.DataFrame({\n",
    "    \"merged_analysis_unit\" : [\"$[_input[0]]\"],\n",
    "    \"resid_corr\" : [\"$[_input[1]]\"],\n",
    "    \"prior\" : prior,\n",
    "    \"Theme_prefix\" : [\"$[Theme_prefix]\"]})\n",
    "    output_pd.to_csv('$[_output]',sep = \"\\t\", index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebae34-94a1-4a32-aa5f-2e720b66fae5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## RDS to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67354d8-c321-40ad-b6cc-f8360d2077e9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[RDS2VCF]\n",
    "parameter: data_dir = path(\"/\")\n",
    "input: output_from(\"MASH_posterior\")[\"mash_output_list\"]\n",
    "output: f'{wd}/mash_vcf/vcf_output_list.txt'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        sos run $[exe_dir]/Meta_Analysis/Reformatting/RDS_to_vcf.ipynb rds_to_vcf \\\n",
    "            --wd $[wd]/ \\\n",
    "            --container $[container] \\\n",
    "            --name $[Theme_prefix] \\\n",
    "            --analysis_units $[_input] \\\n",
    "            --data_dir $[data_dir]  \\\n",
    "            -J $[J] -q $[queue] -c $[yml]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
