{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-ontario",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Genotype data formatting\n",
    "\n",
    "This module implements a collection of workflows used to format genotype data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-biotechnology",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-labor",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The module streamlines conversion between PLINK and VCF formats (possibly more to add), specifically:\n",
    "\n",
    "1. Conversion between VCF and PLINK formats\n",
    "2. Split data (by specified input, by chromosomes, by genes)\n",
    "3. Merge data (by specified input, by chromosomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-balance",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-jewelry",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Depending on the analysis task, input files are specified in one of the following formats:\n",
    "\n",
    "1. A single Whole genome data in VCF format, or in PLINK bim/bed/fam bundle; Or,\n",
    "2. A list of VCF or PLINK bed file\n",
    "3. A singular column file containing a list of VCF or PLINK bed file\n",
    "4. A two column file containing a list of per chromosome VCF or PLINK bed file where the first column is chrom and 2nd column is file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-honduras",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "Genotype data after reformatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-hamilton",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Examples\n",
    "\n",
    "Minimal working example data-set as well as the singularity container `bioinfo.sif` can be downloaded from [Google Drive](https://drive.google.com/drive/u/0/folders/1ahIZGnmjcGwSd-BI91C9ayd_Ya8sB2ed).\n",
    "\n",
    "### PLINK file merger\n",
    "\n",
    "```\n",
    "sos run genotype_formatting.ipynb merge_plink \\\n",
    "    --genoFile data/genotype/chr1.bed data/genotype/chr6.bed \\\n",
    "    --cwd output/genotype \\\n",
    "    --name chr1_chr6 \\\n",
    "    --container container/bioinfo.sif\n",
    "```\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sterling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convertible-colony",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run genotype_formatting.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  plink_to_vcf\n",
      "  vcf_to_plink\n",
      "  plink_by_gene\n",
      "  plink_by_chrom\n",
      "  merge_plink\n",
      "  merge_vcf\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        Work directory & output directory\n",
      "  --container ''\n",
      "                        The filename name for containers\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 3G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --genoFile  paths\n",
      "\n",
      "                        the path to a bed file or VCF file, a vector of bed\n",
      "                        files or VCF files, or a text file listing the bed files\n",
      "                        or VCF files to process\n",
      "\n",
      "Sections\n",
      "  plink_to_vcf_1:\n",
      "  vcf_to_plink:\n",
      "  plink_by_gene_1:\n",
      "    Workflow Options:\n",
      "      --window 500000 (as int)\n",
      "                        cis window size\n",
      "      --region-list VAL (as path, required)\n",
      "                        Region definition\n",
      "  plink_by_chrom_1:\n",
      "    Workflow Options:\n",
      "      --chrom VAL VAL ... (as type, required)\n",
      "  plink_by_chrom_2, plink_by_gene_2:\n",
      "  plink_to_vcf_2:\n",
      "  merge_plink:\n",
      "    Workflow Options:\n",
      "      --name VAL (as str, required)\n",
      "                        File prefix for the analysis output\n",
      "  merge_vcf:\n",
      "    Workflow Options:\n",
      "      --name VAL (as str, required)\n",
      "                        File prefix for the analysis output\n"
     ]
    }
   ],
   "source": [
    "sos run genotype_formatting.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-fellowship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# The filename name for containers\n",
    "parameter: container = ''\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"3G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# the path to a bed file or VCF file, a vector of bed files or VCF files, or a text file listing the bed files or VCF files to process\n",
    "parameter: genoFile = paths\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = f\"{cwd:a}\"\n",
    "\n",
    "import os\n",
    "def get_genotype_file(geno_file_paths):\n",
    "    #\n",
    "    def valid_geno_file(x):\n",
    "        suffixes = path(x).suffixes\n",
    "        if suffixes[-1] == '.bed':\n",
    "            return True\n",
    "        if len(suffixes)>1 and ''.join(suffixes[-2:]) == \".vcf.gz\":\n",
    "            return True\n",
    "        return False\n",
    "    #\n",
    "    def complete_geno_path(x, geno_file):\n",
    "        if not valid_geno_file(x):\n",
    "            raise ValueError(f\"Genotype file {x} should be VCF (end with .vcf.gz) or PLINK bed file (end with .bed)\")\n",
    "        if not os.path.isfile(x):\n",
    "            # relative path\n",
    "            if not os.path.isfile(f'{geno_file:ad}/' + x):\n",
    "                raise ValueError(f\"Cannot find genotype file {x}\")\n",
    "            else:\n",
    "                x = f'{geno_file:ad}/' + x\n",
    "        return x\n",
    "    # \n",
    "    def format_chrom(chrom):\n",
    "        if chrom.startswith('chr'):\n",
    "            chrom = chrom[3:]\n",
    "        return chrom\n",
    "    # Inputs are either VCF or bed, or a vector of them \n",
    "    if len(geno_file_paths) > 1:\n",
    "        if all([valid_geno_file(x) for x in geno_file_paths]):\n",
    "            return paths(geno_file_paths)\n",
    "        else: \n",
    "            raise ValueError(f\"Invalid input {geno_file_paths}\")\n",
    "    # Input is one genotype file or text list of genotype files\n",
    "    geno_file = geno_file_paths[0]\n",
    "    if valid_geno_file(geno_file):\n",
    "        return paths(geno_file)\n",
    "    else: \n",
    "        units = [x.strip().split() for x in open(geno_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "        if all([len(x) == 1 for x in units]):\n",
    "            return paths([complete_geno_path(x[0], geno_file) for x in units])\n",
    "        elif all([len(x) == 2 for x in units]):\n",
    "            genos = dict([(format_chrom(x[0]), path(complete_geno_path(x[1], geno_file))) for x in units])\n",
    "        else:\n",
    "            raise ValueError(f\"{geno_file} should contain one column of file names, or two columns of chrom number and corresponding file name\")\n",
    "        return genos\n",
    "                        \n",
    "genoFile = get_genotype_file(genoFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-dispatch",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## PLINK to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spanish-fundamentals",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_to_vcf_1]\n",
    "if isinstance(genoFile, dict):\n",
    "    genoFile = genoFile.values()\n",
    "\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.vcf.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{_input:ad}:{_input:ad}']\n",
    "    plink --bfile ${_input:n} \\\n",
    "        --recode vcf-iid  \\\n",
    "        --out ${_output:nn} \\\n",
    "        --threads ${numThreads} \\\n",
    "        --memory ${int(expand_size(mem) * 0.9)/1e06} --output-chr chrMT\n",
    "\n",
    "    bgzip -l 9 ${_output:n}\n",
    "    tabix -f -p vcf ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-result",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## VCF to PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-headset",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[vcf_to_plink]\n",
    "if isinstance(genoFile, dict):\n",
    "    genoFile = genoFile.values()\n",
    "\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:nn}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink --vcf ${_input} \\\n",
    "        --vcf-half-call m \\\n",
    "        --vcf-require-gt \\\n",
    "        --allow-extra-chr \\\n",
    "        --make-bed --out ${_output:n} \\\n",
    "        --threads ${numThreads} \\\n",
    "        --memory ${int(expand_size(mem) * 0.9)/1e06}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-preference",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Split PLINK by genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-answer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_gene_1]\n",
    "# cis window size\n",
    "parameter: window = 1000000\n",
    "# Region definition\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: genoFile, for_each = 'regions'\n",
    "output: f'{cwd}/{region_list:bn}_plink_files/{_input:bn}.{_regions[3]}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{region_list:ad}:{region_list:ad}']\n",
    "    plink2 --bfile ${_input:an} \\\n",
    "        --make-bed \\\n",
    "        --out ${_output[0]:n} \\\n",
    "        --chr ${_regions[0]} \\\n",
    "        --from-bp ${f'1' if (int(_regions[1]) - window) < 0 else f'{(int(_regions[1]) - window)}'} \\\n",
    "        --to-bp ${int(_regions[2]) + window} \\\n",
    "        --allow-no-sex --output-chr chrMT || touch ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9cde6-113d-4072-bf88-6dc5b32bf4b5",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{_input[0]:nn}.plink_files_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#id\" : [f'{x.split(\".\")[-2].replace(\"chr\",\"\")}' for x in  [${_input:r,}]],\n",
    "    \"dir\" : [${_input:r,}]\n",
    "    })\n",
    "    data_tempt.to_csv(\"${_output}\",index = False,sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df641a-9fc7-4f32-8553-5f016ac6c4c8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Compute LD matrices given input region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce17ceb9-7d15-4457-8026-54a125046348",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ld_by_region_plink]\n",
    "# Region definition\n",
    "parameter: region_list = path\n",
    "parameter: name = \"\"\n",
    "parameter: build = \"b38\"\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "if len(name) == 0:\n",
    "    name = {_input[0]:bn}\n",
    "input: genoFile, group_by = \"all\", for_each = 'regions'\n",
    "output: f'{cwd}/{region_list:bn}_ld/{name}.{_regions[0]}_{_regions[1]}_{_regions[2]}_{build}.ld.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{region_list:ad}:{region_list:ad}']\n",
    "    plink --bfile ${_input:an} \\\n",
    "        --out ${_output[0]:nn} \\\n",
    "        --chr ${_regions[0]} \\\n",
    "        --from-bp ${_regions[1]} \\\n",
    "        --to-bp ${_regions[2]}  --r square0 gz \\\n",
    "        --make-just-bim \\\n",
    "        --threads ${numThreads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c214372-542d-4b68-8226-f475346abb50",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# [ld_by_region_ldstore]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-productivity",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Split PLINK by Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-fault",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_chrom_1]\n",
    "stop_if(len(paths(genoFile))>1, msg = \"This workflow expects one input genotype file.\")\n",
    "parameter: chrom = list\n",
    "input: genoFile, for_each = \"chrom\"\n",
    "output: f'{cwd}/{_input:bn}.{_chrom}.bed'\n",
    "# look up for genotype file\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{genoFile:ad}:{genoFile:ad}']\n",
    "    ##### Get the locus genotypes for $[_chrom]\n",
    "    plink --bfile $[_input:an] \\\n",
    "    --make-bed \\\n",
    "    --out $[_output[0]:n] \\\n",
    "    --chr $[_chrom] \\\n",
    "    --allow-no-sex  || true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-pressure",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_chrom_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{_input[0]:nn}.plink_files_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#id\" : [x.split(\".\")[-2].replace(\"chr\",\"\") for x in  [${_input:r,}]],\n",
    "    \"dir\" : [${_input:r,}]\n",
    "    })\n",
    "    data_tempt.to_csv(\"${_output}\",index = False,sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de47b8-55c8-45e3-be4c-5c9228a5c886",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_to_vcf_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{_input[0]:nnn}.vcf_files_list.txt'\n",
    "#task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#id\" : [x.split(\".\")[-3] for x in  [${_input:r,}]],\n",
    "    \"dir\" : [${_input:r,}]\n",
    "    })\n",
    "    data_tempt.to_csv(\"${_output}\",index = False,sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-instrument",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Split VCF by Chromosome\n",
    "\n",
    "**FIXME: add this as needed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-issue",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge PLINK files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-development",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_plink]\n",
    "skip_if(len(genoFile) == 1)\n",
    "# File prefix for the analysis output\n",
    "parameter: name = str\n",
    "input: genoFile, group_by = 'all'\n",
    "output: f\"{cwd}/{name}.merge_list\", f\"{cwd}/{name}.bed\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[1]:bn}'\n",
    "\n",
    "with open(_output[0], 'w') as f:\n",
    "    f.write('\\n'.join([str(f'{x:n}') for x in _input[1:]]))\n",
    "\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[1]:n}.stderr', stdout = f'{_output[1]:n}.stdout'\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output[0]} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output[1]:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e06}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-profit",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge VCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-listening",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_vcf]\n",
    "skip_if(len(genoFile) == 1)\n",
    "# File prefix for the analysis output\n",
    "parameter: name = str\n",
    "input: genoFile, group_by = 'all'\n",
    "output:  f\"{cwd}/{name}.vcf.gz\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bcftools concat -Oz ${_input} > ${_output}\n",
    "    tabix -p vcf ${_output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
