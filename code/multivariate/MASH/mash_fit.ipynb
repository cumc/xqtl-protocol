{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# MASH analysis pipeline with data-driven prior matrices\n",
    "\n",
    "In this notebook, we utilize the MASH prior, referred to as the [mixture_prior](https://github.com/cumc/xqtl-pipeline/blob/6c637645ce16aee2aa7dc86bbc334fb6bb66b9d9/code/multivariate/MASH/mixture_prior.ipynb#L4), from a previous step. Our objective is to conduct a multivariate analysis under the MASH model. After fitting the model, we subsequently compute the posteriors for our variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "/home/rf2872/Work/Multivariate/MASH/MWE/output/MWE.rds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## multivariate analysis with [prior](https://github.com/cumc/xqtl-pipeline/blob/d43590b2da112aab357447e4ba931d95bc464cb5/code/multivariate/MASH/mixture_prior.ipynb) from [MWE]((https://github.com/cumc/xqtl-pipeline/blob/d43590b2da112aab357447e4ba931d95bc464cb5/code/multivariate/MASH/mixture_prior.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running \u001b[32mmash_1\u001b[0m: Fit MASH mixture model (time estimate: <15min for 70K by 49 matrix)\n",
      "INFO: Running \u001b[32mvhat_mle\u001b[0m: V estimate: \"mle\" method\n",
      "INFO: \u001b[32mvhat_mle\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mvhat_mle\u001b[0m output:   \u001b[32m/mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/MWE/MWE_udr/MWE_udr.EZ.V_mle.rds\u001b[0m\n",
      "INFO: \u001b[32mmash_1\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mmash_1\u001b[0m output:   \u001b[32m/mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/MWE/MWE_udr/MWE_udr.EZ.V_mle.mash_model.rds\u001b[0m\n",
      "INFO: Running \u001b[32mmash_2\u001b[0m: Compute posterior for the \"strong\" set of data as in Urbut et al 2017. This is optional because most of the time we want to apply the MASH model learned on much larger data-set.\n",
      "INFO: \u001b[32mmash_2\u001b[0m is \u001b[32mcompleted\u001b[0m.\n",
      "INFO: \u001b[32mmash_2\u001b[0m output:   \u001b[32m/mnt/vast/hpc/csg/rf2872/Work/Multivariate/MASH/MWE/MWE_udr/MWE_udr.EZ.posterior.rds\u001b[0m\n",
      "INFO: Workflow mash (ID=wc5d41041963cfe84) is executed successfully with 3 completed steps.\n"
     ]
    }
   ],
   "source": [
    "#2: mash_fit, use the prior data \n",
    "\n",
    "sos run pipeline/mash_fit.ipynb mash \\\n",
    "    --container /mnt/vast/hpc/csg/containers_xqtl/stephenslab.sif \\\n",
    "    --output_prefix MWE_udr \\\n",
    "    --data output/MWE.rds \\\n",
    "    --cwd MWE_udr --vhat mle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path('./mashr_flashr_workflow_output')\n",
    "# Input summary statistics data\n",
    "parameter: data = path(\"fastqtl_to_mash_output/FastQTLSumStats.mash.rds\")\n",
    "# Prefix of output files. If not specified, it will derive it from data.\n",
    "# If it is specified, for example, `--output-prefix AnalysisResults`\n",
    "# It will save output files as `{cwd}/AnalysisResults*`.\n",
    "parameter: output_prefix = ''\n",
    "parameter: output_suffix = 'all'\n",
    "# Exchangable effect (EE) or exchangable z-scores (EZ)\n",
    "parameter: effect_model = 'EZ'\n",
    "# Identifier of $\\hat{V}$ estimate file\n",
    "# Options are \"identity\", \"simple\", \"mle\", \"vhat_corshrink_xcondition\", \"vhat_simple_specific\"\n",
    "parameter: vhat = 'simple'\n",
    "# Options are \"ed\" and \"udr\"\n",
    "parameter: stat_algo = \"ed\"\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca',\"canonical\"]\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "data = data.absolute()\n",
    "cwd = cwd.absolute()\n",
    "if len(output_prefix) == 0:\n",
    "    output_prefix = f\"{data:bn}\"\n",
    "prior_data = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.prior.rds\")\n",
    "vhat_data = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.rds\")\n",
    "mash_model = file_target(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "\n",
    "def sort_uniq(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# V estimate: \"mle\" method\n",
    "[vhat_mle]\n",
    "# number of samples to use\n",
    "parameter: n_subset = 6000\n",
    "# maximum number of iterations\n",
    "parameter: max_iter = 6\n",
    "\n",
    "input: data, prior_data\n",
    "output: f'{vhat_data:nn}.V_mle.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    library(mashr)\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    # choose random subset\n",
    "    set.seed(1)\n",
    "    random.subset = sample(1:nrow(dat$random.b), min(${n_subset}, nrow(dat$random.b)))\n",
    "    random.subset = mash_set_data(dat$random.b[random.subset,], dat$random.s[random.subset,], alpha=${1 if effect_model == 'EZ' else 0}, zero_Bhat_Shat_reset = 1E3)\n",
    "    # estimate V mle\n",
    "    vhatprior = mash_estimate_corr_em(random.subset, readRDS(${_input[1]:r})$U, max_iter = ${max_iter})\n",
    "    vhat = vhatprior$V\n",
    "    saveRDS(vhat, ${_output:r})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## `mashr` mixture model fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Fit MASH mixture model (time estimate: <15min for 70K by 49 matrix)\n",
    "[mash_1]\n",
    "parameter: outputlevel = 1\n",
    "input: data, vhat_data, prior_data\n",
    "output: mash_model\n",
    "\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    library(mashr)\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    vhat = readRDS(${_input[1]:r})\n",
    "    U = readRDS(${_input[2]:r})$U\n",
    "    mash_data = mash_set_data(dat$random.b, Shat=dat$random.s, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    saveRDS(mash(mash_data, Ulist = U, outputlevel = ${outputlevel}), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Optional posterior computations\n",
    "\n",
    "Additionally provide posterior for the \"strong\" set in MASH input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Compute posterior for the \"strong\" set of data as in Urbut et al 2017.\n",
    "# This is optional because most of the time we want to apply the \n",
    "# MASH model learned on much larger data-set.\n",
    "[mash_2]\n",
    "# default to True; use --no-compute-posterior to disable this\n",
    "parameter: compute_posterior = True\n",
    "# input Vhat file for the batch of posterior data\n",
    "skip_if(not compute_posterior)\n",
    "\n",
    "input: data, vhat_data, mash_model\n",
    "output: f\"{cwd:a}/{output_prefix}.{effect_model}.posterior.rds\"\n",
    "\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container, entrypoint=entrypoint\n",
    "    library(mashr)\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    vhat = readRDS(${_input[1]:r})\n",
    "    mash_data = mash_set_data(dat$strong.b, Shat=dat$strong.s, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    mash_model = readRDS(${_input[2]:ar})\n",
    "    saveRDS(mash_compute_posterior_matrices(mash_model, mash_data), ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
