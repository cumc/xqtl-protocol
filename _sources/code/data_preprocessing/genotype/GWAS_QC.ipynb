{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitting-blank",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Genotype PLINK File Quality Control\n",
    "\n",
    "This workflow implements some preliminary data QC steps for PLINK input files. VCF format of inputs will be converted to PLINK before performing QC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-approach",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8acc1a9",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook includes workflow for\n",
    "\n",
    "- Compute kinship matrix in sample and estimate related individuals\n",
    "- Genotype and sample QC: by MAF, missing data and HWE\n",
    "- LD pruning for follow up PCA analysis on genotype, as needed\n",
    "\n",
    "A potential limitation is that the workflow requires all samples and chromosomes to be merged as one single file, in order to perform both sample and variant level QC. However, in our experience using this pipeline with 200K exomes with 15 million variants, this pipeline works on the single merged PLINK file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2277af",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods\n",
    "\n",
    "Depending on the context of your problem, the workflow can be executed in two ways:\n",
    "\n",
    "1. Run `qc` command to perform genotype data QC and LD pruning to generate a subset of variants in preparation for analysis such as PCA.\n",
    "2. Run `king` first on either the original or a subset of common variants to identify unrelated individuals. The `king` pipeline will split samples to related and unrelated individuals. Then you perform `qc` on these individuals only and finally extract the same set of QC-ed variants for related individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-testament",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Default Parameters: QC\n",
    "\n",
    "- Kinship coefficient for related individuals: 0.0625\n",
    "- MAF and MAC default: 0\n",
    "    - Above default includes both common and are variant\n",
    "    - Recommand MAF for PCA: 0.01, [we should stick to common variants](https://bmcgenomdata.biomedcentral.com/articles/10.1186/s12863-020-0833-x)\n",
    "    - Recommand MAC for single variant analysis: 5.\n",
    "- Variant level missingness threshold: 0.1\n",
    "- Sample level missingness threshold: 0.1\n",
    "- LD pruning via PLINK for PCA analysis:\n",
    "    - window 50 \n",
    "    - shift 10 \n",
    "    - r2 0.1\n",
    "- HWE default: 1E-15 which is very lenient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8349731",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "The whole genome PLINK bim/bed/fam bundle. For input in VCF format and/or per-chromosome VCF or PLINK format, please use `vcf_to_plink` and `merge_plink` in [genotype formatting](https://statfungen.github.io/xqtl-protocol/code/data_preprocessing/genotype/genotype_formatting.html) pipeline to convert them to PLINK file bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-caution",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "Minimal working example data-set as well as the singularity container `bioinfo.sif` can be downloaded from [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/).\n",
    "\n",
    "The `chr1_chr6` data-set was merged from `chr1` and `chr6` data, using `merge_plink` command from [genotype formatting](https://statfungen.github.io/xqtl-protocol/code/data_preprocessing/genotype/genotype_formatting.html) pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7ebf0",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### iii. Perform QC on both rare and common variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-saver",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run xqtl-protocol/pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "   --cwd Genotype \\\n",
    "   --genoFile Genotype/ROSMAP_NIA_WGS.leftnorm.bcftools_qc.bed \\\n",
    "   --geno-filter 0.1 \\\n",
    "   --mind-filter 0.1 \\\n",
    "   --hwe-filter 1e-08   \\\n",
    "   --mac-filter 0 \\\n",
    "   --container /mnt/vast/hpc/csg/containers/bioinfo.sif \\\n",
    "   -J 1 -q csg -c csg.yml --mem 150G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfbacd",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### v. Sample match with genotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223604d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e8520",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb genotype_phenotype_sample_overlap \\\n",
    "        --cwd output/sample_meta \\\n",
    "        --genoFile input/protocol_example.genotype.chr21_22.fam  \\\n",
    "        --phenoFile input/protocol_example.protein.csv \\\n",
    "        --container containers/bioinfo.sif \\\n",
    "        --mem 5G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002e5df",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running genotype_phenotype_sample_overlap: This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "INFO: genotype_phenotype_sample_overlap is completed.\n",
    "INFO: genotype_phenotype_sample_overlap output:   /Users/alexmccreight/xqtl-protocol/output/sample_meta/protocol_example.protein.sample_overlap.txt /Users/alexmccreight/xqtl-protocol/output/sample_meta/protocol_example.protein.sample_genotypes.txt\n",
    "INFO: Workflow genotype_phenotype_sample_overlap (ID=w71b4e35979654867) is executed successfully with 1 completed step.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-tracy",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### vi. Kinship QC\n",
    "\n",
    "To accuratly estimate the PCs for the genotype. We split participants based on their kinship coefficients, estimated by KING.\n",
    "\n",
    "1. Variant level and sample level QC on unrelated individuals using missingness > 10%, and LD-prunning in preparation for PCA analysis.    \n",
    "2. There is no related samples in these ROSMAP samples, so there is an additional step to only keep those samples in `rosmap_pheno.sample_genotypes.txt` to do PCA.\n",
    "\n",
    "**Be aware:**    \n",
    "\n",
    "**If the message from `king_2` shown as `No related individuals detected from *.kin0`, this means no related individuals detected for the samples in `--keep_samples`. In this case, there will be no output for related individuals from this step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88289e87",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-documentary",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd output/kinship \\\n",
    "    --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "    --name pQTL \\\n",
    "    --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "    --container containers/bioinfo.sif \\\n",
    "    --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6cebc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running king_1: Inference of relationships in the sample to identify closely related individuals\n",
    "INFO: king_1 is completed.\n",
    "INFO: king_1 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.kin0\n",
    "INFO: Running king_2: Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data\n",
    "INFO: king_2 is completed.\n",
    "INFO: king_2 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.related_id\n",
    "INFO: Running king_3: Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "INFO: king_3 is completed.\n",
    "INFO: king_3 output:   /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed /Users/alexmccreight/xqtl-protocol/output/kinship/protocol_example.genotype.chr21_22.pQTL.related.bed\n",
    "INFO: Workflow king (ID=w7fad1d8b027ec781) is executed successfully with 3 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c47aaa",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### vii. Prepare unrelated individuals data for PCA\n",
    "\n",
    "Here we write data to `cache` folder instead of `output` because this genotype data can be removed later after PCA. Also filter out minor allel accout < 5.\n",
    "\n",
    "**If your data has `*.unrelated.bed` generated, that means there are related individuals in your data. In cases, we will use output from the KING step for unrelated individuals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44866f9d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a3d37",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile output/kinship/protocol_example.genotype.chr21_22.pQTL.unrelated.bed \\\n",
    "   --mac-filter 5 \\\n",
    "   --container containers/bioinfo.sif \\\n",
    "   --mem 16G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b16679",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.bed /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.unrelated.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=w3a34828bd2888342) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-stamp",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "**In other cases eg ROSMAP proteomics data, message `No related individuals detected from *.kin0` occured, there is no separate genotype data generated for unrelated individuals. In this case, we need to work from the original genotype data and must use `--keep-samples` to run `qc` to extract samples for PCA.** For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402b86a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-vacuum",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/GWAS_QC.ipynb qc \\\n",
    "   --cwd output/cache \\\n",
    "   --genoFile input/protocol_example.genotype.chr21_22.bed \\\n",
    "   --keep-samples output/sample_meta/protocol_example.protein.sample_genotypes.txt \\\n",
    "   --name pQTL \\\n",
    "   --mac-filter 5 \\\n",
    "   --container containers/bioinfo.sif \\\n",
    "   --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce69aa2",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INFO: Running basic QC filters: Filter SNPs and select individuals\n",
    "INFO: basic QC filters is completed.\n",
    "INFO: basic QC filters output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.bed\n",
    "INFO: Running LD pruning: LD prunning and remove related individuals (both ind of a pair) Plink2 has multi-threaded calculation for LD prunning\n",
    "INFO: LD pruning is completed.\n",
    "INFO: LD pruning output:   /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.bed /Users/alexmccreight/xqtl-protocol/output/cache/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.in\n",
    "INFO: Workflow qc (ID=w3d8b01776519226f) is executed successfully with 2 completed steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-receptor",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "[FIXME:] Extract previously selected variants from related individuals in preparation for PCA, only applying missingness filter at sample level,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-stable",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run GWAS_QC.ipynb qc_no_prune \\\n",
    "    --cwd output/genotype \\\n",
    "    --genoFile output/genotype/chr1_chr6.20220110.related.bed \\\n",
    "    --keep-variants output/genotype/chr1_chr6.20220110.unrelated.for_pca.filtered.prune.in \\\n",
    "    --maf-filter 0 --geno-filter 0 --mind-filter 0.1 \\\n",
    "    --name for_pca \\\n",
    "    --container container/bioinfo.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-louisiana",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-national",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run GWAS_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  king\n",
      "  qc_no_prune\n",
      "  qc\n",
      "  genotype_phenotype_sample_overlap\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        the output directory for generated files\n",
      "  --name ''\n",
      "                        A string to identify your analysis run\n",
      "  --genoFile  paths\n",
      "\n",
      "                        PLINK binary files\n",
      "  --remove-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to remove (format FID, IID)\n",
      "  --keep-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "  --keep-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to keep\n",
      "  --exclude-variants . (as path)\n",
      "                        The path to the file that contains the list of variants\n",
      "                        to exclude\n",
      "  --kinship 0.0625 (as float)\n",
      "                        Kinship coefficient threshold for related individuals\n",
      "                        (e.g first degree above 0.25, second degree above 0.125,\n",
      "                        third degree above 0.0625)\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "\n",
      "Sections\n",
      "  king_1:               Inference of relationships in the sample to identify\n",
      "                        closely related individuals\n",
      "    Workflow Options:\n",
      "      --kin-maf 0.01 (as float)\n",
      "                        PLINK binary file\n",
      "  king_2:               Select a list of unrelated individual with an attempt to\n",
      "                        maximize the unrelated individuals selected from the\n",
      "                        data\n",
      "  king_3:               Split genotype data into related and unrelated samples,\n",
      "                        if related individuals are detected\n",
      "  qc_no_prune, qc_1:    Filter SNPs and select individuals\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.0 (as float)\n",
      "                        minimum MAF filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --maf-max-filter 0.0 (as float)\n",
      "                        maximum MAF filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --mac-filter 0.0 (as float)\n",
      "                        minimum MAC filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --mac-max-filter 0.0 (as float)\n",
      "                        maximum MAC filter to use. 0 means do not apply this\n",
      "                        filter.\n",
      "      --geno-filter 0.1 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.1 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 1e-15 (as float)\n",
      "                        HWE filter -- a very lenient one\n",
      "      --other-args  (as list)\n",
      "                        Other PLINK arguments e.g snps_only, write-samples, etc\n",
      "      --[no-]meta-only (default to False)\n",
      "                        Only output SNP and sample list, rather than the PLINK\n",
      "                        binary format of subset data\n",
      "      --[no-]rm-dups (default to False)\n",
      "                        Remove duplicate variants\n",
      "  qc_2:                 LD prunning and remove related individuals (both ind of\n",
      "                        a pair) Plink2 has multi-threaded calculation for LD\n",
      "                        prunning\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "                        Window size\n",
      "      --shift 10 (as int)\n",
      "                        Shift window every 10 snps\n",
      "      --r2 0.1 (as float)\n",
      "  genotype_phenotype_sample_overlap: This workflow extracts overlapping samples\n",
      "                        for genotype data with phenotype data, and output the\n",
      "                        filtered sample genotype list as well as sample\n",
      "                        phenotype list\n",
      "    Workflow Options:\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        A phenotype file, can be bed.gz or tsv\n",
      "      --sample-participant-lookup . (as path)\n",
      "                        If this file is provided, a genotype/phenotype sample\n",
      "                        name match will be performed It must contain two column\n",
      "                        names: genotype_id, sample_id\n"
     ]
    }
   ],
   "source": [
    "sos run GWAS_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-syntax",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path(\"output\")\n",
    "# A string to identify your analysis run\n",
    "parameter: name = \"\"\n",
    "# PLINK binary files\n",
    "parameter: genoFile = paths\n",
    "# The path to the file that contains the list of samples to remove (format FID, IID)\n",
    "parameter: remove_samples = path('.')\n",
    "# The path to the file that contains the list of samples to keep (format FID, IID)\n",
    "parameter: keep_samples = path('.')\n",
    "# The path to the file that contains the list of variants to keep\n",
    "parameter: keep_variants = path('.')\n",
    "# The path to the file that contains the list of variants to exclude\n",
    "parameter: exclude_variants = path('.')\n",
    "# Kinship coefficient threshold for related individuals\n",
    "# (e.g first degree above 0.25, second degree above 0.125, third degree above 0.0625)\n",
    "parameter: kinship = 0.0625\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-planner",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Estimate kinship in the sample\n",
    "\n",
    "The output is a list of related individuals, as well as the kinship matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-attitude",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Inference of relationships in the sample to identify closely related individuals\n",
    "[king_1]\n",
    "# PLINK binary file\n",
    "parameter: kin_maf = 0.01\n",
    "input: genoFile\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.kin0'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      --make-king-table \\\n",
    "      --king-table-filter ${kinship} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      --min-af ${kin_maf} \\\n",
    "      --max-af ${1-kin_maf} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} \n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(cat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(cat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-scholar",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a list of unrelated individual with an attempt to maximize the unrelated individuals selected from the data \n",
    "[king_2: shared = \"related_id\" ]\n",
    "related_id = [x.strip() for x in open(_input).readlines() if not x.startswith(\"#\")]\n",
    "output: f'{_input:n}.related_id'\n",
    "with open(_output, 'a'):\n",
    "    pass\n",
    "done_if(len(related_id) == 0, msg = f\"No related individuals detected from {_input}.\")\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R:  container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint=entrypoint\n",
    "\n",
    "    # By Rui Dong and Derek Lamb, Columbia Neurology\n",
    "    # This function enhances the standard plinkQC::relatednessFilter approach through:\n",
    "    #\n",
    "    # 1. Graph-based preprocessing:\n",
    "    #    - For large relatedness networks, breaks down dense clusters of related individuals\n",
    "    #    - Removes highly connected nodes (individuals with many relatives) first\n",
    "    #    - Prevents memory issues when processing large components (>20 individuals)\n",
    "    #    - Reduces the input size for the more intensive plinkQC filtering\n",
    "    #\n",
    "    # 2. Additional checks:\n",
    "    #    - Verifies that all related pairs are properly handled\n",
    "    #    - Runs up to 20 iterations to ensure complete filtering\n",
    "    #    - Catches edge cases that might be missed in a single pass\n",
    "    #\n",
    "    # This implementation is particularly helpful for datasets with large family \n",
    "    # clusters or complex relatedness structures where the standard approach\n",
    "    # might struggle.    \n",
    "\n",
    "    filter_relatedness <- function(\n",
    "      relatedness,                                  # Path to the relatedness file (required)\n",
    "      relatednessTh = 0.0625,                       # Threshold for relatedness\n",
    "      analysis_type = \"maximize_unrelated\",         # Type of analysis: \"maximize_unrelated\" or \"maximize_cases\"\n",
    "      output_prefix = \"output_prefix\",              # Base name for output file\n",
    "      otherCriterion = NULL,                        # Optional additional criterion for filtering\n",
    "      otherCriterionTh = NULL,                      # Threshold for the additional criterion\n",
    "      otherCriterionThDirection = \"ge\",             # Direction of the threshold\n",
    "      relatednessIID1 = \"IID1\",                     # Column name for first individual ID\n",
    "      relatednessIID2 = \"IID2\",                     # Column name for second individual ID\n",
    "      relatednessFID1 = NULL,                       # Column name for first family ID\n",
    "      relatednessFID2 = NULL,                       # Column name for second family ID\n",
    "      relatednessRelatedness = \"PI_HAT\",            # Column name for relatedness value\n",
    "      pheno_file = NULL,                            # File for phenotype information\n",
    "      pheno_col = \"pheno\",                          # Column name for phenotype\n",
    "      otherCriterionIID = \"IID\",                    # Column name for additional criterion ID\n",
    "      otherCriterionMeasure = NULL,                 # Column name for additional criterion measure\n",
    "      verbose = FALSE                               # Whether to print verbose output\n",
    "    ) {\n",
    "      # Load required packages\n",
    "      suppressMessages({\n",
    "        library(tidyverse)\n",
    "        library(igraph)\n",
    "        library(plinkQC)\n",
    "        library(data.table)\n",
    "      })\n",
    "      \n",
    "      # Validate inputs\n",
    "      if (is.null(relatedness)) {\n",
    "        stop(\"Relatedness file path is required\")\n",
    "      }\n",
    "      \n",
    "      if (analysis_type == \"maximize_cases\" && is.null(pheno_file)) {\n",
    "        stop(\"Must provide phenotype file when analysis_type is 'maximize_cases'\")\n",
    "      }\n",
    "      \n",
    "      # Read the relatedness file\n",
    "      full_kin0 <- fread(relatedness)\n",
    "      \n",
    "      # Initial pruning of highly related individuals\n",
    "      working_graph <- full_kin0 |>\n",
    "        filter(!!sym(relatednessRelatedness) >= relatednessTh) |>\n",
    "        select(!!sym(relatednessIID1), !!sym(relatednessIID2)) |>\n",
    "        graph_from_data_frame(directed = FALSE)\n",
    "      \n",
    "      working_comp <- components(working_graph)\n",
    "      \n",
    "      # Set parameters\n",
    "      graph_size_th = 20\n",
    "      reduce_fraction = 0.05\n",
    "      high_related_indiv <- c()\n",
    "      \n",
    "      # Reduce components to max 20\n",
    "      while (max(working_comp$csize > graph_size_th)) {\n",
    "        \n",
    "        if (verbose) {\n",
    "          print(paste0(\"The largest component graph has \", max(working_comp$csize), \n",
    "                       \" individuals. Removing the most connected \", \n",
    "                       scales::percent(reduce_fraction), \" of them.\"))\n",
    "        }\n",
    "        \n",
    "        # Prepare for loop\n",
    "        large_comp_ids <- which(working_comp$csize > graph_size_th)\n",
    "        nodes_to_remove <- c()\n",
    "        \n",
    "        for (comp_id in large_comp_ids) {\n",
    "          # Get nodes/degrees for component\n",
    "          comp_nodes <- V(working_graph)[working_comp$membership == comp_id]\n",
    "          comp_degrees <- degree(working_graph, v = comp_nodes)\n",
    "          \n",
    "          # Remove highly related individuals\n",
    "          num_to_remove <- ceiling(length(comp_nodes) * reduce_fraction)\n",
    "          high_degree_nodes <- names(sort(comp_degrees, decreasing = TRUE))[1:num_to_remove]\n",
    "          \n",
    "          # Append to removal list\n",
    "          nodes_to_remove <- c(nodes_to_remove, high_degree_nodes)\n",
    "        }\n",
    "        \n",
    "        # Update for next loop\n",
    "        high_related_indiv <- c(high_related_indiv, nodes_to_remove)\n",
    "        working_graph <- delete_vertices(working_graph, nodes_to_remove)\n",
    "        working_comp <- components(working_graph)\n",
    "      }\n",
    "      \n",
    "      kin0 <- full_kin0 |>\n",
    "        filter(!(!!sym(relatednessIID1) %in% high_related_indiv) & \n",
    "               !(!!sym(relatednessIID2) %in% high_related_indiv))\n",
    "      \n",
    "      # Process based on analysis type\n",
    "      if (analysis_type == \"maximize_unrelated\") {\n",
    "        # Run the plinkQC relatedness Filter\n",
    "        rel <- plinkQC::relatednessFilter(\n",
    "          relatedness = kin0,\n",
    "          otherCriterion = otherCriterion,\n",
    "          relatednessTh = relatednessTh,\n",
    "          relatednessIID1 = relatednessIID1,\n",
    "          relatednessIID2 = relatednessIID2,\n",
    "          otherCriterionTh = otherCriterionTh,\n",
    "          otherCriterionThDirection = otherCriterionThDirection,\n",
    "          relatednessFID1 = relatednessFID1,\n",
    "          relatednessFID2 = relatednessFID2,\n",
    "          relatednessRelatedness = relatednessRelatedness,\n",
    "          otherCriterionIID = otherCriterionIID,\n",
    "          otherCriterionMeasure = otherCriterionMeasure,\n",
    "          verbose = verbose\n",
    "        )$failIDs\n",
    "        \n",
    "        all_exclude <- rel$IID\n",
    "        \n",
    "      } else if (analysis_type == \"maximize_cases\") {\n",
    "        # Load phenotype information\n",
    "        related_individuals <- unique(c(kin0 |> pull(relatednessIID1), kin0 |> pull(relatednessIID2)))\n",
    "        \n",
    "        df_pheno <- fread(pheno_file) |>\n",
    "          drop_na(!!sym(pheno_col)) |>\n",
    "          filter(IID %in% related_individuals)\n",
    "        \n",
    "        # Match kinship and phenotype information\n",
    "        related_pheno_individuals <- df_pheno |> \n",
    "          pull(IID)\n",
    "        \n",
    "        related_cases <- df_pheno |> \n",
    "          filter(!!sym(pheno_col) == 1) |> \n",
    "          pull(IID)\n",
    "        \n",
    "        related_controls <- df_pheno |> \n",
    "          filter(!!sym(pheno_col) == 0) |> \n",
    "          pull(IID)\n",
    "        \n",
    "        kin0 <- kin0 |>\n",
    "          filter(!!sym(relatednessIID1) %in% related_pheno_individuals & \n",
    "                 !!sym(relatednessIID2) %in% related_pheno_individuals)\n",
    "        \n",
    "        # Optimize cases\n",
    "        df_case_kin <- kin0 |>\n",
    "          filter(!!sym(relatednessIID1) %in% related_cases & \n",
    "                 !!sym(relatednessIID2) %in% related_cases)\n",
    "        \n",
    "        rel_cases <- plinkQC::relatednessFilter(\n",
    "          relatedness = df_case_kin,\n",
    "          otherCriterion = otherCriterion,\n",
    "          relatednessTh = relatednessTh,\n",
    "          relatednessIID1 = relatednessIID1,\n",
    "          relatednessIID2 = relatednessIID2,\n",
    "          otherCriterionTh = otherCriterionTh,\n",
    "          otherCriterionThDirection = otherCriterionThDirection,\n",
    "          relatednessFID1 = relatednessFID1,\n",
    "          relatednessFID2 = relatednessFID2,\n",
    "          relatednessRelatedness = relatednessRelatedness,\n",
    "          otherCriterionIID = otherCriterionIID,\n",
    "          otherCriterionMeasure = otherCriterionMeasure,\n",
    "          verbose = verbose\n",
    "        )$failIDs\n",
    "        \n",
    "        # Remove controls related to cases\n",
    "        related_cases_keep <- setdiff(related_cases, rel_cases$IID)\n",
    "        \n",
    "        related_controls_exclude <- c()\n",
    "        \n",
    "        for (i in 1:nrow(kin0)) {\n",
    "          iid1 <- kin0 |> pull(!!sym(relatednessIID1)) |> nth(i) \n",
    "          iid2 <- kin0 |> pull(!!sym(relatednessIID2)) |> nth(i)\n",
    "          \n",
    "          if (iid1 %in% related_cases_keep & iid2 %in% related_controls) {\n",
    "            related_controls_exclude <- c(related_controls_exclude, iid2)\n",
    "            \n",
    "          } else if(iid2 %in% related_cases_keep & iid1 %in% related_controls) {\n",
    "            related_controls_exclude <- c(related_controls_exclude, iid1)\n",
    "            \n",
    "          }\n",
    "        }\n",
    "        \n",
    "        # Subset controls to only unrelated controls\n",
    "        related_controls_keep <- setdiff(related_controls, related_controls_exclude)\n",
    "        \n",
    "        df_control_kin <- kin0 |>\n",
    "          filter(!!sym(relatednessIID1) %in% related_controls_keep & \n",
    "                 !!sym(relatednessIID2) %in% related_controls_keep)\n",
    "        \n",
    "        rel_controls <- plinkQC::relatednessFilter(\n",
    "          relatedness = df_control_kin,\n",
    "          otherCriterion = otherCriterion,\n",
    "          relatednessTh = relatednessTh,\n",
    "          relatednessIID1 = relatednessIID1,\n",
    "          relatednessIID2 = relatednessIID2,\n",
    "          otherCriterionTh = otherCriterionTh,\n",
    "          otherCriterionThDirection = otherCriterionThDirection,\n",
    "          relatednessFID1 = relatednessFID1,\n",
    "          relatednessFID2 = relatednessFID2,\n",
    "          relatednessRelatedness = relatednessRelatedness,\n",
    "          otherCriterionIID = otherCriterionIID,\n",
    "          otherCriterionMeasure = otherCriterionMeasure,\n",
    "          verbose = verbose\n",
    "        )$failIDs\n",
    "        \n",
    "        # Handle leftover individuals\n",
    "        all_exclude <- c(rel_cases$IID, related_controls_exclude, rel_controls$IID)\n",
    "        \n",
    "      } else {\n",
    "        # Directly filter on kinship threshold\n",
    "        rel <- kin0 %>% dplyr::filter(!!sym(relatednessRelatedness) >= relatednessTh)\n",
    "        \n",
    "        all_exclude <- unique(c(rel |> pull(relatednessIID1), rel |> pull(relatednessIID2)))\n",
    "      }\n",
    "      \n",
    "      # Check for leftovers\n",
    "      df_related <- kin0 |>\n",
    "        filter(!(!!sym(relatednessIID1) %in% all_exclude) & \n",
    "               !(!!sym(relatednessIID2) %in% all_exclude)) |>\n",
    "        filter(!!sym(relatednessRelatedness) > relatednessTh)\n",
    "      \n",
    "      if (nrow(df_related) > 0) {\n",
    "        if (verbose) {\n",
    "          print(paste0(\"Warning: After first plinkQC pass, there are still \", \n",
    "                      nrow(df_related), \" related subjects in dataset.\"))\n",
    "        }\n",
    "        \n",
    "        # Iterate until all subjects are removed\n",
    "        iter <- 0\n",
    "        while (nrow(df_related) > 0 & iter < 20) {\n",
    "          # Rerun plinkQC\n",
    "          additional_exclude <- plinkQC::relatednessFilter(\n",
    "            relatedness = df_related,\n",
    "            otherCriterion = otherCriterion,\n",
    "            relatednessTh = relatednessTh,\n",
    "            relatednessIID1 = relatednessIID1,\n",
    "            relatednessIID2 = relatednessIID2,\n",
    "            otherCriterionTh = otherCriterionTh,\n",
    "            otherCriterionThDirection = otherCriterionThDirection,\n",
    "            relatednessFID1 = relatednessFID1,\n",
    "            relatednessFID2 = relatednessFID2,\n",
    "            relatednessRelatedness = relatednessRelatedness,\n",
    "            otherCriterionIID = otherCriterionIID,\n",
    "            otherCriterionMeasure = otherCriterionMeasure,\n",
    "            verbose = verbose\n",
    "          )$failIDs\n",
    "          \n",
    "          # Add to exclude list\n",
    "          all_exclude <- c(all_exclude, additional_exclude$IID)\n",
    "          \n",
    "          # Update df_related and iter\n",
    "          df_related <- kin0 |>\n",
    "            filter(!(!!sym(relatednessIID1) %in% all_exclude) & \n",
    "                   !(!!sym(relatednessIID2) %in% all_exclude)) |>\n",
    "            filter(!!sym(relatednessRelatedness) > relatednessTh)\n",
    "          iter <- iter + 1\n",
    "        }\n",
    "        \n",
    "        # Print status\n",
    "        if (verbose) {\n",
    "          if (nrow(df_related) == 0) {\n",
    "            print(paste0(\"All related subjects successfully removed after \", iter, \" iterations.\"))\n",
    "          } else if (nrow(df_related) > 0) {\n",
    "            stop(paste0(\"Error: After 20 plinkQC passes, there are still \", \n",
    "                       nrow(df_related), \" subjects in dataset.\"))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      # Add in high-related individuals\n",
    "      all_exclude <- c(all_exclude, high_related_indiv)\n",
    "      \n",
    "      # List of all excluded subjects\n",
    "      dat <- data.frame(IID = all_exclude, FID = as.character(all_exclude)) # Because IID and FID are the same\n",
    "      \n",
    "      # Output the related ids\n",
    "      output_related <- paste0(output_prefix, \"_kinship_cutoff_\", relatednessTh, \".related_id\")\n",
    "      write.table(dat, output_related, quote = FALSE, row.names = FALSE, col.names = FALSE)\n",
    "      \n",
    "      if (verbose) {\n",
    "        cat(\"\\n[INFO] There are\", nrow(dat), \"excluded individuals identified using a kinship threshold of\", relatednessTh, \"\\n\")\n",
    "        cat(\"[OUTPUT] Excluded individual IDs have been written to the file:\\n\")\n",
    "        cat(\"      \", normalizePath(output_related), \"\\n\")\n",
    "      }\n",
    "      \n",
    "      # Return the excluded IDs\n",
    "      return(dat)\n",
    "    }\n",
    "    \n",
    "  \n",
    "    # main code\n",
    "    suppressMessages({\n",
    "      library(tidyverse)\n",
    "      library(data.table)\n",
    "    })\n",
    "    \n",
    "    # Read input and set column names to match your original code\n",
    "    kin0 <- read.table(${_input:r}, header=FALSE, stringsAsFactors=FALSE)\n",
    "    colnames(kin0) <- c(\"FID1\",\"ID1\",\"FID2\",\"ID2\",\"NSNP\",\"HETHET\",\"IBS0\",\"KINSHIP\")\n",
    "    \n",
    "    # Always use the filter_relatedness function with maximize_unrelated\n",
    "    result <- filter_relatedness(\n",
    "      relatedness = kin0,  \n",
    "      relatednessTh = ${kinship},\n",
    "      analysis_type = \"maximize_unrelated\",\n",
    "      relatednessIID1 = \"ID1\",\n",
    "      relatednessIID2 = \"ID2\",\n",
    "      relatednessFID1 = \"FID1\", \n",
    "      relatednessFID2 = \"FID2\",\n",
    "      relatednessRelatedness = \"KINSHIP\",\n",
    "      verbose = FALSE\n",
    "    )\n",
    "    \n",
    "    # Format output to match your original code\n",
    "    tmp1 <- kin0[,1:2]\n",
    "    tmp2 <- kin0[,3:4]\n",
    "    colnames(tmp1) = colnames(tmp2) = c(\"FID\", \"ID\")\n",
    "    lookup <- dplyr::distinct(rbind(tmp1,tmp2))\n",
    "    dat <- lookup[which(lookup[,2] %in% result$IID),]\n",
    "    # Write output in the exact format of the original script\n",
    "    cat(\"There are\", nrow(dat), \"related individuals using a kinship threshold of ${kinship}\\n\")\n",
    "    write.table(dat, ${_output:r}, quote=FALSE, row.names=FALSE, col.names=FALSE)\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(cat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(cat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6)\n",
    "    \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-roommate",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Split genotype data into related and unrelated samples, if related individuals are detected\n",
    "[king_3]\n",
    "depends: sos_variable(\"related_id\")\n",
    "input: output_from(2), genoFile\n",
    "output: unrelated_bed = f'{cwd}/{_input[0]:bn}.unrelated.bed',\n",
    "        related_bed = f'{cwd}/{_input[0]:bn}.related.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --remove ${_input[0]} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[0]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "\n",
    "    if [ ${len(related_id)} -ne 0 ] ; then\n",
    "    plink2 \\\n",
    "      --bfile ${_input[1]:n} \\\n",
    "      --keep ${_input[0]} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output[1]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "    else\n",
    "       touch ${_output[1]}\n",
    "    fi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-malaysia",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype and sample QC\n",
    "\n",
    "QC the genetic data based on MAF, sample and variant missigness and Hardy-Weinberg Equilibrium (HWE).\n",
    "\n",
    "In this step you may also provide a list of samples to keep, for example in the case when you would like to subset a sample based on their ancestries to perform independent analyses on each of these groups.\n",
    "\n",
    "The default parameters are set to reflect some suggestions in Table 1 of [this paper](https://dx.doi.org/10.1002%2Fmpr.1608)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "requested-stanley",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[qc_no_prune, qc_1 (basic QC filters)]\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0.0\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# minimum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_filter = 0.0\n",
    "# maximum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_max_filter = 0.0 \n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter -- a very lenient one\n",
    "parameter: hwe_filter = 1e-15\n",
    "# Other PLINK arguments e.g snps_only, write-samples, etc\n",
    "parameter: other_args = []\n",
    "# Only output SNP and sample list, rather than the PLINK binary format of subset data\n",
    "parameter: meta_only = False\n",
    "# Remove duplicate variants\n",
    "parameter: rm_dups = False\n",
    "\n",
    "fail_if(not (keep_samples.is_file() or keep_samples == path('.')), msg = f'Cannot find ``{keep_samples}``')\n",
    "fail_if(not (keep_variants.is_file() or keep_variants == path('.')), msg = f'Cannot find ``{keep_variants}``')\n",
    "fail_if(not (remove_samples.is_file() or remove_samples == path('.')), msg = f'Cannot find ``{remove_samples}``')\n",
    "\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}{(\".\"+name) if name else \"\"}.plink_qc{\".extracted\" if keep_variants.is_file() else \"\"}{\".bed\" if not meta_only else \".snplist\"}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "      ${('--mac %s' % mac_filter) if mac_filter > 0 else ''} \\\n",
    "      ${('--max-mac %s' % mac_max_filter) if mac_max_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--exclude %s' % exclude_variants) if exclude_variants.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % keep_variants) if keep_variants.is_file() else \"\"} \\\n",
    "      ${('--make-bed') if not meta_only else \"--write-snplist --write-samples\"} \\\n",
    "      ${(\"\") if not rm_dups else \"--rm-dup force-first 'list'\"} \\\n",
    "      ${paths([\"--%s\" % x for x in other_args]) if other_args else \"\"} \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)/1e6} --new-id-max-allele-len 1000 --set-all-var-ids chr@:#_\\$r_\\$a \n",
    "        \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output:n}.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nuclear-semester",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning and remove related individuals (both ind of a pair)\n",
    "# Plink2 has multi-threaded calculation for LD prunning\n",
    "[qc_2 (LD pruning)]\n",
    "# Window size\n",
    "parameter: window = 50\n",
    "# Shift window every 10 snps\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "stop_if(r2==0)\n",
    "output: bed=f'{cwd}/{_input:bn}.prune.bed', prune=f'{cwd}/{_input:bn}.prune.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', entrypoint=entrypoint\n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[\"prune\"]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "   \n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output['prune']} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output['bed']:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e6}\n",
    "    \n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    i=\"${_output[0]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    printf \"output_info: %s\\noutput_size: %s\\n\" \"$i\" \"$output_size\" >> ${_output[0]:n}.stdout\n",
    "    i=\"${_output[1]}\"\n",
    "    output_size=$(ls -lh $i | cut -f 5 -d ' ')\n",
    "    output_rows=$(zcat $i | wc -l | cut -f 1 -d ' ')\n",
    "    output_column=$(zcat $i | head -1 | wc -w)\n",
    "    output_preview=$(cat $i | grep -v \"##\" | head | cut -f 1,2,3,4,5,6) \n",
    "    printf \"output_info: %s\\noutput_size: %s\\noutput_rows: %s\\noutput_column: %s\\noutput_preview:\\n%s\\n\" \\\n",
    "        \"$i\" \"$output_size\" \"$output_rows\" \"$output_column\" \"$output_preview\" >> ${_output[1]}.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-condition",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Extract genotype based on overlap with phenotype\n",
    "\n",
    "This is an auxiliary step to match genotype and phenotype based on the data and look-up table. The look up table should contain two columns: `sample_id`, `genotype_id`. If the look up table is not provided or look-up table file not found, then we will assume the names have already been matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-calibration",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This workflow extracts overlapping samples for genotype data with phenotype data, and output the filtered sample genotype list as well as sample phenotype list\n",
    "[genotype_phenotype_sample_overlap]\n",
    "# A genotype fam file\n",
    "parameter: genoFile = path\n",
    "# A phenotype file, can be bed.gz or tsv\n",
    "parameter: phenoFile = path\n",
    "# If this file is provided, a genotype/phenotype sample name match will be performed\n",
    "# It must contain two column names: genotype_id, sample_id\n",
    "parameter: sample_participant_lookup = path(\".\")\n",
    "depends: executable('tabix'), executable('bgzip')\n",
    "input: genoFile, phenoFile\n",
    "output: f'{cwd:a}/{path(_input[1]):bn}.sample_overlap.txt', f'{cwd:a}/{path(_input[1]):bn}.sample_genotypes.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(readr)\n",
    "    library(data.table)\n",
    "\n",
    "    # Read data files; let read_delim auto-determine the delimiter\n",
    "    genoFam <- fread(${_input[0]:ar}, header=FALSE)\n",
    "    phenoFile <- read_delim(${_input[1]:ar}, col_names=TRUE)\n",
    "    if (${\"TRUE\" if sample_participant_lookup.is_file() else \"FALSE\"}) {\n",
    "        sample_lookup <- fread(${sample_participant_lookup:ar}, header=TRUE)\n",
    "        colnames(sample_lookup) <- c(\"sample_id\", \"genotype_id\") # FIXME: This is for the old lookup table with columns c(\"sample_id\", \"participant_id\")\n",
    "        # rename phenotype file according to lookup file\n",
    "        colnames(phenoFile)[-c(1:4)] <- phenoFile %>%\n",
    "          colnames() %>%\n",
    "          .[-c(1:4)] %>%\n",
    "          match(sample_lookup$sample_id) %>%\n",
    "          sample_lookup$genotype_id[.]\n",
    "      output_file <- paste0(${phenoFile:nnr}, '.rename_sample.bed')\n",
    "      # rename phenotype file\n",
    "      phenoFile$start <- as.integer(phenoFile$start) \n",
    "      phenoFile$end <- as.integer(phenoFile$end) \n",
    "      fwrite(phenoFile, output_file, sep = '\\t')\n",
    "      # Compress the file using bgzip\n",
    "      system(paste(\"bgzip -c\", output_file, \">\", paste0(output_file, \".gz\")))\n",
    "      # Create the index file using tabix\n",
    "      system(paste(\"tabix -p bed\", paste0(output_file, \".gz\")))\n",
    "      system(paste(\"rm\", output_file))\n",
    "    } else {\n",
    "        sample_lookup <- cbind(genoFam[,2], genoFam[,2])\n",
    "        colnames(sample_lookup) <- c(\"genotype_id\", \"sample_id\")\n",
    "    }\n",
    "    sample_lookup <- sample_lookup %>%\n",
    "    filter(\n",
    "        genotype_id %in% genoFam$V2,\n",
    "        sample_id %in% colnames(phenoFile)\n",
    "    )\n",
    "    \n",
    "    genoFam %>%\n",
    "    filter(\n",
    "        V2 %in% sample_lookup$genotype_id,\n",
    "    ) %>%\n",
    "    select(V1, V2) %>%\n",
    "    fwrite(${_output[1]:r}, col.names=FALSE, sep=\"\\t\")\n",
    "\n",
    "    sample_lookup %>%\n",
    "    fwrite(${_output[0]:r}, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "0.22.4"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "sos",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "0.22.6"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "sos",
     "op": "patch"
    }
   ]
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
