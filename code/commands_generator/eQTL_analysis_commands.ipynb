{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-tonight",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Univariate xQTL Discovery\n",
    "\n",
    "This notebook provide a command generator on the XQTL workflow so it can automate the work for data preprocessing and association testing on multiple data collection as proposed. This version of command generator is suitable for bed file with sQTL and eQTL, the user should specify the input and the output in a recipe file, as documented below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85ba78-199e-4648-a65e-83e9ed7a4188",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This master control notebook is mainly to serve the 8 tissues snuc_bulk_expression analysis, but should be functional on all analysis where expression data are are a tsv table in a bed.gz like format.\n",
    "\n",
    "Input:\n",
    "\n",
    "    A recipe file,each row is a data collection and with the following column:\n",
    "    \n",
    "        Theme\n",
    "            name of dataset, must be different, each uni_study analysis will be performed in a folder named after each, meta analysis will be performed in a folder named as {study1}_{study2}\n",
    "            \n",
    "            The column name must contain the # and be the first column\n",
    "    \n",
    "        genotype_file\n",
    "            {Path to a whole genome genotype file}\n",
    "        \n",
    "        molecular_pheno\n",
    "            {Path to file}\n",
    "            \n",
    "        covariate_file\n",
    "            {Path to file}\n",
    "        \n",
    "        ### note: Only data collection from the same Populations and conditions will me merged to perform Fix effect meta analysis\n",
    "        \n",
    "    A genotype list, with two column, `#chr` and  `path`\n",
    "        \n",
    "        This can be generated by the genotype session of this command generator.\n",
    "     \n",
    "    \n",
    "Output:\n",
    "    \n",
    "    1 set of association_scan result for each tissue (each row in the recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f946-36ad-45fe-80ba-0c916aee48f0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Theme\":\"MWE\",\"molecular_pheno\":\"MWE.log2cpm.tsv\",\"genotype_file\":\"MWE.bed\",\"covariate_file\":\"MWE.covariate.cov.gz\"}).to_csv(\"/mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/MWE/command_generator\",sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b899d-8eb3-4f44-98a1-aa1308e35a9e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Theme      | molecular_pheno | genotype_file |covariate_file| phenotype_group |\n",
    "| ----------- | ----------- |-----------|----|-----| \n",
    "| eQTL      | MWE.log2cpm.bed.gz       | /data/genotype_data/GRCh38_liftedover_sorted_all.add_chr.leftnorm.filtered.bed |MWE.covariate.cov.gz|/data/genotype_data/GRCh38_liftedover_sorted_all.add_chr.leftnorm.filtered.phenotype_group |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-parliament",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93117226-1dca-48d6-8d51-cad1d9ce42c1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype\n",
    "The MWE for the genotype session can be ran with the following commands, please be noted that a [seperated MWE genoFile]( https://drive.google.com/file/d/1zaacRlZ63Nf_oEUv2nIiqekpQmt2EDch/view?usp=sharing) was needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e3725-9d4b-4ddd-adc5-e97fd198c45f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb plink_per_chrom \\\n",
    "    --ref_fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta    \\\n",
    "    --genoFile   mwe_genotype.vcf.gz  \\\n",
    "    --dbSNP_vcf  reference_data/00-All.vcf.gz \\\n",
    "    --sample_participant_lookup reference_data/sampleSheetAfterQC.txt -n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95ac0d-4286-4bf4-8659-138eccb71101",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Per tissue analysis\n",
    "A MWE for the core per tissue analysis can be ran with the following commands, a complete collection of input file as well as intermediate output of the analysis can be found at [here](https://drive.google.com/drive/folders/16ZUsciZHqCeeEWwZQR46Hvh5OtS8lFtA?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd30014-f864-49ab-93ed-0e6472febc48",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb sumstat_standardizer \\\n",
    "    --recipe MWE.recipe   \\\n",
    "    --genotype_list plink_files_list.txt      \\\n",
    "    --fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta     \\\n",
    "    --sample_participant_lookup reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"TensorQTL\"  -n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966eafe-c5cb-429d-bed7-9c1fd5bffc93",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    " sos run pipeline/eQTL_analysis_commands.ipynb sumstat_standardizer    \\\n",
    "    --recipe MWE.recipe    \\\n",
    "    --genotype_list plink_files_list.txt  \\\n",
    "    --fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta      \\\n",
    "    --sample_participant_lookup reference_data/sampleSheetAfterQC.txt    \\\n",
    "    --Association_option \"TensorQTL\" --cwd output2 --run  --yml \"\" --N 3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f13f55-79c9-44d6-b76f-6308fd341d33",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55877891-2e84-4c98-90b3-1f9ee3e24128",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb sumstat_merge \\\n",
    "    --recipe  MWE.recipe \\\n",
    "    --genotype_list plink_files_list.txt      \\\n",
    "    --annotation_gtf /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"APEX\"   -n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f8621-a660-4d70-a774-70ef6f6bc5a3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb factor \\\n",
    "    --recipe  /mnt/vast/hpc/csg/xqtl_workflow_testing/methyl/recipe_PCC_methylation \\\n",
    "    --annotation_gtf /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/vast/hpc/csg/xqtl_workflow_testing/methyl/Methylation_sample_list.tsv -n > Methylation_mqtl_script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589c9ad-3554-448e-bf88-9885a291bd1e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Protocol data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e00aeb-2918-459c-9494-407d3e734f80",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb plink_per_chrom \\\n",
    "    --ref_fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta    \\\n",
    "    --genoFile   input_data/Genotype/DEJ_11898_B01_GRM_WGS_2017-05-15_2*.recalibrated_variants.xqtl_protocol_data.add_chr.vcf.gz  \\\n",
    "    --dbSNP  reference_data/00-All.add_chr.variants.gz \\\n",
    "    --sample_participant_lookup reference_data/sample_participant_lookup.rnaseq --run --monitor --cwd output_rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa41a08-e307-45a9-8948-4a2c12a7b1ef",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    " sos run pipeline/eQTL_analysis_commands.ipynb sumstat_standardizer    \\\n",
    "    --recipe protocol_data.recipe    \\\n",
    "    --genotype_list output_rerun/data_preprocessing/genotype/xqtl_protocol_data.merged.filtered.plink_files_list.txt  \\\n",
    "    --fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta      \\\n",
    "    --sample_participant_lookup reference_data/sample_participant_lookup.rnaseq    \\\n",
    "    --Association_option \"TensorQTL\" --cwd output3 --run  --N 3    --cwd output_rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a4beb-de99-400d-9670-110bf3176e6d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b63746ef-7a60-432f-b8ae-4543c873ce57",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example for running the workflow\n",
    "This will run the workflow from via several submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b02e2-8cc6-4fd2-9624-b2b71ccfc28d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb sumstat_merge \\\n",
    "    --recipe  data/recipe_8tissue_new \\\n",
    "    --genotype_list data/genotype_qced/plink_files_list.txt      \\\n",
    "    --annotation_gtf data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"TensorQTL\"   -n &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f0969-213e-41a7-b0c1-a41a74b0b7c6",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run ~/GIT/xqtl-pipeline/pipeline/eQTL_analysis_commands.ipynb sumstat_merge  \\\n",
    "    --recipe  <(cat /mnt/vast/hpc/csg/snuc_pseudo_bulk//data/recipe_8tissue_new  | head -2)    \\\n",
    "    --genotype_list /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/genotype_qced/plink_files_list.txt      \\\n",
    "    --annotation_gtf /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --factor_option \"PEER\" --Association_option \"TensorQTL\"   -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-samuel",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "## The aforementioned input recipe\n",
    "parameter: recipe = path(\".\")  # Added option to run genotype part without the recipe input, which was not used.\n",
    "## Overall wd, the file structure of analysis is wd/[steps]/[sub_dir for each steps]\n",
    "parameter:  cwd = path(\"output\")\n",
    "## Diretory to the excutable\n",
    "parameter: exe_dir = path(\"~/GIT/xqtl-pipeline/\")\n",
    "parameter: container_base_bioinfo = 'containers/bioinfo.sif'\n",
    "parameter: container_apex = 'containers/apex.sif'\n",
    "parameter: container_PEER = 'containers/PEER.sif'\n",
    "parameter: container_TensorQTL = 'containers//TensorQTL.sif'\n",
    "parameter: container_rnaquant = 'containers/rna_quantification.sif'\n",
    "parameter: container_flashpca = 'containers/flashpcaR.sif'\n",
    "parameter: container_susie = 'containers/stephenslab.sif'\n",
    "parameter: phenotype_id_type = \"gene_name\" \n",
    "parameter: yml = path(\"csg.yml\")\n",
    "parameter: run = False\n",
    "parameter: monitor = False\n",
    "interpreter = 'cat' if not run else 'bash'\n",
    "import pandas as pd\n",
    "if recipe.is_file():\n",
    "    input_inv = pd.read_csv(recipe, sep = \"\\t\").to_dict(\"records\")\n",
    "import os\n",
    "parameter: jobs = 50 # Number of jobs that are submitted to the cluster\n",
    "parameter: queue = \"csg2\" # The queue that jobs are submitted to\n",
    "submission = f'-J {jobs} -c {yml} -q {queue}'\n",
    "parameter: mem = \"16G\"\n",
    "## Control of the workflow\n",
    "parameter: factor_option = \"PEER\"\n",
    "### Association scan option (APEX vs TensorQTL)\n",
    "parameter: Association_option = \"TensorQTL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-wrestling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data Preprocessing\n",
    "### Genotype Preprocessing (Once for all tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933a470-2e1e-4be5-b6a4-7598479e67cf",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee4fb6-5aed-4f05-8efd-1496110c2221",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[VCF_QC]\n",
    "parameter: genoFile = paths\n",
    "parameter: ref_fasta = path\n",
    "parameter: add_chr = True\n",
    "parameter: dbSNP = path\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/data_preprocessing/genotype/{_input[0]:bnn}.{\"add_chr.\" if  add_chr else False}leftnorm.filtered.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "       $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]//pipeline/VCF_QC.ipynb qc \\\n",
    "            --genoFile $[_input[0]] \\\n",
    "            --dbsnp-variants $[dbSNP] \\\n",
    "            --reference-genome $[ref_fasta] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --container $[container_base_bioinfo] \\\n",
    "            --walltime \"24h\" \\\n",
    "            $[submission if yml.is_file() else \"\" ] $[\"--add_chr\" if add_chr else \"--no-add_chr\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d256b89-1ea3-4d55-a98e-ccde9bf83d75",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_plink]\n",
    "parameter: genoFile = paths\n",
    "skip_if(len(genoFile) == 1)\n",
    "input: output_from(\"VCF_QC\"), group_by = \"all\"\n",
    "parameter: name = \"xqtl_protocol_data.merged\"\n",
    "output: f\"{cwd}/data_preprocessing/genotype//{name}.bed\"\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    " $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]//pipeline/genotype_formatting.ipynb merge_plink \\\n",
    "            --genoFile $[_input:r] \\\n",
    "            --cwd $[_output:d] --name $[name] \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9cf57-fcad-4168-b2ae-35d41068d553",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_QC]\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0\n",
    "# minimum MAC filter to use. 0 means do not apply this filter.\n",
    "parameter: mac_filter = 5\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 1e-06\n",
    "# MAC filter\n",
    "parameter: mac_filter = 5\n",
    "parameter: genoFile = paths\n",
    "\n",
    "input: (output_from(\"VCF_QC\") if len(genoFile) == 1 else output_from(\"merge_plink\"))\n",
    "output: f'{_input:n}.filtered.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "        $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]//pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --genoFile $[_input] \\\n",
    "            --maf-filter $[maf_filter] \\\n",
    "            --mac_filter $[0 if maf_filter else mac_filter] \\\n",
    "            --geno-filter $[geno_filter] \\\n",
    "            --mind-filter $[mind_filter] \\\n",
    "            --hwe-filter $[hwe_filter]   \\\n",
    "            --mem  $[mem]  \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166a329-38f2-4da4-84cd-c4e0a51c0059",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_per_chrom]\n",
    "input: output_from(\"plink_QC\")\n",
    "output: f'{cwd}/data_preprocessing//genotype/{_input:bn}.plink_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "        $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]//pipeline/genotype_formatting.ipynb plink_by_chrom \\\n",
    "            --genoFile $[_input] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --chrom  `cut -f 1  $[_input:n].bim  | uniq | sed \"s/chr//g\"` \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59112fda-4333-4210-8481-0eb11fd32d9d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_to_vcf]\n",
    "parameter: genotype_list = path\n",
    "input: genotype_list\n",
    "import pandas as pd\n",
    "parameter: genotype_file_name = pd.read_csv(_input,\"\\t\",nrows = 1).values.tolist()[0][1]\n",
    "output: f'{cwd}/data_preprocessing//genotype/{path(genotype_file_name):bnn}.vcf_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "        $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]//pipeline/genotype_formatting.ipynb plink_to_vcf \\\n",
    "            --genoFile $[_input] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c15b82-ca9e-4095-a634-0bba1eb85194",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[plink_per_gene]\n",
    "# The plink genotype file\n",
    "parameter: genoFile = path\n",
    "input: output_from(\"region_list_concat\"),genoFile\n",
    "output: f'{cwd}/data_preprocessing/genotype/{_input[1]:bn}.plink_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "        $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline//genotype_formatting.ipynb plink_by_gene \\\n",
    "            --genoFile $[_input[1]] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --region_list  $[_input[0]] \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee5311-3b75-4e5a-9269-716cbfcd901c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Molecular Phenotype Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dcb67-f366-41a1-b0ca-09bd4d293601",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[phenotype_partition_by_chrom]\n",
    "parameter: region_list = path() \n",
    "input: for_each = \"input_inv\"\n",
    "output: per_chrom_pheno_list = f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{path(_input_inv[\"molecular_pheno\"]):bn}.per_chrom.recipe'        \n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --phenoFile $[path(_input_inv[\"molecular_pheno\"]):a] \\\n",
    "        --region-list  $[region_list if region_list.is_file() else f'<(zcat {path(_input_inv[\"molecular_pheno\"]):a}  | cut -f 1,2,3,4)']  \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        $[f'--mem {mem}' if yml.is_file() else \"\" ]       $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-marking",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype Processing\n",
    "Since genotype is shared among the eight tissue, the QC of whole genome file is not needed. Only pca needed to be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acb9fc-b803-4939-80c9-32cec7308170",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sample_match]\n",
    "parameter: sample_participant_lookup = path\n",
    "input: for_each = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:bn}.filtered.txt',\n",
    "        geno = f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:bn}.filtered_geno.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/sample_matcher.ipynb filtered_sample_list \\\n",
    "        --cwd $[_output[0]:d]  \\\n",
    "        --phenoFile $[_input_inv[\"molecular_pheno\"]]  \\\n",
    "        --genoFile $[path(_input_inv[\"genotype_file\"]):n].fam  \\\n",
    "        --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        --translated_phenoFile $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df9826-b0b5-4c67-b52f-6f4e96a318cb",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[king]\n",
    "parameter: sample_participant_lookup = path\n",
    "parameter: maximize_unrelated = False\n",
    "input:output_from(\"sample_match\")[\"geno\"], group_with = \"input_inv\"\n",
    "output: related = f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.{_input_inv[\"Theme\"]}.related.bed',\n",
    "        unrelated = f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.{_input_inv[\"Theme\"]}.unrelated.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input_inv[\"genotype_file\"]] \\\n",
    "    --name $[_input_inv[\"Theme\"]] \\\n",
    "    --keep-samples $[_input] \\\n",
    "    --container $[container_base_bioinfo] \\\n",
    "    --walltime 48h  $[submission if yml.is_file() else \"\" ] $[\"--maximize_unrelated\" if maximize_unrelated else \"--no-maximize_unrelated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56d62f-a560-4802-9fd8-ded3ada60a93",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[unrelated_QC]\n",
    "input: output_from(\"king\")[\"unrelated\"]\n",
    "output: unrelated_bed = f'{_input:n}.filtered.prune.bed', \n",
    "        prune = f'{_input:n}.filtered.prune.in'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input] \\\n",
    "    --exclude-variants /mnt/vast/hpc/csg/snuc_pseudo_bulk/Ast/genotype/dupe_snp_to_exclude \\\n",
    "    --mac-filter 5 \\\n",
    "    --container $[container_base_bioinfo] \\\n",
    "    $[f'--mem {mem}' if yml.is_file() else \"\" ]   $[submission if yml.is_file() else \"\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109d434-a4f0-4543-b912-1f2e64b0c54a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[related_QC]\n",
    "input: output_from(\"king\")[\"related\"],output_from(\"unrelated_QC\")[\"prune\"]\n",
    "output: f'{_input[0]:n}.filtered.extracted.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input[0]] \\\n",
    "    --maf-filter 0 \\\n",
    "    --geno-filter 0 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe-filter 0 \\\n",
    "    --keep-variants $[_input[1]]  \\\n",
    "    --container $[container_base_bioinfo]  \\\n",
    "    $[f'--mem {mem}' if yml.is_file() else \"\" ]    $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-opening",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb7095-247e-44eb-aaa3-0f050c358b73",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca]\n",
    "input: output_from(\"unrelated_QC\")[\"unrelated_bed\"],group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.rds',\n",
    "        f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.scree.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/PCA.ipynb flashpca \\\n",
    "        --cwd $[_output:d] \\\n",
    "        --genoFile $[_input] \\\n",
    "        --container $[container_flashpca]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd276535-2566-4b17-b27d-27688e8c6ef7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[projected_sample]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"related_QC\"),output_from(\"pca\"), group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input[0]:bn}.pca.projected.rds',\n",
    "        f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input[0]:bn}.pca.projected.scree.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/PCA.ipynb project_samples \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --genoFile $[_input[0]] \\\n",
    "            --pca-model  $[_input[1]] \\\n",
    "            --maha-k `awk '$3 < $[PVE_treshold]' $[_input[2]] | tail -1 | cut -f 1  ` \\\n",
    "            --container $[container_flashpca]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589ea80-e69f-4d3b-8cb7-9ccf12f3af54",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_pca_covariate]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"projected_sample\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{path(_input_inv[\"covariate_file\"]):bn}.pca.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/covariate_formatting.ipynb merge_pca_covariate \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --pcaFile $[_input[0]:a] \\\n",
    "            --covFile  $[path(_input_inv[\"covariate_file\"])] \\\n",
    "            --tol_cov 0.3  \\\n",
    "            --k `awk '$3 < $[PVE_treshold]' $[_input[1]] | tail -1 | cut -f 1 ` \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ] --name $[_output:bn] --outliersFile $[_input[0]:an].outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e45bf9-eb9a-45b6-b3b5-d275f1821f03",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[resid_exp]\n",
    "input: output_from(\"merge_pca_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/resid_phenotype/{path(_input_inv[\"molecular_pheno\"]):bnn}.cov_pca.resid.bed.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"]  sos run $[exe_dir]/pipeline/covariate_formatting.ipynb compute_residual \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --phenoFile $[path(_input_inv[\"molecular_pheno\"]):a] \\\n",
    "            --covFile  $[_input[0]:a] \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ] --name $[_output:bnnn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-indianapolis",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[factor]\n",
    "parameter: N = 0\n",
    "input: output_from(\"resid_exp\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input[0]:bnn}.{factor_option}.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "         $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/Hidden_factor.ipynb $[factor_option] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --phenoFile $[_input[0]:a]  \\\n",
    "            --container $[container_apex if factor_option == \"BiCV\" else container_PEER]  \\\n",
    "            --walltime 24h \\\n",
    "            --numThreads 8 \\\n",
    "            --iteration 1000 \\\n",
    "            --N $[N]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbba48-5d7b-4217-93cc-8d91943ad45d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_factor_covariate]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"factor\"),output_from(\"merge_pca_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input[0]:bn}.cov.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.step_{step_name}.stderr', stdout = f'{_output}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/covariate_formatting.ipynb merge_factor_covariate \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --factorFile $[_input[0]:a] \\\n",
    "            --covFile  $[_input[1]:a] \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ] --name $[_output:bn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee34865-5d82-4c29-aa61-78d3f9051dbc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e6af-dec0-475e-aafc-4db2d43c1945",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL]\n",
    "# The number of minor allele count as treshold for the analysis\n",
    "parameter: MAC = 0\n",
    "# The minor allele frequency as treshold for the analysis, overwrite MAC\n",
    "parameter: maf_threshold = 0\n",
    "parameter: genotype_list = path\n",
    "parameter: cis_window = 1000000\n",
    "parameter: mem = \"50G\"\n",
    "input: genotype_list, output_from(\"phenotype_partition_by_chrom\"),output_from(\"merge_factor_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/association_scan/{_input_inv[\"Theme\"]}/TensorQTL/TensorQTL.cis._recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/TensorQTL.ipynb cis \\\n",
    "        --genotype-file $[_input[0]]   \\\n",
    "        --phenotype-file  $[_input[1]] \\\n",
    "        --region-list  <(cat $[_input[1]] | grep -v  \"\\.1\\.\" | grep -v chrX | grep -v chrY | grep -v chrM | cut -f 1,2,3,4 )  \\\n",
    "        --covariate-file $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --window $[cis_window] \\\n",
    "         $[submission if yml.is_file() else \"\" ] $[f'--mem {mem}' if yml.is_file() else \"\" ] \\\n",
    "         $[f'--MAC {MAC}' if MAC else \"\"]  \\\n",
    "         $[f'--maf_threshold {maf_threshold}' if maf_threshold else \"\"] \\\n",
    "         $[f'--phenotype_group {_input_inv[\"phenotype_group\"]}' if _input_inv[\"phenotype_group\"] else \"\" ] \\\n",
    "        --container $[container_TensorQTL]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2359b0-c9f2-4100-a26a-53820b8d4e12",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[APEX]\n",
    "parameter: genotype_list = path\n",
    "input: output_from(\"plink_to_vcf\"), output_from(\"phenotype_partition_by_chrom\"),output_from(\"merge_factor_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/association_scan/{_input_inv[\"Theme\"]}/APEX/APEX_QTL_recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/APEX.ipynb cis \\\n",
    "        --genotype-list $[_input[0]]   \\\n",
    "        --phenotype-list $[_input[1]] \\\n",
    "        --covariate-file $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --container $[container_apex] $[submission if yml.is_file() else \"\" ] --name $[_input[1]:bnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbcd80-8489-42e4-a77c-0c7429b0f171",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Trans Association Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5b683-ceb4-4ccf-a8db-a19bc1b5fcef",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_Trans]\n",
    "parameter: MAC = 0\n",
    "# The minor allele frequency as treshold for the analysis, overwrite MAC\n",
    "parameter: maf_threshold = 0\n",
    "parameter: genotype_list = path\n",
    "parameter: region_list = path\n",
    "input: genotype_list, output_from(\"phenotype_partition_by_chrom\"),output_from(\"merge_factor_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/association_scan/{_input_inv[\"Theme\"]}/Trans/TensorQTL.trans._recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/TensorQTL.ipynb trans \\\n",
    "        --genotype-list $[_input[0]]   \\\n",
    "        --phenotype-list $[_input[1]] \\\n",
    "        --covariate-file $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --region_list $[region_list] \\\n",
    "        --container $[container_TensorQTL] $[submission if yml.is_file() else \"\" ] $[f'--MAC {MAC}' if MAC else \"\"] $[f'--maf_threshold {maf_threshold}' if maf_threshold else \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43001652-ca24-4e9b-b124-14af22796cbe",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Sumstat Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d8716-e235-4834-ab86-66c04c0bcad2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[yml_generation]\n",
    "parameter: TARGET_list = path(\"./\")\n",
    "input: output_from(Association_option), group_by = \"all\"\n",
    "output: f'{cwd:a}/data_intergration/{Association_option}/qced_sumstat_list.txt',f'{cwd:a}/data_intergration/{Association_option}/yml_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.step_{step_name}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "        $[\"monitor.py\" if monitor else \"\"] sos run $[exe_dir]/pipeline/yml_generator.ipynb yml_list \\\n",
    "            --sumstat-list $[_input] \\\n",
    "            --cwd  $[_output[1]:d] --name $[\" \".join([str(x).split(\"/\")[-3] for x in _input])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12910c2b-22bf-4d55-a005-27838d8d90e6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[target_generation]\n",
    "parameter: fasta = \"reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta\"\n",
    "parameter: mem = \"50G\"\n",
    "input: output_from(\"yml_generation\")\n",
    "output: f'{_input[0]:d}/TARGET.ref.list'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{step_name}.step_{step_name}.stderr', stdout = f'{step_name}.stdout'\n",
    "      $[\"monitor.py\" if monitor else \"\"] sos run  $[exe_dir]/pipeline/summary_stats_standardizer.ipynb TARGET_generation  \\\n",
    "            --fasta $[fasta] \\\n",
    "            --sumstat-list $[_input[0]]    \\\n",
    "            --yml-list $[_input[1]]    \\\n",
    "            --cwd $[_input[0]:d]  $[submission if yml.is_file() else \"\" ] $[f'--mem {mem}' if yml.is_file() else \"\" ]  --walltime 48h --container $[container_base_bioinfo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02a8fa-c914-4d9d-bfda-54f368848546",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sumstat_standardizer]\n",
    "parameter: mem = \"50G\"\n",
    "input: output_from(\"yml_generation\"), output_from(\"target_generation\")\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{step_name}.step_{step_name}.stderr', stdout = f'{step_name}.stdout'\n",
    "      $[\"monitor.py\" if monitor else \"\"] sos run  $[exe_dir]/pipeline/summary_stats_standardizer.ipynb sumstat_standardization  \\\n",
    "            --sumstat-list $[_input[0]]    \\\n",
    "            --yml-list $[_input[1]]    \\\n",
    "            --TARGET_list $[_input[2]] \\\n",
    "            --cwd $[_input[0]:d]  $[submission if yml.is_file() else \"\" ] $[f'--mem {mem}' if yml.is_file() else \"\" ]  --walltime 48h --container $[container_base_bioinfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7603d3-e78e-46b2-adc1-66cc1cf339e4",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sumstat_to_vcf]\n",
    "parameter: mem = \"50G\"\n",
    "input: output_from(\"yml_generation\")\n",
    "depends: sos_step('sumstat_standardizer')\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{step_name}.step_{step_name}.stderr', stdout = f'{step_name}.stdout'\n",
    "      $[\"monitor.py\" if monitor else \"\"] sos run  $[exe_dir]/pipeline/summary_stats_standardizer.ipynb sumstat_to_vcf  \\\n",
    "            --sumstat-list $[_input[0]]    \\\n",
    "            --cwd $[_input[0]:d]  $[submission if yml.is_file() else \"\" ] $[f'--mem {mem}' if yml.is_file() else \"\" ]  --walltime 48h --container $[container_base_bioinfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45fc862-2b19-4b8c-b03d-4bd1a85deaf4",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[assoc_result_proc]\n",
    "input: output_from(\"yml_generation\")\n",
    "depends: sos_step('sumstat_to_vcf')\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{step_name}.step_{step_name}.stderr', stdout = f'{step_name}.stdout'\n",
    "    $[\"monitor.py\" if monitor else \"\"] sos run  $[exe_dir]/pipeline/assoc_result_processing.ipynb genome  \\\n",
    "        --vcf `ls $[_input[0]:d]/*/*cis_long_table.vcf` \\\n",
    "        --padjust-method \"bonferroni\"      \\\n",
    "        --container $[container_base_bioinfo] \\\n",
    "        $[f'--mem {mem}' if yml.is_file() else \"\" ]   $[submission if yml.is_file() else \"\" ] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
