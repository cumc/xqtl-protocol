{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-assist",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data formatting\n",
    "\n",
    "\n",
    "This module implements a collection of workflows used to format molecular phenotype data.\n",
    "\n",
    "\n",
    "\n",
    "## Input\n",
    "The input for this workflow is the collection of data for 1 conditions as described in the readme of this git repo\n",
    "1. 1 complete residual molecular_phenotype data\n",
    "2. 1 region_list\n",
    "Both of these input can be generated by the annotation module of this pipeline\n",
    "\n",
    "## Output\n",
    "For each collection, the output is \n",
    "1. 1 lists of phenotype file (bed+index) for each chrom, suitable to be fed into both apex and tensorQTL, annotated with chrom and pos\n",
    "2. 1 lists of phenotype file (bed+index) for each gene, annotated with chrom and tss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682274a-fb11-4de5-849f-8320188cb674",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67f860-4813-4882-8a53-bf1a4ba5a315",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting_modified.ipynb bam_to_fastq  \\\n",
    "    --phenoFile `ls /mnt/vast/hpc/csg/ftp_lisanwanglab_sync/ftp_fgc_xqtl/projects/rna-seq/knightadrc-washu/BAMfiles/03-DryLab/02-Data/03-RNASeq/01-bulkRNASeq/03-AnalysisReady/02-GRCh38/01-Brain/05-Requests/202212_Wang_data_request/*.bam | head -6` \\\n",
    "    --cwd /mnt/vast/hpc/csg/cl4215/ROSMAP/test  \\\n",
    "    --container /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_celltypes_analysis/SuSiE/containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-championship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output  \\\n",
    "    --phenoFile MWE.log2cpm.mol_phe.bed.gz \\\n",
    "    --region-list ROSMAP_PCC.methylation.M.renamed.region_list \\\n",
    "    --container containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e74e9-cc2f-4d37-8b47-6d02f9103748",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd mQTL_perchrom  \\\n",
    "    --phenoFile ROSMAP_arrayMethylation_covariates.sesame.methyl.beta.sample_matched.bed_BMIQ.bed.filter_na.bed.softImputed.bed.gz \\\n",
    "    --region-list ROSMAP_PCC.methylation.M.renamed.region_list \\\n",
    "    --container containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-silence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# The filename namefor output data\n",
    "parameter: container = ''\n",
    "\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# name for the analysis output\n",
    "parameter: name= f'{phenoFile:bn}'\n",
    "# Whether the input data is named by gene_id or gene_name. By default it is gene_id, if not, please change it to gene_name\n",
    "parameter: phenotype_id_type = 'gene_id'\n",
    "gene_name_as_phenotype_id = \"gene_name\" == phenotype_id_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0a8a6-a874-4c02-b007-142d96b860fe",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Region List generation\n",
    "\n",
    "To partitioning the data by genes require a region list file which:\n",
    "\n",
    "    1. have 5 columns: chr,start,end,gene_id,gene_name\n",
    "    2. have the same gene as or less gene than that of the bed file\n",
    "    \n",
    "Input:\n",
    "\n",
    "    1. A gtf file used to generated the bed\n",
    "    2. A phenotype bed file, must have a gene_id column indicating the name of genes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913f0bd-a40e-45ff-a5d1-77b99b5752dd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[generate_region_list]\n",
    "#  gene gtf annotation table\n",
    "parameter: annotation_gtf = path\n",
    "input: phenoFile, annotation_gtf\n",
    "output: f'{cwd}/{_input[0]:bnn}.region_list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    import pandas as pd\n",
    "    import qtl.io\n",
    "    # get the five column data\n",
    "    bed_template_df_id = qtl.io.gtf_to_tss_bed(${_input[1]:r}, feature='transcript',phenotype_id = \"gene_id\" )\n",
    "    bed_template_df_name = qtl.io.gtf_to_tss_bed(${_input[1]:r}, feature='transcript',phenotype_id = \"gene_name\" )\n",
    "    bed_template_df = bed_template_df_id.merge(bed_template_df_name, on = [\"chr\",\"start\",\"end\"])\n",
    "    bed_template_df.columns = [\"#chr\",\"start\",\"end\",\"gene_id\",\"gene_name\"]\n",
    "    pheno = pd.read_csv(${_input[0]:r}, sep = \"\\t\")\n",
    "    # Retaining only the genes in the data\n",
    "    region_list = bed_template_df[bed_template_df.${phenotype_id_type}.isin(pheno.gene_id)]\n",
    "    region_list.to_csv(\"${_output}\", sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-summit",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Process of molecular phenotype file\n",
    "This workflow produce a bed+tabix file for all the molecular pheno data that are included in the region list to feed into downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-tobacco",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_1]\n",
    "# An index text file with 4 columns specifying the chr, start, end and names of regions to analyze, can be made on fly with <(zcat {phenoFile}.bed.gz | cut -f 1,2,3,4 )\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"chrom\"\n",
    "output: f'{cwd}/{name}.{_chrom}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    tabix $[_input] $[_chrom] >> $[_output:n] \n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767d479-730c-4f76-ae4d-3af30bdde6f9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_2]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.per_chrom.recipe'\n",
    "import pandas as pd\n",
    "chrom = [str(x).split(\".\")[-3].replace(\"chr\",\"\") for x in _input]\n",
    "chrom_df = pd.DataFrame({\"#id\" : chrom ,\"#dir\" : _input})\n",
    "chrom_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-pollution",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_1]\n",
    "# An index text file with 5 columns specifying the chr, start, end and names of regions to analyze\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"regions\"\n",
    "output: f'{cwd}/{name}.{_regions[3]}.{_regions[4]}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    zcat $[_input] | grep  $[_regions[3] if gene_name_as_phenotype_id else _regions[4]] >> $[_output:n]\n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-abraham",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.per_gene.recipe'\n",
    "import pandas as pd\n",
    "region_df = pd.DataFrame({\"#id\" : [x[3] for x in regions] ,\"dir\" : _input})\n",
    "region_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cd129-66d3-4325-8cdf-8cf9a73114d6",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The resource usage for softimputing 450K methylation data are as followed:\n",
    "    \n",
    "time elapsed: 880.90s\n",
    "peak first occurred: 152.11s\n",
    "peak last occurred: 175.41s\n",
    "max vms_memory: 38.95GB\n",
    "max rss_memory: 34.35GB\n",
    "memory check interval: 1s\n",
    "return code: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7494e52-0954-48a5-86ee-9a518efa3c7f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bed_filter_na]\n",
    "parameter: rank_max = 50 # max rank estimated in the per-chr methyl matrix\n",
    "parameter: lambda_hyp = 30 # hyper par, indicating the importance of the nuclear norm\n",
    "parameter: impute_method = \"soft\"\n",
    "# Tolerance of missingness rows with missing rate larger than tol_missing will be removed,\n",
    "# with missing rate smaller than tol_missing will be mean_imputed. Say if we want to keep rows with less than 5% missing, then we use 0.05 as tol_missing.\n",
    "parameter: tol_missing = 0.05\n",
    "input: phenoFile\n",
    "output: f'{_input:nn}.filter_na.{impute_method}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "   library(\"dplyr\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(softImpute)\n",
    "   compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        soft_impute <- function(){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "  \n",
    "  \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return((X))\n",
    "        }  \n",
    "  \n",
    "    bed = read_delim(\"${_input}\")\n",
    "    mtx = bed[,5:ncol(bed)]%>%as.matrix\n",
    "    rownames(mtx) = bed[,4]%>%unlist()\n",
    "    tbl_filtered = filter_mtx(mtx%>%t(),${tol_missing})\n",
    "    if ( \"${impute_method}\" == \"mean\" ){\n",
    "    tbl_filtered = tbl_filtered%>%mean_impute()%>%t()\n",
    "     } else if (\"${impute_method}\" == \"soft\"){ \n",
    "      tbl_filtered_C= as(t(tbl_filtered),\"Incomplete\")\n",
    "      fit=softImpute(tbl_filtered_C,rank=${rank_max},lambda=${lambda_hyp},type=\"svd\")\n",
    "      tbl_filtered = complete(t(tbl_filtered),fit)\n",
    "    }\n",
    "    tbl_filtered = tbl_filtered%>%as_tibble(rownames = colnames(bed)[4])  \n",
    "    bed_filtered = inner_join(bed[,1:4],tbl_filtered)\n",
    "    bed_filtered%>%write_delim(\"${_output:n}\", \"\\t\" )\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f4f3-2384-47fa-8a97-846294b7001a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_subsetting]\n",
    "parameter: region = \"chr21 chr22\"\n",
    "input: phenoFile , group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.subsetted.bam'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    samtools view -b ${_input} ${region} > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab315733-53b9-4a2e-bbdd-7f86b1696684",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_to_fastq_1]\n",
    "input: phenoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:b}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container\n",
    "    cp ${_input}  ${cwd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d035d-02aa-4675-b765-b4ba0ad453f5",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_to_fastq_2]\n",
    "input: f'{cwd}/*.bam', group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.1.fastq',f'{cwd}/{_input:bn}.2.fastq'\n",
    "parameter: flist = f'{phenoFile:b}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container\n",
    "    samtools sort -n ${_input} -o ${_input}.sorted.bam\n",
    "    bedtools bamtofastq -i ${_input}.sorted.bam  -fq ${_output[0]} -fq2 ${_output[1]}\n",
    "    rm ${cwd}/*.bam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
