{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "usual-fancy",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data formatting\n",
    "\n",
    "This module implements a collection of workflows used to format molecular phenotype data.\n",
    "\n",
    "**FIXME: this entire pipeline needs to be improved**\n",
    "\n",
    "## Input\n",
    "The input for this workflow is the collection of data for 1 molecular phenotype as described in the format of:\n",
    "\n",
    "1. a complete residualized (covariates regressed out) molecular phenotype data \n",
    "2. a region list\n",
    "\n",
    "These input are outputs from previous pipelines such as `covariate_preprocessing` and `gene_annotation`.\n",
    "\n",
    "## Output\n",
    "\n",
    "1. A list of phenotype file (bed+index) for each chrom, annotated with genomic coordiates, suitable for TensorQTL analysis.\n",
    "2. 1 lists of phenotype file (bed+index) for each gene,  annotated with genomic coordiates, suitable for fine-mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-inspiration",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n",
    "\n",
    "**FIXME: these have to be updated to synapse links. Examples below also need updates**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-kansas",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output  \\\n",
    "    --phenoFile MWE.log2cpm.mol_phe.bed.gz \\\n",
    "    --region-list ROSMAP_PCC.methylation.M.renamed.region_list \\\n",
    "    --container containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-explosion",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd mQTL_perchrom  \\\n",
    "    --phenoFile ROSMAP_arrayMethylation_covariates.sesame.methyl.beta.sample_matched.bed_BMIQ.bed.filter_na.bed.softImputed.bed.gz \\\n",
    "    --region-list ROSMAP_PCC.methylation.M.renamed.region_list \\\n",
    "    --container containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capable-digit",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# The filename namefor output data\n",
    "parameter: container = ''\n",
    "parameter: entrypoint={('micromamba run -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# name for the analysis output\n",
    "parameter: name= f'{phenoFile:bn}'\n",
    "# Whether the input data is named by gene_id or gene_name. By default it is gene_id, if not, please change it to gene_name\n",
    "parameter: phenotype_id_type = 'gene_id'\n",
    "gene_name_as_phenotype_id = \"gene_name\" == phenotype_id_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-airplane",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Region List generation\n",
    "\n",
    "To partitioning the data by genes require a region list file which:\n",
    "\n",
    "    1. have 5 columns: chr,start,end,gene_id,gene_name\n",
    "    2. have the same gene as or less gene than that of the bed file\n",
    "    \n",
    "Input:\n",
    "\n",
    "    1. A gtf file used to generated the bed\n",
    "    2. A phenotype bed file, must have a gene_id column indicating the name of genes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-bahamas",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wanted-palace",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Process of molecular phenotype file\n",
    "This workflow produce a bed+tabix file for all the molecular pheno data that are included in the region list to feed into downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-tolerance",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_1]\n",
    "# An index text file with 4 columns specifying the chr, start, end and names of regions to analyze, can be made on fly with <(zcat {phenoFile}.bed.gz | cut -f 1,2,3,4 )\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"chrom\"\n",
    "output: f'{cwd}/{name}.{_chrom}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout',container = container, entrypoint=entrypoint\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    tabix $[_input] $[_chrom] >> $[_output:n] \n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | grep -v \"##\"   | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-affairs",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_2]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.per_chrom.recipe'\n",
    "import pandas as pd\n",
    "chrom = [str(x).split(\".\")[-3].replace(\"chr\",\"\") for x in _input]\n",
    "chrom_df = pd.DataFrame({\"#id\" : chrom ,\"#dir\" : _input})\n",
    "chrom_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-texture",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_1]\n",
    "# An index text file with 5 columns specifying the chr, start, end and names of regions to analyze\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"regions\"\n",
    "output: f'{cwd}/{name}.{_regions[3]}.{_regions[4]}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout',container = container, entrypoint=entrypoint\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    zcat $[_input] | grep  $[_regions[3] if gene_name_as_phenotype_id else _regions[4]] >> $[_output:n]\n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | grep -v \"##\"   | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-slovakia",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.per_gene.recipe'\n",
    "import pandas as pd\n",
    "region_df = pd.DataFrame({\"#id\" : [x[3] for x in regions] ,\"dir\" : _input})\n",
    "region_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-warren",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "FIXME: isn't it just the partition by gene code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-vegetation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_subsetting]\n",
    "parameter: region = \"chr21 chr22\"\n",
    "input: phenoFile , group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.subsetted.bam'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    samtools view -b ${_input} ${region} > ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-colorado",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "FIXME: This part should go to the rna-seq callign pipeine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-machinery",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_to_fastq]\n",
    "input: phenoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.1.fastq',f'{cwd}/{_input:bn}.2.fastq'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    samtools sort -n ${_input} -o ${_output[0]:nn}.sorted.bam\n",
    "    bedtools bamtofastq -i ${_output[0]:nn}.sorted.bam -fq ${_output[0]} -fq2 ${_output[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b518601",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract samples from expression data generated by RNASeQC\n",
    "[gct_extract_samples]\n",
    "parameter: phenoFile = path\n",
    "parameter: keep_samples = path\n",
    "input: phenoFile\n",
    "output: f'{_input[0]:nn}.sample_matched.gct.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"$[ ]\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout', container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    phenoFile = read_delim($[_input[0]:ar], \"\\t\", col_names = T, comment = \"#\")\n",
    "    sample_lookup = read_delim($[keep_samples:ar], \"\\t\" ,col_names = T, comment = \"#\")\n",
    "    ## Make phenoFile consistant with sampleLookup, remove samples by select()\n",
    "    int = intersect(colnames(phenoFile),unlist(sample_lookup[,1]))\n",
    "    phenoFile_tmp = phenoFile%>%select(c(colnames(phenoFile)[1],all_of(int)))\n",
    "    ## Add 2 header lines, https://github.com/getzlab/rnaseqc/blob/286f99dfd4164d33014241dd4f3149da0cddf5bf/src/RNASeQC.cpp#L426\n",
    "    cat(paste(\"#1.2\\n#\", nrow(phenoFile_tmp), ncol(phenoFile_tmp) - 2, \"\\n\"), file=$[_output:nr], append=FALSE)\n",
    "    phenoFile_tmp%>%write_delim($[_output:nr],delim = \"\\t\",col_names = T, append = T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
