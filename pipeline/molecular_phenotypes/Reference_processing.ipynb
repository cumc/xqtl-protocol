{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc1e773-7909-4e10-89f7-dd318a12439e",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Reference Processing\n",
    "This module will perform variouse proprocessing for reference data\n",
    "In Particular:\n",
    "1. Convert gff3 to gtf\n",
    "\n",
    "Input: an uncompressed gff3 file.(i.e. can be view via cat)\n",
    "\n",
    "Output: a gtf file.\n",
    "\n",
    "2. Produce gene collapesed version of gtf\n",
    "\n",
    "Input: a gtf file.\n",
    "\n",
    "Output: a gtf file with collapesed gene model.\n",
    "\n",
    "\n",
    "3. Generate STAR index based on gtf and reference fasta\n",
    "\n",
    "Input: a gtf file and an acompanying fasta file.\n",
    "\n",
    "Output: A folder of STAR index.\n",
    "\n",
    "\n",
    "4. Generate RSEM index based on gtf and reference fasta\n",
    "\n",
    "Input: a gtf file and an acompanying fasta file.\n",
    "\n",
    "Output: A folder of RSEM index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb23eaa-8248-4f1b-a1dc-88eb10051ee7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. MUST BE FULL PATH\n",
    "parameter: wd = path(\"./\")\n",
    "cwd = wd\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80531974-0b82-4405-890d-d2c1746edfec",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gff3_to_gtf]\n",
    "parameter: gff3_file = path\n",
    "input: gff3_file\n",
    "output: f'{wd}/{_input:n}.gtf'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_input[0]}.stderr', stdout = f'{_input[0]}.stdout'\n",
    "        gffread ${_input} -T -o ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfd858-f65f-4aae-bed2-441761459916",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Fasta Processing\n",
    "1. Remove the HLA/ALT/Decoy record from the fasta\n",
    "2. Adding in ERCC information to the fasta file\n",
    "3. Generating index for the fasta file\n",
    "\n",
    "### Example code\n",
    "\n",
    "Running following codes can run all the step for fasta processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fc475-9cd4-4821-9899-ef2b7d72fa42",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/molecular_phenotypes/Reference_processing.ipynb FASTA_index \\\n",
    "    --ERCC_fa /mnt/mfs/statgen/xqtl_workflow_testing/rna_quant_topmed/data/ERCC92.fa \\\n",
    "    --fasta  /mnt/mfs/statgen/xqtl_workflow_testing/rna_quant/data/GRCh38_full_analysis_set_plus_decoy_hla.fa \\\n",
    "    --container \"/mnt/mfs/statgen/containers/xqtl_pipeline_sif/rna_quantification.sif\" -s force &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155340ff-7e92-4883-891b-7b4455806683",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[HLA_removal]\n",
    "parameter: fasta = path\n",
    "input: fasta\n",
    "output:  f'{wd}/{_input:bn}.noALT_noHLA_noDecoy.fasta'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '30G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    with open('${_input}', 'r') as fasta:\n",
    "        contigs = fasta.read()\n",
    "        contigs = contigs.split('>')\n",
    "        contig_ids = [i.split(' ', 1)[0] for i in contigs]\n",
    "\n",
    "        # exclude ALT, HLA and decoy contigs\n",
    "        filtered_fasta = '>'.join([c for i,c in zip(contig_ids, contigs)\n",
    "        if not (i[-4:]=='_alt' or i[:3]=='HLA' or i[-6:]=='_decoy')])\n",
    "    \n",
    "    with open('${_output}', 'w') as fasta:\n",
    "        fasta.write(filtered_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1e5a6-33c2-4a84-b46a-bf82d94d8e65",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[FASTA_merge]\n",
    "parameter: ERCC_fa = path\n",
    "input: output_from(\"HLA_removal\")\n",
    "output: f'{wd}/{_input:bn}_ERCC.fasta'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    sed 's/ERCC-/ERCC_/g' ${ERCC_fa} >  ${ERCC_fa:n}.patched.fa\n",
    "    cat ${_input} ${ERCC_fa:n}.patched.fa > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74ead4-cff0-4c6a-83d8-178a86f25c87",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[FASTA_index]\n",
    "input: output_from(\"FASTA_merge\")\n",
    "output: f'{wd}/{_input:bn}.dict'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    samtools faidx ${_input}\n",
    "    java -jar /opt/picard-tools/picard.jar \\\n",
    "    CreateSequenceDictionary \\\n",
    "    R=${_input} \\\n",
    "    O=${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a51056-2ceb-4598-b5ee-b8e8d30ec8d1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### GTF Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271038a-d831-4fe2-b5e7-0d841655452e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This step modify the gtf file for following reason:\n",
    "1. RSEM require GTF input to have the same chromosome name format as the fasta file.\n",
    "\n",
    "**For STAR, this problem can be solved by the now commented --sjdbGTFchrPrefix \"chr\"  option**\n",
    "   \n",
    "2. collapse_annotation.py from GTEX require the gtf have transcript_type insteadd transcript_biotype in its annotation.\n",
    "**This problem can be solved by modifying the collapse_annotation.py while building the docker**\n",
    "\n",
    "Once the problem with RSEM is solved, or when RSEM is no longer needed, the aforementioned remedy can be implemented and this step can be remvoed\n",
    "\n",
    "3. Adding in ERCC information to the gtf\n",
    "\n",
    "### Example commands\n",
    "Running the following commands will generate the reformat version of annotation gtf and collapsed.gtf with ERCC addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d6d18-6197-4f78-b252-d0a84fc10624",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/molecular_phenotypes/Reference_processing.ipynb gtf_merge \\\n",
    "    --ERCC_gtf /mnt/mfs/statgen/xqtl_workflow_testing/rna_quant_topmed/data/ERCC92.gtf \\\n",
    "    --gtf  /mnt/mfs/statgen/xqtl_workflow_testing/rna_quant/data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --fasta  /mnt/mfs/statgen/xqtl_workflow_testing/rna_quant_topmed/data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta  \\\n",
    "    -s force &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32941265-117a-4e3b-b609-ddafa95b100d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[chrom_reformating]\n",
    "# Reference genome\n",
    "parameter: gtf = path\n",
    "parameter: fasta = path\n",
    "parameter: empty_rows = 5\n",
    "input: fasta, gtf\n",
    "output:  f'{wd}/{_input[1]:bn}.reformated.gtf'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '30G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    library(\"readr\")\n",
    "    library(\"stringr\")\n",
    "    library(\"dplyr\")\n",
    "    options(scipen = 999)\n",
    "    fasta = system(\"head -1 ${_input[0]}\",intern = TRUE)\n",
    "    gtf = read_delim(\"${_input[1]}\", col_names  = F,\"\\t\", skip = ${empty_rows})\n",
    "    if(!str_detect(fasta,\">chr\")){\n",
    "    gtf_mod = gtf%>%mutate(X1 = str_remove_all(X1,\"chr\"))\n",
    "    } else if(!any(str_detect(gtf$X1[1],\"chr\"))) {\n",
    "        gtf_mod = gtf%>%mutate(X1 = paste0(\"chr\",X1))    \n",
    "    }\n",
    "    if(str_detect(gtf_mod$X9,\"transcript_biotype\")){gtf_mod = gtf_mod%>%mutate(X9 = str_replace_all(X9,\"transcript_biotype\",\"transcript_type\"))}\n",
    "    gtf_mod%>%write.table(\"${_output}\",sep = \"\\t\",quote = FALSE,col.names = F,row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6d923-c5f3-415e-aa60-d7ef853d4f94",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[collapse]\n",
    "parameter: gtf = path\n",
    "parameter: collapse_only_switch = False\n",
    "input: gtf\n",
    "output: f'{wd}/{_input:bn}{\".collapse_only\" if collapse_only_switch else \"\"}.gene.gtf'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    collapse_annotation.py ${\"--collapse-only\" if collapse_only_switch else \"\"} ${_input} ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4881c42-0267-45dd-bcf3-2964c9cedbf0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ERCC_gtf]\n",
    "parameter: ERCC_gtf = path\n",
    "input: ERCC_gtf\n",
    "output: f'{wd}/{_input:bn}.genes.patched.gtf'\n",
    "python: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    with open('${_input}') as exon_gtf, open('${_output}', 'w') as gene_gtf:\n",
    "        for line in exon_gtf:\n",
    "            f = line.strip().split('\\t')\n",
    "            f[0] = f[0].replace('-','_')  # required for RNA-SeQC/GATK (no '-' in contig name)\n",
    "        \n",
    "            attr = f[8]\n",
    "            if attr[-1]==';':\n",
    "                attr = attr[:-1]\n",
    "            attr = dict([i.split(' ') for i in attr.replace('\"','').split('; ')])\n",
    "            # add gene_name, gene_type\n",
    "            attr['gene_name'] = attr['gene_id']\n",
    "            attr['gene_type'] = 'ercc_control'\n",
    "            attr['gene_status'] = 'KNOWN'\n",
    "            attr['level'] = 2\n",
    "            for k in ['id', 'type', 'name', 'status']:\n",
    "                attr['transcript_'+k] = attr['gene_'+k]\n",
    "        \n",
    "            attr_str = []\n",
    "            for k in ['gene_id', 'transcript_id', 'gene_type', 'gene_status', 'gene_name',\n",
    "                'transcript_type', 'transcript_status', 'transcript_name']:\n",
    "                attr_str.append('{0:s} \"{1:s}\";'.format(k, attr[k]))\n",
    "            attr_str.append('{0:s} {1:d};'.format('level', attr['level']))\n",
    "            f[8] = ' '.join(attr_str)\n",
    "        \n",
    "            # write gene, transcript, exon\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['gene']+f[3:])+'\\n')\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['transcript']+f[3:])+'\\n')\n",
    "            f[8] = ' '.join(attr_str[:2])\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['exon']+f[3:])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd91b4c-ff5d-465c-ac6f-6b9ab45eaebe",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gtf_merge]\n",
    "parameter: gtf\n",
    "input:  output_from(\"chrom_reformating\") ,output_from(\"collapse\"),output_from(\"ERCC_gtf\")\n",
    "output: f'{wd}/{_input[0]:bn}.ERCC.gtf', f'{wd}/{_input[1]:bn}.ERCC.gtf'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    cat ${_input[0]} ${_input[2]} > ${_output[0]}\n",
    "    cat ${_input[1]} ${_input[2]} > ${_output[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947063b-eb0d-4a93-9824-b19fc3cc5b8b",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Generating indexing file for `STAR` \n",
    "This step generate the indexing file for STAR alignment. This file just need to generate once and can be re-used. \n",
    "\n",
    "At least 40GB of memory is needed\n",
    "### Step Inputs:\n",
    "* `STAR_index_dir`: a path to the output.\n",
    "* `gtf` and `fasta`: path to reference sequence. Both of them needs to be unzipped\n",
    "* `sjdbOverhang`: specifies the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. Ideally, this length should be equal to the ReadLength-1, where ReadLength is the length of the reads.\n",
    "\n",
    "### Step Output:\n",
    "* Indexing file stored in `STAR_index_dir`, which will be used by `STAR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d89c7b-2fd8-487f-b3e0-5557b7508f8b",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[STAR_indexing]\n",
    "\n",
    "# The directory for STAR index\n",
    "# Reference genome\n",
    "parameter: gtf = path\n",
    "parameter: fasta = path\n",
    "\n",
    "# Length:\n",
    "parameter: sjdbOverhang = 150\n",
    "input: fasta, gtf\n",
    "output: f'{wd}/STAR_Index/genomeParameters.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_input[0]}.stderr', stdout = f'{_input[0]}.stdout'\n",
    "    STAR --runMode genomeGenerate \\\n",
    "         --genomeDir ${_output:d} \\\n",
    "         --genomeFastaFiles ${_input[0]} \\\n",
    "         --sjdbGTFfile ${_input[1]} \\\n",
    "         --sjdbOverhang ${sjdbOverhang} \\\n",
    "         --runThreadN ${numThreads} #--sjdbGTFchrPrefix \"chr\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccf674-bd36-4f51-ae04-9d9b293932fb",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Generating indexing file for `RSEM`\n",
    "This step generate the indexing file for `RSEM`. This file just need to generate once.\n",
    "\n",
    "### Step Inputs:\n",
    "\n",
    "* `RSEM_index_dir`: a path to the output.\n",
    "* `gtf` and `fasta`: path to reference sequence.\n",
    "* `sjdbOverhang`: specifies the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. Ideally, this length should be equal to the ReadLength-1, where ReadLength is the length of the reads.\n",
    "\n",
    "### Step Outputs:\n",
    "* Indexing file stored in `RSEM_index_dir`, which will be used by `RSEM`\n",
    "\n",
    "### Example Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8529a-eb35-4722-96ca-dfba23726b82",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a7d73-8daf-4f3c-9185-ca6f07d7987e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[RSEM_indexing]\n",
    "# Output directory:\n",
    "\n",
    "# Reference genome\n",
    "parameter: gtf = path\n",
    "parameter: fasta = path\n",
    "parameter: name = str\n",
    "input: fasta, gtf\n",
    "output: f'{wd}/RSEM_Index/rsem_reference.idx.fa'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_input[0]}.stderr', stdout = f'{_input[0]}.stdout'\n",
    "    rsem-prepare-reference \\\n",
    "            ${_input[0]} \\\n",
    "            ${_output:nn} \\\n",
    "            --gtf ${_input[1]} \\\n",
    "            --num-threads ${numThreads}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
