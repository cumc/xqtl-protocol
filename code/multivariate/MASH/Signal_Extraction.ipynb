{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superior-regard",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Top signal extraction\n",
    "This notebook is to extract strong and random signals from the sumstat rds of each of the gene so that they can be fed into flashr for mixture prior and mashr.\n",
    "\n",
    "At th momenet,      \n",
    "\n",
    "1. the NA sumstat  will be removed\n",
    "\n",
    "2. nan beta will be set to 0 \n",
    "\n",
    "3. nan and infinit sumstat will be set to 1E3 \n",
    "      \n",
    "4. nan treatment( 2 and 3 ). are based on the original design in bioworkflow/mixture_prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-korean",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reported-ballet",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-embassy",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./output')\n",
    "# The filename prefix for output data\n",
    "parameter: name = str\n",
    "parameter: job_size = 1\n",
    "parameter: container = 'gaow/twas'\n",
    "parameter: table_name = \"\"\n",
    "parameter: bhat = \"bhat\"\n",
    "parameter: sbhat = \"sbhat\"\n",
    "parameter: expected_ncondition = 0\n",
    "## 1 condition can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = 0\n",
    "parameter: datadir = \"\"\n",
    "parameter: seed = 999\n",
    "parameter: n_random = 4\n",
    "parameter: n_null = 4\n",
    "parameter: z_only = False\n",
    "# Analysis units file. For RDS files it can be generated by `ls *.rds | sed 's/\\.rds//g' > analysis_units.txt`\n",
    "parameter: analysis_units = path\n",
    "# handle N = per_chunk data-set in one job\n",
    "parameter: per_chunk = 1000\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-warrant",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Get top, random and null effects per analysis unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-chassis",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract data for MASH from summary stats\n",
    "[extract_effects_1]\n",
    "input: regions , group_by = per_chunk\n",
    "output: f\"{cwd}/{name}/cache/{name}_{_index+1}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    set.seed(${seed})\n",
    "    matxMax <- function(mtx) {\n",
    "      return(arrayInd(which.max(mtx), dim(mtx)))\n",
    "    }\n",
    "    remove_rownames = function(x) {\n",
    "        for (name in names(x)) rownames(x[[name]]) = NULL\n",
    "        return(x)\n",
    "    }\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    extract_one_data = function(dat, n_random, n_null, infile) {\n",
    "        if (is.null(dat)) return(NULL)\n",
    "        na.info = list()\n",
    "        na.info$n_bhat_ori = nrow(dat$${bhat})\n",
    "        dat$bhat = na.omit(dat$${bhat})\n",
    "        na.info$n_bhat = nrow(dat$${bhat})\n",
    "        na.info$n_sbhat_ori = nrow(dat$${sbhat})\n",
    "        dat$sbhat = na.omit(dat$${sbhat})\n",
    "        na.info$n_sbhat_ori = nrow(dat$${sbhat})\n",
    "        msg = paste(c(\"Out of \",na.info$n_bhat_ori,\" SNP, \",na.info$n_bhat,\" was retained for analysis\"), collapse = \"\")\n",
    "        message(msg)\n",
    "        z = abs(dat$${bhat}/dat$${sbhat})\n",
    "        max_idx = matxMax(z)\n",
    "        if (is.null(max_idx)) return(NULL)\n",
    "        # strong effect samples\n",
    "        strong = list(bhat = dat$${bhat}[max_idx[1],,drop=F], sbhat = dat$${sbhat}[max_idx[1],,drop=F])\n",
    "        # random samples excluding the top one\n",
    "        if (max_idx[1] == 1) {\n",
    "            sample_idx = 2:nrow(z)\n",
    "        } else if (max_idx[1] == nrow(z)) {\n",
    "            sample_idx = 1:(max_idx[1]-1)\n",
    "        } else {\n",
    "            sample_idx = c(1:(max_idx[1]-1), (max_idx[1]+1):nrow(z))\n",
    "        }\n",
    "        random_idx = sample(sample_idx, min(n_random, length(sample_idx)), replace = F)\n",
    "        random = list(bhat = dat$${bhat}[random_idx,,drop=F], sbhat = dat$${sbhat}[random_idx,,drop=F])\n",
    "        # null samples defined as |z| < 2\n",
    "        null.id = which(apply(abs(z), 1, max) < 2)\n",
    "        if (length(null.id) == 0) {\n",
    "          warning(paste(\"Null data is empty for input file\", infile))\n",
    "          null = list()\n",
    "        } else {\n",
    "          null_idx = sample(null.id, min(n_null, length(null.id)), replace = F)\n",
    "          null = list(bhat = dat$${bhat}[null_idx,,drop=F], sbhat = dat$${sbhat}[null_idx,,drop=F])\n",
    "        }\n",
    "        dat = (list(random = remove_rownames(random), null = remove_rownames(null), strong = remove_rownames(strong)))\n",
    "        dat$random = handle_nan_etc(dat$random)\n",
    "        dat$null = handle_nan_etc(dat$null)\n",
    "        dat$strong = handle_nan_etc(dat$strong)\n",
    "        return(dat)\n",
    "    }\n",
    "    reformat_data = function(dat, z_only = TRUE) {\n",
    "        # make output consistent in format with \n",
    "        # https://github.com/stephenslab/gtexresults/blob/master/workflows/mashr_flashr_workflow.ipynb      \n",
    "        res = list(random.z = dat$random$bhat/dat$random$sbhat, \n",
    "                  strong.z = dat$strong$bhat/dat$strong$sbhat,  \n",
    "                  null.z = dat$null$bhat/dat$null$sbhat)\n",
    "        if (!z_only) {\n",
    "          res = c(res, list(random.b = dat$random$bhat,\n",
    "           strong.b = dat$strong$bhat,\n",
    "           null.b = dat$null$bhat,\n",
    "           null.s = dat$null$sbhat,\n",
    "           random.s = dat$random$sbhat,\n",
    "           strong.s = dat$strong$sbhat))\n",
    "      }\n",
    "      return(res)\n",
    "    }\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else if (is.null(one_data)) {\n",
    "          return(res)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            if (is.null(one_data[[d]])) {\n",
    "              next\n",
    "            } else {\n",
    "                res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "            }\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    res = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      # If cannot read the input for some reason then we just skip it, assuming we have other enough data-sets to use.\n",
    "      dat = tryCatch(readRDS(f), error = function(e) return(NULL))${(\"$\"+table_name) if table_name != \"\" else \"\"}\n",
    "      if (is.null(dat)) {\n",
    "          message(paste(\"Skip loading file\", f, \"due to load failure.\"))\n",
    "          next\n",
    "      }\n",
    "      if (${expected_ncondition} > 0 && (ncol(dat$${bhat}) != ${expected_ncondition} || ncol(dat$${sbhat}) != ${expected_ncondition})) {\n",
    "          message(paste(\"Skip loading file\", f, \"because it has\", ncol(dat$${bhat}), \"columns different from required\", ${expected_ncondition}))\n",
    "          next\n",
    "      }\n",
    "      if(${exclude_condition} > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\")\n",
    "      dat$bhat = dat$bhat[,-${exclude_condition}]\n",
    "      dat$sbhat = dat$sbhat[,-${exclude_condition}]\n",
    "      dat$Z = dat$Z[,-${exclude_condition}]\n",
    "        )\n",
    "\n",
    "  \n",
    "      res = merge_data(res, reformat_data(tryCatch( extract_one_data(dat, ${n_random}, ${n_null}, f)  , error = function(e) return(NULL)) , ${\"TRUE\" if z_only else \"FALSE\"}))\n",
    "    }\n",
    "      \n",
    "    saveRDS(res, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-offer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-premium",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[extract_effects_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container,stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f'{cwd:ad}:{cwd:ad}']\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    # compute empirical covariance XtX\n",
    "    X = dat$strong.z\n",
    "    X[is.na(X)] = 0\n",
    "    dat$XtX = t(as.matrix(X)) %*% as.matrix(X) / nrow(X)\n",
    "    saveRDS(dat, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
