{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "played-nicholas",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Summary statistics merger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fc526-6783-4005-b1b4-c50077170565",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a30f7f-95ec-4121-b277-a14e4a18ede8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "- 1.To merge multiple summary statistic files to new summary statistic files with common SNPs\n",
    "- 2.To deal with allele flip and reserve issues in the process of merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc489ee3-b68d-4f72-89ff-6dde1f36bbf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "Make sure you install the pre-requisited before running this notebook:\n",
    "\n",
    "```\n",
    "pip install Biopython\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795fea6-7083-4404-947f-e3b9cb1e7b6c",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "- `--cwd`, the path of output directory\n",
    "- `--yml_path`, the path of yaml file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e3b9b-7ffa-43fb-b369-743c90334d32",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### The format of the input yaml file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2f5c9-7e17-41db-8884-83783b87c89a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "INPUT:\n",
    "  - ./data/testflip/*.gz:\n",
    "        CHR: CHR\n",
    "        POS: POS\n",
    "        A0: REF\n",
    "        A1: ALT\n",
    "        SNP: SNP\n",
    "        STAT: BETA\n",
    "        SE: SE\n",
    "        P: P\n",
    "  - ./data/testflip/flip/snps500_flip.regenie.snp_stats.gz:\n",
    "  \n",
    "TARGET: \n",
    "  - ./data/testflip/snps500.regenie.snp_stats.gz:\n",
    "        CHR: CHR\n",
    "        POS: POS\n",
    "        A0: REF\n",
    "        A1: ALT\n",
    "        SNP: SNP\n",
    "        STAT: BETA\n",
    "        SE: SE\n",
    "        P: P\n",
    "OUTPUT: data/testflip/output/\n",
    "KEEP_AMBIGUOUS: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a08c1-c7a4-4272-bc0a-08f34a9da381",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "There are four parts in the input yaml file.\n",
    "- INPUT\n",
    "   - A list of yml file, as the output from yml_generator, each yml file documents a set of input\n",
    "       - the input summary statistic files with the column names in below. \n",
    "       - the input files can be from multiple directory and from different format. The input paths must follow the rules related to Unix shell. the format is to pair the column names with keys (CHR, POS, A0, A1, SNP, STAT, SE, P). if not provided, the column names of the input file will be considered as the default keys.\n",
    "       - The input summary statistic file cannot have duplicated chr:pos\n",
    "       - The input summary statstic file cannot have # in its header\n",
    "- TARGET\n",
    "   - the reference summary statistic file, which the other files compare with.\n",
    "- OUTPUT\n",
    "   - the path of an output directory for new summary statistic files\n",
    "   - for each input sumstat file, a qced version will be generated.\n",
    "   - The generated sumstat files will have header as \"CHR  ,   POS  ,   A0   ,   A1    ,  SNP   ,  STAT ,   SE    ,  P\" regardless of input header\n",
    "   - The generated sumstat files will be in gz format.\n",
    "- KEEP_AMBIGUOUS\n",
    "   - if Ture, keep ambiguous alleles which can not be decided from flip or reverse, such as A/T or C/G. Otherwise, remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c9eb3-55d8-4f32-8cc3-67105cfe4831",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "new summary statistic files with common SNPs in all input files. the sign of statistics has been corrected to make it consistent in different data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bfe8a-dcf4-47d8-b4c7-9f582003d222",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab31ad-7374-4231-ae04-a9444c438833",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "```\n",
    "sos run ./summary_stats_merger.ipynb --cwd data --yml_path data/template.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-rainbow",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory where output will be saved to\n",
    "parameter: cwd = path\n",
    "## path to a list of yml file , with columns #chr and dir\n",
    "parameter: yml_list = path\n",
    "import pandas as pd\n",
    "yml_path = pd.read_csv(yml_list,sep = \"\\t\").values.tolist()\n",
    "# Path to work directory where the yaml file locates\n",
    "#parameter: yml_path = path(\".\")\n",
    "# Containers that contains the necessary packages\n",
    "parameter: container = str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003c566-e58f-401d-8e33-5847af8d8241",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflow codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "88cdb2f7-f129-4e9f-af44-06bf51357c7a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_1 (export utils script)]\n",
    "depends: Py_Module('pandas'), Py_Module('yaml'), Py_Module('glob'), Py_Module('Bio')\n",
    "output: f'{cwd:a}/utils.py'\n",
    "report: expand = '${ }', output=f'{cwd:a}/utils.py'\n",
    "    import os\n",
    "    import yaml\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    from Bio.Seq import Seq\n",
    "\n",
    "    def merge_sumstats(yml):\n",
    "        #parse yaml\n",
    "        yml = load_yaml(yml)\n",
    "        input_dict = parse_input(yml['INPUT'])\n",
    "        target_dict = parse_input(yml['TARGET'])\n",
    "        output_path = yml['OUTPUT']\n",
    "        keep_ambiguous = yml['KEEP_AMBIGUOUS']\n",
    "        input_dict[list(target_dict.keys())[0]] = list(target_dict.values())[0]\n",
    "        lst_sumstats_file = [os.path.basename(i) for i in input_dict.keys()]\n",
    "        print('Total number of sumstats: ',len(lst_sumstats_file))\n",
    "        if len(set(lst_sumstats_file))<len(lst_sumstats_file):\n",
    "            raise Exception(\"There are duplicated names in \", lst_sumstats_file)\n",
    "        #read all sumstats\n",
    "        print(input_dict)\n",
    "        lst_sumstats = {os.path.basename(i):read_sumstat(i,j) for i,j in input_dict.items()}\n",
    "        nqs = []\n",
    "        for query in lst_sumstats.values():\n",
    "            nq,_ = snps_match(query,lst_sumstats[os.path.basename(list(target_dict.keys())[0])],keep_ambiguous)\n",
    "            nqs.append(nq)\n",
    "        #get common snps\n",
    "        common_snps = set.intersection(*[set(nq.SNP) for nq in nqs])\n",
    "        print('Total number of common SNPs: ',len(common_snps))\n",
    "        #write out new smustats\n",
    "        for output_sumstats,nq in zip(lst_sumstats_file,nqs):\n",
    "            sumstats = nq[nq.SNP.isin(common_snps)]\n",
    "            sumstats.to_csv(os.path.join(output_path, output_sumstats), sep = \"\\t\", header = True, index = False,compression='gzip')\n",
    "        print('All are done!!!')\n",
    "\n",
    "    def load_yaml(yaml_file):\n",
    "        with open(yaml_file, \"r\") as stream:\n",
    "            try:\n",
    "                yml = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "        return yml\n",
    "\n",
    "    def parse_input(yml_input):\n",
    "        input_dict = {}\n",
    "        for i in yml_input:\n",
    "            for name in glob.glob(list(i.keys())[0]):\n",
    "                input_dict[name] = list(i.values())[0]\n",
    "        return input_dict\n",
    "\n",
    "    def read_sumstat(file, config=None):\n",
    "        try:\n",
    "            sumstats = pd.read_csv(file, compression='gzip', header=0, sep='\\t', quotechar='\"')\n",
    "        except:\n",
    "            sumstats = pd.read_csv(file, header=0, sep='\\t', quotechar='\"')\n",
    "        if config is not None:\n",
    "            try:\n",
    "                sumstats = sumstats.loc[:,list(config.values())]\n",
    "            except:\n",
    "                raise ValueError(f'According to config_file, input summary statistics should have the following columns: %s' % list(config.values()))\n",
    "            sumstats.columns = list(config.keys())\n",
    "        sumstats.SNP = 'chr'+sumstats.CHR.astype(str) + ':' + sumstats.POS.astype(str) + '_' + sumstats.A0.astype(str) + '_' + sumstats.A1.astype(str)\n",
    "        sumstats.CHR = sumstats.CHR.astype(int)\n",
    "        sumstats.POS = sumstats.POS.astype(int)\n",
    "        return sumstats\n",
    "\n",
    "    def snps_match(query,subject,keep_ambiguous=True):\n",
    "        query.index = query.iloc[:,:2].astype(str).agg(':'.join, axis=1)\n",
    "        subject.index = subject.iloc[:,:2].astype(str).agg(':'.join, axis=1)\n",
    "        #overlap snps by chr+pos\n",
    "        print(\"Total rows of query: \",query.shape[0],\"Total rows of subject: \",subject.shape[0])\n",
    "        subject = subject[subject.index.isin(query.index)]\n",
    "        query = query.loc[subject.index]\n",
    "        print(\"Overlap chr:pos\",query.shape[0])\n",
    "        if query.index.duplicated().any():\n",
    "            raise Exception(\"There are duplicated chr:pos\")\n",
    "        pm = pair_match(query.A1,query.A0,subject.A1,subject.A0)\n",
    "        if keep_ambiguous:\n",
    "            print('Warning: there are',sum(~pm.ambiguous),'ambiguous SNPs')\n",
    "            pm = pm.iloc[:,1:]\n",
    "        else:\n",
    "            pm = pm[~pm.ambiguous].iloc[:,1:]\n",
    "        keep_idx = pm.any(axis=1)\n",
    "        print(\"Overlap SNPs\",sum(keep_idx))\n",
    "        #overlap snps by chr+pos+alleles.\n",
    "        new_subject = subject[keep_idx]\n",
    "        #update beta and snp info\n",
    "        new_query = pd.concat([new_subject.iloc[:,:5],query[keep_idx].iloc[:,5:]],axis=1)\n",
    "        new_query.STAT[pm.sign_flip] = -new_query.STAT[pm.sign_flip]\n",
    "        return new_query,new_subject\n",
    "\n",
    "    def pair_match(a1,a2,ref1,ref2):\n",
    "        # a1 and a2 are the first data-set\n",
    "        # ref1 and ref2 are the 2nd data-set\n",
    "        # Make all the alleles into upper-case, as A,T,C,G:\n",
    "        a1 = a1.str.upper()\n",
    "        a2 = a2.str.upper()\n",
    "        ref1 = ref1.str.upper()\n",
    "        ref2 = ref2.str.upper()\n",
    "        # Strand flip, to change the allele representation in the 2nd data-set\n",
    "        flip1 = ref1.apply(strand_flip)\n",
    "        flip2 = ref2.apply(strand_flip)\n",
    "        result = {}\n",
    "        result[\"ambiguous\"] = ((a1==\"A\") & (a2==\"T\")) | ((a1==\"T\") & (a2==\"A\")) | ((a1==\"C\") & (a2==\"G\")) | ((a1==\"G\") & (a2==\"C\"))\n",
    "        # as long as scenario 1 is involved, sign_flip will return TRUE\n",
    "        result[\"sign_flip\"] = ((a1==ref2) & (a2==ref1)) | ((a1==flip2) & (a2==flip1))\n",
    "        # as long as scenario 2 is involved, strand_flip will return TRUE\n",
    "        result[\"strand_flip\"] = ((a1==flip1) & (a2==flip2)) | ((a1==flip2) & (a2==flip1))\n",
    "        # remove other cases, eg, tri-allelic, one dataset is A C, the other is A G, for example.\n",
    "        result[\"exact_match\"] = ((a1 == ref1) & (a2 == ref2))\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def strand_flip(s):\n",
    "        return ''.join(Seq(s).reverse_complement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63b670-435a-44ea-91a4-4a754dd2fe2a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_2 (merge sumstats)]\n",
    "depends: f'{cwd:a}/utils.py'\n",
    "input: for_each = \"yml_path\"\n",
    "python: expand = '${ }', input = f'{cwd:a}/utils.py', stderr = f'{cwd:a}/output.stderr', stdout = f'{cwd:a}/output.stdout', container = container\n",
    "    yml_input = \"${_yml_path[1]}\"\n",
    "    print(yml_input)\n",
    "    merge_sumstats(yml_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
