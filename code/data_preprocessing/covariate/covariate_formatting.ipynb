{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "solar-relief",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Covariate Data Formatting\n",
    "\n",
    "This module is used to merge various sources of previously computed or obtained covariates into one file, for downstreams QTL analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2728ff43",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "1. PCA file as output from the PCA module\n",
    "2. Fixed covariate files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac867bf0",
   "metadata": {},
   "source": [
    "## Output\n",
    "1. PCA + Covariate file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3210489",
   "metadata": {},
   "source": [
    "## Minimal Working Example\n",
    "\n",
    "The data and singularity used in this minimal working example can be found on [Synapse](https://www.synapse.org/#!Synapse:syn52369482)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4162c98a",
   "metadata": {},
   "source": [
    "### Merge Covariates and Genotype PCA\n",
    "You can edit the total amount of variation you want your PCs to explain by editing the `--k ` parameter. In this example, we chose 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing: <1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705806c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sos run pipeline/covariate_formatting.ipynb merge_genotype_pc \\\n",
    "    --cwd output/covariate \\\n",
    "    --pcaFile output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.rds \\\n",
    "    --covFile  input/protocol_example.samples.tsv \\\n",
    "    --tol_cov 0.4  \\\n",
    "    --k `awk '$3 < 0.8' output/genotype_pca/protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.scree.txt | tail -1 | cut -f 1 ` \\\n",
    "    --container containers/bioinfo.sif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2326cc45",
   "metadata": {},
   "source": [
    "```\n",
    "INFO: Running merge_genotype_pc:\n",
    "INFO: merge_genotype_pc is completed.\n",
    "INFO: merge_genotype_pc output:   /Users/alexmccreight/xqtl-pipeline/output/covariate/protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.gz\n",
    "INFO: Workflow merge_genotype_pc (ID=weaef0ce301340b3d) is executed successfully with 1 completed step.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "balanced-albania",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run covariate_formatting.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  merge_pca_covariate\n",
      "  compute_residual\n",
      "  merge_factor_covariate\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        The output directory for generated files.\n",
      "  --covFile VAL (as path, required)\n",
      "                        The covariate file\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 2G\n",
      "                        Memory expected\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "  --nCov -1 (as int)\n",
      "                        The number of the external covariates to be included, -1\n",
      "                        means includs all of them, 0 means include none of them,\n",
      "                        but keeping only the header (Basicaaly just formatting\n",
      "                        the PCs).\n",
      "  --tol-cov -1.0 (as float)\n",
      "                        Tolerance of missingness in covariates, -1 means quit,\n",
      "                        otherwise for covariate with missing rate larger than\n",
      "                        tol_cov will be removed, with missing rate smaller than\n",
      "                        tol_cov will be mean_imputed.\n",
      "\n",
      "Sections\n",
      "  merge_pca_covariate:\n",
      "    Workflow Options:\n",
      "      --pcaFile VAL (as path, required)\n",
      "                        The PCA file. an RDS file as the output of the pca\n",
      "                        module\n",
      "      --k 20 (as int)\n",
      "                        The number of PCs to retained, by default is 20, in\n",
      "                        pratice should be the number of pc that captured more\n",
      "                        than 70% PVE\n",
      "      --name  f'{covFile:bn}.{pcaFile:bn}'\n",
      "\n",
      "  compute_residual_1:\n",
      "    Workflow Options:\n",
      "      --phenoFile VAL (as path, required)\n",
      "                        Path to the input molecular phenotype data.\n",
      "      --name  f'{phenoFile:bnn}.{covFile:bn}'\n",
      "\n",
      "  compute_residual_2:   tabix via samtools\n",
      "  merge_factor_covariate:\n",
      "    Workflow Options:\n",
      "      --factorFile VAL (as path, required)\n",
      "      --name  f'{factorFile:bnn}.{covFile:bn}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run covariate_formatting.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saving-transsexual",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. \n",
    "parameter: cwd = path(\"output\")\n",
    "# The covariate file\n",
    "parameter: covFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"2G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "cwd = path(f\"{cwd:a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-accent",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_genotype_pc]\n",
    "# An RDS file as the output of the genotype PCA module\n",
    "parameter: pcaFile = path\n",
    "# The number of PCs to retain, by default is 20, in practice can be the number of PC that captured more than 70% PVE\n",
    "parameter: k = 20\n",
    "parameter: name = f'{covFile:bn}.{pcaFile:bn}'\n",
    "# Outliers\n",
    "parameter: outliersFile = path(\".\") \n",
    "parameter: remove_outliers = False\n",
    "# Tolerance of missingness in covariates, -1 means do nothing, otherwise for samples with covariates missing rate larger than tol_cov will be removed,\n",
    "# with missing rate smaller than tol_cov will be kept.\n",
    "parameter: tol_cov = -1.0 \n",
    "parameter: mean_impute = True\n",
    "stop_if(remove_outliers and not outliersFile.is_file(), msg = \"No outliers file specified, please add outliers file or remove the remove-outliers flag\")\n",
    "input: pcaFile, covFile\n",
    "output:  f'{cwd:a}/{name}.gz'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint = entrypoint\n",
    "        library(\"dplyr\")\n",
    "        library(\"readr\")\n",
    "        library(\"data.table\")\n",
    "\n",
    "        compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "\n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return($['mean_impute(X)' if mean_impute else 'X'])\n",
    "        }  \n",
    "\n",
    "        pca_output = readRDS(\"$[_input[0]]\")$pc_scores\n",
    "        mtx = pca_output%>%select(contains(\"PC\"))%>%t()\n",
    "        colnames(mtx) <- pca_output$IID\n",
    "        ## Keep only the number of PCs specified\n",
    "        mtx = mtx[1:$[k],]\n",
    "        mtx = mtx%>%as_tibble(rownames = \"#id\")\n",
    "        ## Load covariates\n",
    "        covt = transpose(fread(\"$[_input[1]]\", head=T), keep.names=\"#id\", make.names=1) %>% as_tibble()\n",
    "\n",
    "        ## Retaining only the overlapped samples with genotype\n",
    "        overlap = intersect(colnames(covt),colnames(mtx))\n",
    "        \n",
    "        ## Report sample counts:\n",
    "        print(paste(ncol(covt) - 1, \"samples are in the covariate file\", sep = \" \"))\n",
    "        print(paste(ncol(mtx), \"samples are in the PCA file\", sep = \" \"))\n",
    "\n",
    "        ## Report identical samples:\n",
    "        print(paste(length(overlap) - 1, \"samples overlap between covariate & PCA files and are included in the analysis:\", sep = \" \"))\n",
    "        print(overlap[!overlap == '#id'])\n",
    "\n",
    "        ## Report non-overlapping samples:\n",
    "        cov_missing = covt %>% select(-all_of(overlap))\n",
    "        print(paste(ncol(cov_missing), \"samples in the covariate file are missing from the PCA file:\", sep = \" \"))\n",
    "        print(colnames(cov_missing))\n",
    "\n",
    "        pca_missing = mtx %>% select(-all_of(overlap))\n",
    "        print(paste(ncol(pca_missing), \"samples in the PCA file are missing from the covariate file:\", sep = \" \"))\n",
    "        print(colnames(pca_missing))\n",
    "        \n",
    "        ## Removal of outlier if needed\n",
    "        if ($[\"TRUE\" if remove_outliers else \"FALSE\"]){\n",
    "              outlier = fread(\"$[outliersFile]\", head = FALSE)$V2 %>% as_tibble()\n",
    "              overlap = setdiff(overlap,outlier)\n",
    "              }\n",
    "        covt = covt%>%select(all_of(overlap))\n",
    "\n",
    "        mtx = mtx%>%select(all_of(overlap))\n",
    "        output = bind_rows(covt,mtx)\n",
    "\n",
    "        ## Handle missingess in covariates\n",
    "        if($[tol_cov] == -1){if(sum(is.na(output)) > 0 ){ stop(\"NA in covariates input: Check input file or set parameter tol_cov to allow for removing missing values; mean_impute to allow for imputing missing values\")}}\n",
    "        output = output%>%as.data.frame\n",
    "        rownames(output) = output$`#id`\n",
    "        output = filter_mtx(output[,2:ncol(output)],$[tol_cov])%>%as_tibble(rownames = \"#id\")\n",
    "        output%>%write_delim(\"$[_output]\",\"\\t\")\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint = entrypoint\n",
    "        stdout=$[_output:n].stdout \n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
