
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Multi-trait colocalization using ColocBoost &#8212; FunGen-xQTL Consortium</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'code/mnm_analysis/mnm_methods/colocboost';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Chromosome-Specific Enrichment Analysis of Annotations Using Block Jackknife" href="../../enrichment/eoo_enrichment.html" />
    <link rel="prev" title="TWAS, cTWAS and MR" href="../../pecotmr_integration/twas_ctwas.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/xqtl_wf.png" class="logo__image only-light" alt="FunGen-xQTL Consortium - Home"/>
    <script>document.write(`<img src="../../../_static/xqtl_wf.png" class="logo__image only-dark" alt="FunGen-xQTL Consortium - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../README.html">
                    FunGen-xQTL Computational Protocol
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../xqtl_protocol_demo.html">Illustration of xQTL protocol</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Command Generator</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../commands_generator/bulk_expression_commands.html">RNA-seq calling and QC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../commands_generator/eQTL_analysis_commands.html">Univariate xQTL Discovery</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference_data/reference_data.html">Reference Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference_data/reference_data_preparation.html">Reference Data Standardization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference_data/generalized_TADB.html">Generation of Topologically Associated Domains and their Boundaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference_data/ld_prune_reference.html">Independent list of variants using LD clumping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference_data/ld_reference_generation.html">Generating LD Reference Panel</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Molecular Phenotypes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../molecular_phenotypes/bulk_expression.html">RNA-seq expression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/calling/RNA_calling.html">Quantifying expression from RNA-seq data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/QC/bulk_expression_QC.html">Sample level RNA-seq quality control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/QC/bulk_expression_normalization.html">Bulk RNA-seq counts normalization</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../molecular_phenotypes/scnuc_expression.html">scRNA-seq expression calling</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../molecular_phenotypes/apa.html">Alternative polyadenylation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/calling/apa_calling.html">APA Calling</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../molecular_phenotypes/methylation.html">Methylation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/calling/methylation_calling.html">Quantification of methylation data</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../molecular_phenotypes/splicing.html">Alternative splicing from RNA-seq data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/calling/splicing_calling.html">Quantifying alternative splicing from RNA-seq data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../molecular_phenotypes/QC/splicing_normalization.html">Normalization and phenotype table generation for splicingQTL analysis</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Pre-processing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../data_preprocessing/genotype_preprocessing.html">Genotype data preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/genotype/VCF_QC.html">Genotype VCF File Quality Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/genotype/GWAS_QC.html">Genotype PLINK File Quality Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/genotype/PCA.html">Principal Component Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/genotype/GRM.html">Genomic Relationship Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/genotype/genotype_formatting.html">Genotype Data Formatting</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../data_preprocessing/phenotype_preprocessing.html">Phenotype data preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/phenotype/gene_annotation.html">Gene Coordinate Annotation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/phenotype/phenotype_imputation.html">Phenotype data imputation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/phenotype/phenotype_formatting.html">Phenotype Data Formatting</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../data_preprocessing/covariate_preprocessing.html">Covariate Data Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/covariate/covariate_formatting.html">Covariate Data Formatting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../data_preprocessing/covariate/covariate_hidden_factor.html">Hidden Factor Analysis</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">QTL Association Testing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../association_scan/qtl_association_testing.html">QTL Association Analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../association_scan/TensorQTL/TensorQTL.html">QTL Association Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../association_scan/quantile_models/qr_and_twas.html">Quantile regression for QTL association testing</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../association_scan/qtl_association_postprocessing.html">QTL data postprocessing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multivariate Mixture Model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../multivariate_genome/multivariate_mixture_vignette.html">Mixture Multivariate Distribution Estimate</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../multivariate_genome/MASH/mixture_prior.html">A multivariate EBNM approach for mixture multivariate distribution estimate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../multivariate_genome/MASH/mash_fit.html">MASH analysis pipeline with data-driven prior matrices</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Multiomics Regression Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../mnm_miniprotocol.html">Integrative Analysis with High-Dimensional Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../univariate_fine_mapping_twas_vignette.html">Univariate Fine-Mapping and TWAS with SuSiE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multivariate_multigene_fine_mapping_vignette.html">Multivariate Fine-Mapping for multiple genes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../univariate_fine_mapping_fsusie_vignette.html">Univariate Fine-Mapping of Functional (Epigenomic) Data with fSuSiE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multivariate_fine_mapping_vignette.html">Multivariate Fine-Mapping with mvSuSiE and mr.mash</a></li>
<li class="toctree-l2"><a class="reference internal" href="../summary_stats_finemapping_vignette.html">Regression with Summary Statistics (RSS) Fine-Mapping and TWAS with SuSiE</a></li>
<li class="toctree-l2"><a class="reference internal" href="mnm_regression.html">Advanced regression models for association analysis with individual level data</a></li>
<li class="toctree-l2"><a class="reference internal" href="rss_analysis.html">High-dimensional regression with summary statistics</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GWAS Integration</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pecotmr_integration/SuSiE_enloc.html">xQTL-GWAS pairwise enrichment and colocalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pecotmr_integration/twas_ctwas.html">TWAS, cTWAS and MR</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Multi-trait colocalization using ColocBoost</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Enrichment and Validation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../enrichment/eoo_enrichment.html">Chromosome-Specific Enrichment Analysis of Annotations Using Block Jackknife</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../enrichment/gsea.html">Pathway Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../enrichment/gregor.html">GREGOR enrichment analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../enrichment/sldsc_enrichment.html">Stratified LD Score Regression</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cumc/xqtl-protocol/edit/gh-pages/code/mnm_analysis/mnm_methods/colocboost.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cumc/xqtl-protocol/issues/new?title=Issue%20on%20page%20%2Fcode/mnm_analysis/mnm_methods/colocboost.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/code/mnm_analysis/mnm_methods/colocboost.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Multi-trait colocalization using ColocBoost</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#description">Description</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input">Input</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-genotype-phenotype-and-association-analysis-windows">Example genotype, phenotype and association analysis windows</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-summary-statistics-and-ld-reference">Example summary statistics and LD reference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#about-indels">About indels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimal-working-example-steps">Minimal Working Example Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#troubleshooting">Troubleshooting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#command-interface">Command interface</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflow-implementation">Workflow implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#colocboost-analysis">ColocBoost analysis</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="multi-trait-colocalization-using-colocboost">
<h1>Multi-trait colocalization using ColocBoost<a class="headerlink" href="#multi-trait-colocalization-using-colocboost" title="Link to this heading">#</a></h1>
<section id="description">
<h2>Description<a class="headerlink" href="#description" title="Link to this heading">#</a></h2>
<p>This notebook performs colocalizatoin for multiple xQTL in a given region, with/without GWAS summary statistics. Current protocol (Feb, 2025) supports individual level xQTL data from the same cohort (multiple phenotypes, same genotype) along with summary statistics and companion LD reference data.</p>
</section>
<section id="input">
<h2>Input<a class="headerlink" href="#input" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>A list of regions to be analyzed (optional); the last column of this file should be region name.</p></li>
<li><p>Either a list of per chromosome genotype files, or one file for genotype data of the entire genome. Genotype data has to be in PLINK <code class="docutils literal notranslate"><span class="pre">bed</span></code> format.</p></li>
<li><p>Vector of lists of phenotype files per region to be analyzed, in UCSC <code class="docutils literal notranslate"><span class="pre">bed.gz</span></code> with index in <code class="docutils literal notranslate"><span class="pre">bed.gz.tbi</span></code> formats.</p></li>
<li><p>Vector of covariate files corresponding to the lists above.</p></li>
<li><p>Customized association windows file for variants (cis or trans). If it is not provided, a fixed sized window will be used around the region (a cis-window)</p></li>
<li><p>Optionally a vector of names of the phenotypic conditions in the form of <code class="docutils literal notranslate"><span class="pre">cond1</span> <span class="pre">cond2</span> <span class="pre">cond3</span></code> separated with whitespace.</p></li>
<li><p>Optionally summary statistics meta-data file and LD reference meta-data file.</p></li>
</ol>
<p>Input 2 and 3 should be outputs from <code class="docutils literal notranslate"><span class="pre">genotype_per_region</span></code> and <code class="docutils literal notranslate"><span class="pre">annotate_coord</span></code> modules in previous preprocessing steps. 4 should be output of <code class="docutils literal notranslate"><span class="pre">covariate_preprocessing</span></code> pipeline that contains genotype PC, phenotypic hidden confounders and fixed covariates.</p>
<section id="example-genotype-phenotype-and-association-analysis-windows">
<h3>Example genotype, phenotype and association analysis windows<a class="headerlink" href="#example-genotype-phenotype-and-association-analysis-windows" title="Link to this heading">#</a></h3>
<p>See <a class="reference internal" href="mnm_regression.html"><span class="doc std std-doc">this page</span></a> for example inputs of these information.</p>
</section>
<section id="example-summary-statistics-and-ld-reference">
<h3>Example summary statistics and LD reference<a class="headerlink" href="#example-summary-statistics-and-ld-reference" title="Link to this heading">#</a></h3>
<p>See <a class="reference internal" href="rss_analysis.html"><span class="doc std std-doc">this page</span></a> for example inputs of these information.</p>
</section>
<section id="about-indels">
<h3>About indels<a class="headerlink" href="#about-indels" title="Link to this heading">#</a></h3>
<p>Option <code class="docutils literal notranslate"><span class="pre">--no-indel</span></code> will remove indel from analysis. FIXME: Gao need to provide more guidelines how to deal with indels in practice.</p>
</section>
</section>
<section id="output">
<h2>Output<a class="headerlink" href="#output" title="Link to this heading">#</a></h2>
<p>For each analysis region, the output are various ColocBoost models fitted and saved in RDS format.</p>
</section>
<section id="minimal-working-example-steps">
<h2>Minimal Working Example Steps<a class="headerlink" href="#minimal-working-example-steps" title="Link to this heading">#</a></h2>
<p>Timing [FIXME]</p>
<p>Below we duplicate the examples for phenotype and covariates to demonstrate that when there are multiple phenotypes for the same genotype it is possible to use this pipeline to analyze all of them (more than two is accepted as well).</p>
<p>Here using <code class="docutils literal notranslate"><span class="pre">--region-name</span></code> we focus the analysis on 3 genes. In practice if this parameter is dropped, the union of all regions in all phenotype region lists will be analyzed. It is possible for some of the regions there are no genotype data, in which case the pipeline will output RDS files with a warning message to indicate the lack of genotype data to analyze.</p>
<p><strong>Note:</strong> Suggested output naming convention is cohort_modality, eg ROSMAP_snRNA_pseudobulk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>sos run pipeline/colocboost.ipynb colcoboost  \
    --name protocol_example_protein  \
    --genoFile input/xqtl_association/protocol_example.genotype.chr21_22.bed   \
    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \
                output/phenotype/protocol_example.protein.region_list.txt \
    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \
              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz  \
    --customized-association-windows input/xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \
    --region-name ENSG00000241973_P42356 ENSG00000160209_O00764 ENSG00000100412_Q99798 \
    --phenotype-names trait_A trait_B
</pre></div>
</div>
</div>
</div>
<p>It is also possible to analyze a selected list of regions using option <code class="docutils literal notranslate"><span class="pre">--region-list</span></code>. The last column of this file will be used for the list to analyze. Here for example use the same list of regions as we used for customized association-window:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>sos run xqtl-protocol/pipeline/mnm_regression.ipynb susie_twas  \
    --name protocol_example_protein  \
    --genoFile xqtl_association/protocol_example.genotype.chr21_22.bed   \
    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \
                output/phenotype/protocol_example.protein.region_list.txt \
    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \
              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz  \
    --customized-association-windows xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \
    --region-list xqtl_association/protocol_example.protein.enhanced_cis_chr21_chr22.bed \
    --phenotype-names trait_A trait_B
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong> When both <code class="docutils literal notranslate"><span class="pre">--region-name</span></code> and <code class="docutils literal notranslate"><span class="pre">--region-list</span></code> are used, the union of regions from these parameters will be analyzed.</p>
</section>
<section id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Substep</p></th>
<th class="head"><p>Problem</p></th>
<th class="head"><p>Possible Reason</p></th>
<th class="head"><p>Solution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="command-interface">
<h2>Command interface<a class="headerlink" href="#command-interface" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>sos run colocboost.ipynb -h
</pre></div>
</div>
</div>
</div>
</section>
<section id="workflow-implementation">
<h2>Workflow implementation<a class="headerlink" href="#workflow-implementation" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>[global]
# It is required to input the name of the analysis
parameter: name = str
parameter: cwd = path(&quot;output&quot;)
# A list of file paths for genotype data, or the genotype data itself. 
parameter: genoFile = path
# One or multiple lists of file paths for phenotype data.
parameter: phenoFile = paths
# One or multiple lists of file paths for phenotype ID mapping file. The first column should be the original ID, the 2nd column should be the ID to be mapped to.
parameter: phenoIDFile = paths()
# Covariate file path
parameter: covFile = paths
# Summary statistics interface, see `rss_analysis.ipynb` for details
parameter: gwas_meta_data = path()
parameter: ld_meta_data = path()
parameter: gwas_name = []
parameter: gwas_data = []
parameter: column_mapping = []
# Optional: if a region list is provide the analysis will be focused on provided region. 
# The LAST column of this list will contain the ID of regions to focus on when region_name is given
# Otherwise, all regions with both genotype and phenotype files will be analyzed
parameter: region_list = path()
# Optional: if a region name is provided 
# the analysis would be focused on the union of provides region list and region names
parameter: region_name = []
# Only focus on a subset of samples
parameter: keep_samples = path()
# Only focus on a subset of variants
parameter: keep_variants = path()
# An optional list documenting the custom association window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).
# If this list is not provided, the default `window` parameter (see below) will be used.
parameter: customized_association_windows = path()
# Specify the cis window for the up and downstream radius to analyze around the region of interest in units of bp
# When this is set to negative, we will rely on using customized_association_windows
parameter: cis_window = -1
# save data object or not
parameter: save_data = False
# Name of phenotypes
parameter: phenotype_names = [f&#39;{x:bn}&#39; for x in phenoFile]
# And indicator whether it is trans-analysis, ie, not using phenotypic coordinate information
parameter: trans_analysis = False
parameter: seed = 999

# remove a variant if it has more than imiss missing individual level data
parameter: imiss = 1.0
# MAF and variance of X cutoff
parameter: maf = 0.0025
parameter: xvar_cutoff = 0.0
# MAC cutoff, on top of MAF cutoff
parameter: mac = 5
# Remove indels if indel = False
parameter: indel = True
parameter: event_filter_rules = path()
# If this value is not 0, then an initial single effect analysis will be performed 
# to determine if follow up analysis will be continued or to simply return NULL
# If this is negative we use a default way to determine this cutoff which is conservative but still useful
parameter: skip_analysis_pip_cutoff = []
parameter: skip_sumstats_analysis_pip_cutoff = -1.0
# Perform xQTL colocalization
parameter: xqtl_coloc = True
# Perform joint colocalization with many traits
parameter: joint_gwas = False
# Perform separate GWAS targeted anlaysis one at a time
parameter: separate_gwas = True
# Whether to impute the sumstat for all the snp in LD but not in sumstat.
parameter: impute = False 
parameter: rcond = 0.01
parameter: lamb = 0.01
parameter: R2_threshold = 0.6
parameter: minimum_ld = 5
# summary stats QC methods: rss_qc, dentist, slalom
parameter: qc_method = &quot;NULL&quot;

parameter: target = &quot;&quot;
# Either an index number in str format or &quot;NULL&quot; as a string
parameter: target_column_index = &quot;3&quot;
parameter: comment_string = &quot;NULL&quot;
parameter: ld_data_name = []

# Analysis environment settings
parameter: container = &quot;&quot;
parameter: entrypoint= &quot;&quot;
# For cluster jobs, number commands to run per job
parameter: job_size = 200
# Wall clock time expected
parameter: walltime = &quot;1h&quot;
# Memory expected
parameter: mem = &quot;20G&quot;
# Number of threads
parameter: numThreads = 1

if len(phenoFile) != len(covFile):
    raise ValueError(&quot;Number of input phenotypes files must match that of covariates files&quot;)
if len(phenoFile) != len(phenotype_names):
    raise ValueError(&quot;Number of input phenotypes files must match the number of phenotype names&quot;)
if len(phenoIDFile) &gt; 0 and len(phenoFile) != len(phenoIDFile):
    raise ValueError(&quot;Number of input phenotypes files must match the number of phenotype ID mapping files&quot;)

if len(skip_analysis_pip_cutoff) == 0:
    skip_analysis_pip_cutoff = [0.0] * len(phenoFile)
if len(skip_analysis_pip_cutoff) == 1:
    skip_analysis_pip_cutoff = skip_analysis_pip_cutoff * len(phenoFile)
if len(skip_analysis_pip_cutoff) != len(phenoFile):
    raise ValueError(f&quot;``skip_analysis_pip_cutoff`` should have either length 1 or length the same as phenotype files ({len(phenoFile)} in this case)&quot;)

# make it into an R List string
skip_analysis_pip_cutoff = [f&quot;&#39;{y}&#39;={x}&quot; for x,y in zip(skip_analysis_pip_cutoff, phenotype_names)]
    
def group_by_region(lst, partition):
    # from itertools import accumulate
    # partition = [len(x) for x in partition]
    # Compute the cumulative sums once
    # cumsum_vector = list(accumulate(partition))
    # Use slicing based on the cumulative sums
    # return [lst[(cumsum_vector[i-1] if i &gt; 0 else 0):cumsum_vector[i]] for i in range(len(partition))]
    return partition

import os
import pandas as pd

def adapt_file_path(file_path, reference_file):
    &quot;&quot;&quot;
    Adapt a single file path based on its existence and a reference file&#39;s path.

    Args:
    - file_path (str): The file path to adapt.
    - reference_file (str): File path to use as a reference for adaptation.

    Returns:
    - str: Adapted file path.

    Raises:
    - FileNotFoundError: If no valid file path is found.
    &quot;&quot;&quot;
    reference_path = os.path.dirname(reference_file)

    # Check if the file exists
    if os.path.isfile(file_path):
        return file_path

    # Check file name without path
    file_name = os.path.basename(file_path)
    if os.path.isfile(file_name):
        return file_name

    # Check file name in reference file&#39;s directory
    file_in_ref_dir = os.path.join(reference_path, file_name)
    if os.path.isfile(file_in_ref_dir):
        return file_in_ref_dir

    # Check original file path prefixed with reference file&#39;s directory
    file_prefixed = os.path.join(reference_path, file_path)
    if os.path.isfile(file_prefixed):
        return file_prefixed

    # If all checks fail, raise an error
    raise FileNotFoundError(f&quot;No valid path found for file: {file_path}&quot;)

def adapt_file_path_all(df, column_name, reference_file):
    return df[column_name].apply(lambda x: adapt_file_path(x, reference_file))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>[get_analysis_regions: shared = &quot;regional_data&quot;]
# input is genoFile, phenoFile, covFile and optionally region_list. If region_list presents then we only analyze what&#39;s contained in the list.
# regional_data should be a dictionary like:
#{&#39;data&#39;: [(&quot;genotype_1.bed&quot;, &quot;phenotype_1.bed.gz&quot;, &quot;covariate_1.gz&quot;), (&quot;genotype_2.bed&quot;, &quot;phenotype_1.bed.gz&quot;, &quot;phenotype_2.bed.gz&quot;, &quot;covariate_1.gz&quot;, &quot;covariate_2.gz&quot;) ... ],
# &#39;meta_info&#39;: [(&quot;chr12:752578-752579&quot;,&quot;chr12:752577-752580&quot;, &quot;gene_1&quot;, &quot;trait_1&quot;), (&quot;chr13:852580-852581&quot;,&quot;chr13:852579-852580&quot;, &quot;gene_2&quot;, &quot;trait_1&quot;, &quot;trait_2&quot;) ... ]}
import numpy as np

def preload_id_map(id_map_files):
    id_maps = {}
    missing_files = []
    
    for id_map_file in id_map_files:
        if id_map_file is not None:
            if os.path.isfile(id_map_file):
                df = pd.read_csv(id_map_file, sep=r&quot;\s+&quot;, header=None, comment=&#39;#&#39;, names=[&#39;old_ID&#39;, &#39;new_ID&#39;])
                id_maps[id_map_file] = df.set_index(&#39;old_ID&#39;)[&#39;new_ID&#39;].to_dict()
            else:
                missing_files.append(id_map_file)
    
    # If there are missing files, print a summary
    # if missing_files:
    #    print(f&quot;Warning: {len(missing_files)} ID map file(s) specified but not found:&quot;)
    #    for file in missing_files:
    #        print(f&quot;  - {file}&quot;)
    
    return id_maps

def load_and_apply_id_map(pheno_path, id_map_path, preloaded_id_maps):
    pheno_df = pd.read_csv(pheno_path, sep=r&quot;\s+&quot;, header=0)
    pheno_df[&#39;Original_ID&#39;] = pheno_df[&#39;ID&#39;]
    
    # Check if id_map_path is specified
    if id_map_path is not None:
        # Check if the id_map_path exists in preloaded maps
        if id_map_path in preloaded_id_maps:
            id_map = preloaded_id_maps[id_map_path]
            pheno_df[&#39;ID&#39;] = pheno_df[&#39;ID&#39;].map(id_map).fillna(pheno_df[&#39;ID&#39;])
        else:
            # ID map file was specified but doesn&#39;t exist or wasn&#39;t loaded
            print(f&quot;Warning: ID map file &#39;{id_map_path}&#39; was specified but does not exist. Using original IDs.&quot;)
            # No mapping is done here, so ID remains the same as Original_ID
    
    return pheno_df

def filter_by_region_ids(data, region_ids):
    if region_ids is not None and len(region_ids) &gt; 0:
        data = data[data[&#39;ID&#39;].isin(region_ids)]
    return data

def custom_join(series):
    # Initialize an empty list to hold the processed items
    result = []
    for item in series:
        if &#39;,&#39; in item:
            # If the item contains commas, split by comma and convert to tuple
            result.append(tuple(item.split(&#39;,&#39;)))
        else:
            # If the item does not contain commas, add it directly
            result.append(item)
    # Convert the list of items to a tuple and return
    return tuple(result)

def aggregate_phenotype_data(accumulated_pheno_df):
    if not accumulated_pheno_df.empty:
        accumulated_pheno_df = accumulated_pheno_df.groupby([&#39;#chr&#39;,&#39;ID&#39;,&#39;cond&#39;,&#39;path&#39;,&#39;cov_path&#39;], as_index=False).agg({
            &#39;#chr&#39;: lambda x: np.unique(x).astype(str)[0],
            &#39;ID&#39;: lambda x: np.unique(x).astype(str)[0],
            &#39;Original_ID&#39;: &#39;,&#39;.join,
            &#39;start&#39;: &#39;min&#39;,
            &#39;end&#39;: &#39;max&#39;
        }).groupby([&#39;#chr&#39;,&#39;ID&#39;], as_index=False).agg({
            &#39;cond&#39;: &#39;,&#39;.join,
            &#39;path&#39;: &#39;,&#39;.join,
            &#39;Original_ID&#39;: custom_join,
            &#39;cov_path&#39;: &#39;,&#39;.join,
            &#39;start&#39;: &#39;min&#39;,
            &#39;end&#39;: &#39;max&#39;
        })
    return accumulated_pheno_df

def process_cis_files(pheno_files, cov_files, phenotype_names, pheno_id_files, region_ids, preloaded_id_maps):
    &#39;&#39;&#39;
    Example output:
    #chr    start      end    ID  Original_ID   path     cov_path             cond
    chr12   752578   752579  ENSG00000060237  Q9H4A3,P62873  protocol_example.protein_1.bed.gz,protocol_example.protein_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B
    &#39;&#39;&#39;
    accumulated_pheno_df = pd.DataFrame()
    pheno_id_files = [None] * len(pheno_files) if len(pheno_id_files) == 0 else pheno_id_files

    for pheno_path, cov_path, phenotype_name, id_map_path in zip(pheno_files, cov_files, phenotype_names, pheno_id_files):
        if not os.path.isfile(cov_path):
            raise FileNotFoundError(f&quot;No valid path found for file: {cov_path}&quot;)
        pheno_df = load_and_apply_id_map(pheno_path, id_map_path, preloaded_id_maps)
        pheno_df = filter_by_region_ids(pheno_df, region_ids)
        
        if not pheno_df.empty:
            pheno_df.iloc[:, 4] = adapt_file_path_all(pheno_df, pheno_df.columns[4], f&quot;{pheno_path:a}&quot;)
            pheno_df = pheno_df.assign(cov_path=str(cov_path), cond=phenotype_name)           
            accumulated_pheno_df = pd.concat([accumulated_pheno_df, pheno_df], ignore_index=True)

    accumulated_pheno_df = aggregate_phenotype_data(accumulated_pheno_df)
    return accumulated_pheno_df

def process_trans_files(pheno_files, cov_files, phenotype_names, pheno_id_files, region_ids, customized_association_windows):
    &#39;&#39;&#39;
    Example output:
    #chr    start      end    ID  Original_ID   path     cov_path             cond
    chr21   0   0  chr21_18133254_19330300  carnitine,benzoate,hippurate  metabolon_1.bed.gz,metabolon_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B
    &#39;&#39;&#39;
    
    if not os.path.isfile(customized_association_windows):
        raise ValueError(&quot;Customized association analysis window must be specified for trans analysis.&quot;)
    accumulated_pheno_df = pd.DataFrame()
    pheno_id_files = [None] * len(pheno_files) if len(pheno_id_files) == 0 else pheno_id_files
    genotype_windows = pd.read_csv(customized_association_windows, comment=&quot;#&quot;, header=None, names=[&quot;#chr&quot;,&quot;start&quot;,&quot;end&quot;,&quot;ID&quot;], sep=&quot;\t&quot;)
    genotype_windows = filter_by_region_ids(genotype_windows, region_ids)
    if genotype_windows.empty:
        return accumulated_pheno_df
    
    for pheno_path, cov_path, phenotype_name, id_map_path in zip(pheno_files, cov_files, phenotype_names, pheno_id_files):
        if not os.path.isfile(cov_path):
            raise FileNotFoundError(f&quot;No valid path found for file: {cov_path}&quot;)
        pheno_df = pd.read_csv(pheno_path, sep=r&quot;\s+&quot;, header=0, names=[&#39;Original_ID&#39;, &#39;path&#39;])
        if not pheno_df.empty:
            pheno_df.iloc[:, -1] = adapt_file_path_all(pheno_df, pheno_df.columns[-1], f&quot;{pheno_path:a}&quot;)
            pheno_df = pheno_df.assign(cov_path=str(cov_path), cond=phenotype_name)
            # Here we combine genotype_windows which contains &quot;#chr&quot; and &quot;ID&quot; to pheno_df by creating a cartesian product
            pheno_df = pd.merge(genotype_windows.assign(key=1), pheno_df.assign(key=1), on=&#39;key&#39;).drop(&#39;key&#39;, axis=1)
            # then set start and end columns to zero
            pheno_df[&#39;start&#39;] = 0
            pheno_df[&#39;end&#39;] = 0
            if id_map_path is not None:
                # Filter pheno_df by specific association-window and phenotype pairs
                association_analysis_pair = pd.read_csv(id_map_path, sep=r&quot;\s+&quot;, header=None, comment=&#39;#&#39;, names=[&#39;ID&#39;, &#39;Original_ID&#39;])
                pheno_df = pd.merge(pheno_df, association_analysis_pair, on=[&#39;ID&#39;, &#39;Original_ID&#39;])
            accumulated_pheno_df = pd.concat([accumulated_pheno_df, pheno_df], ignore_index=True)

    accumulated_pheno_df = aggregate_phenotype_data(accumulated_pheno_df)
    return accumulated_pheno_df

def load_regional_data(genoFile, phenoFile, covFile, phenotype_names, phenoIDFile, 
                      region_list=None, region_name=None, trans_analysis=False, 
                      customized_association_windows=None, cis_window=-1):   
    # Ensure region_name is a list
    if region_name is None:
        region_name = []
    
    # Load genotype meta data
    if f&quot;{genoFile:x}&quot; == &quot;.bed&quot;:
        geno_meta_data = pd.DataFrame([(&quot;chr&quot;+str(x), f&quot;{genoFile:a}&quot;) for x in range(1,23)] + [(&quot;chrX&quot;, f&quot;{genoFile:a}&quot;)], columns=[&#39;#chr&#39;, &#39;geno_path&#39;])
    else:
        geno_meta_data = pd.read_csv(f&quot;{genoFile:a}&quot;, sep=r&quot;\s+&quot;, header=0)
        geno_meta_data.iloc[:, 1] = adapt_file_path_all(geno_meta_data, geno_meta_data.columns[1], f&quot;{genoFile:a}&quot;)
        geno_meta_data.columns = [&#39;#chr&#39;, &#39;geno_path&#39;]
        geno_meta_data[&#39;#chr&#39;] = geno_meta_data[&#39;#chr&#39;].apply(lambda x: str(x) if str(x).startswith(&#39;chr&#39;) else f&#39;chr{x}&#39;)

    # Checking the DataFrame
    valid_chr_values = [f&#39;chr{x}&#39; for x in range(1, 23)] + [&#39;chrX&#39;]
    if not all(value in valid_chr_values for value in geno_meta_data[&#39;#chr&#39;]):
        raise ValueError(&quot;Invalid chromosome values found. Allowed values are chr1 to chr22 and chrX.&quot;)

    region_ids = []
    # If region_list is provided, read the file and extract IDs
    if region_list is not None and region_list.is_file():
        region_list_df = pd.read_csv(region_list, delim_whitespace=True, header=None, comment=&quot;#&quot;)
        region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs

    # If region_name is provided, include those IDs as well
    # --region-name A B C will result in a list of [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;] here
    if len(region_name) &gt; 0:
        region_ids = list(set(region_ids).union(set(region_name)))

    if trans_analysis:
        meta_data = process_trans_files(phenoFile, covFile, phenotype_names, phenoIDFile, region_ids, customized_association_windows)
    else:
        meta_data = process_cis_files(phenoFile, covFile, phenotype_names, phenoIDFile, region_ids, preload_id_map(phenoIDFile))
        
    if not meta_data.empty:
        meta_data = meta_data.merge(geno_meta_data, on=&#39;#chr&#39;, how=&#39;inner&#39;)
        # Adjust association-window
        if customized_association_windows is not None and os.path.isfile(customized_association_windows):
            print(f&quot;Loading customized association analysis window from {customized_association_windows}&quot;)
            association_windows_list = pd.read_csv(customized_association_windows, comment=&quot;#&quot;, header=None, 
                                                  names=[&quot;#chr&quot;,&quot;start&quot;,&quot;end&quot;,&quot;ID&quot;], sep=&quot;\t&quot;)
            meta_data = pd.merge(meta_data, association_windows_list, on=[&#39;#chr&#39;, &#39;ID&#39;], how=&#39;left&#39;, suffixes=(&#39;&#39;, &#39;_association&#39;))
            mismatches = meta_data[meta_data[&#39;start_association&#39;].isna()]
            if not mismatches.empty:
                print(&quot;First 5 mismatches:&quot;)
                print(mismatches[[&#39;ID&#39;]].head())
                raise ValueError(f&quot;{len(mismatches)} regions to analyze cannot be found in ``{customized_association_windows}``. &quot;
                                f&quot;Please check your ``{customized_association_windows}`` database to make sure it contains all &quot;
                                f&quot;association-window definitions. &quot;)
        else:
            if cis_window &lt; 0:
                raise ValueError(&quot;Please either input valid path to association-window file via ``--customized-association-windows``, &quot;
                                &quot;or set ``--cis-window`` to a non-negative integer.&quot;)
            if cis_window == 0:
                print(&quot;Warning: only variants within the range of start and end of molecular phenotype will be considered &quot;
                     &quot;since cis_window is set to zero and no customized association window file was found. &quot;
                     &quot;Please make sure this is by design.&quot;)
            meta_data[&#39;start_association&#39;] = meta_data[&#39;start&#39;].apply(lambda x: max(x - cis_window, 0))
            meta_data[&#39;end_association&#39;] = meta_data[&#39;end&#39;] + cis_window

        # Example meta_data:
        # #chr    start      end    start_association       end_association           ID  Original_ID   path     cov_path             cond             coordinate     geno_path
        # 0  chr12   752578   752579  652578   852579  ENSG00000060237  Q9H4A3,P62873  protocol_example.protein_1.bed.gz,protocol_example.protein_2.bed.gz  covar_1.gz,covar_2.gz  trait_A,trait_B    chr12:752578-752579  protocol_example.genotype.chr21_22.bed       
        # Create the final dictionary
        regional_data = {
            &#39;data&#39;: [(row[&#39;geno_path&#39;], *row[&#39;path&#39;].split(&#39;,&#39;), *row[&#39;cov_path&#39;].split(&#39;,&#39;)) for _, row in meta_data.iterrows()],
            &#39;meta_info&#39;: [(f&quot;{row[&#39;#chr&#39;]}:{row[&#39;start&#39;]}-{row[&#39;end&#39;]}&quot;, # this is the phenotypic region to extract data from
                          f&quot;{row[&#39;#chr&#39;]}:{row[&#39;start_association&#39;]}-{row[&#39;end_association&#39;]}&quot;, # this is the association window region
                          row[&#39;ID&#39;], row[&#39;Original_ID&#39;], *row[&#39;cond&#39;].split(&#39;,&#39;)) for _, row in meta_data.iterrows()]
        }
    else:
        regional_data = {&#39;data&#39;: [], &#39;meta_info&#39;: []}
        
    return regional_data


# Modified main code section to document the key format alignment
regional_data = load_regional_data(
    genoFile=genoFile, 
    phenoFile=phenoFile, 
    covFile=covFile, 
    phenotype_names=phenotype_names, 
    phenoIDFile=phenoIDFile,
    region_list=region_list, 
    region_name=region_name, 
    trans_analysis=trans_analysis,
    customized_association_windows=customized_association_windows, 
    cis_window=cis_window
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>[get_rss_analysis_regions: shared = &quot;regional_rss_data&quot;]

from collections import OrderedDict

def file_exists(file_path, relative_path=None):
    &quot;&quot;&quot;Check if a file exists at the given path or relative to a specified path.&quot;&quot;&quot;
    if os.path.exists(file_path) and os.path.isfile(file_path):
        return True
    elif relative_path:
        relative_file_path = os.path.join(relative_path, file_path)
        return os.path.exists(relative_file_path) and os.path.isfile(relative_file_path)
    return False

def check_required_columns(df, required_columns):
    &quot;&quot;&quot;Check if the required columns are present in the dataframe.&quot;&quot;&quot;
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f&quot;Missing required columns: {&#39;, &#39;.join(missing_columns)}&quot;)

def parse_region(region):
    &quot;&quot;&quot;
    Parse a region string in &#39;chr:start-end&#39; format into a list [chr, start, end].
    Returns a list containing [chromosome_with_chr_prefix, start_position, end_position].
    &quot;&quot;&quot;
    # Handle both numeric and &#39;chr&#39; prefixed chromosome formats
    if &#39;:&#39; in region:
        chrom, rest = region.split(&#39;:&#39;)
        # Store original chrom value with &#39;chr&#39; prefix preserved
        original_chrom = chrom
        
        # Strip &#39;chr&#39; prefix if present (for internal processing)
        if chrom.startswith(&#39;chr&#39;):
            chrom = chrom[3:]  # Remove &#39;chr&#39; prefix if present
        
        # Handle both hyphen and underscore separators for start-end
        if &#39;-&#39; in rest:
            start, end = rest.split(&#39;-&#39;)
        elif &#39;_&#39; in rest:
            start, end = rest.split(&#39;_&#39;)
        else:
            raise ValueError(f&quot;Invalid region format: {region}. Expected format: chr:start-end or chr:start_end&quot;)
            
        # Return with the original chromosome format that includes &#39;chr&#39; prefix
        return [original_chrom, int(start), int(end)]
    else:
        raise ValueError(f&quot;Invalid region format: {region}. Expected format: chr:start-end or chr:start_end&quot;)

def resolve_region_names(region_name, customized_association_windows=None, region_list=None):
    &quot;&quot;&quot;
    Resolve region names by looking them up in either customized_association_windows or region_list.
    Returns a dictionary mapping region keys to parsed regions.
    &quot;&quot;&quot;
    region_dict = {}
    
    # If no region names provided, return empty dict
    if not region_name:
        return region_dict
    
    # Check if either file exists
    if not ((customized_association_windows and os.path.isfile(customized_association_windows)) or 
            (region_list and os.path.isfile(region_list))):
        raise ValueError(&quot;Either customized association window file or region list file must exist when region names are provided&quot;)
    
    # Determine which file to use (prioritize customized_association_windows)
    region_file = None
    if customized_association_windows and os.path.isfile(customized_association_windows):
        region_file = customized_association_windows
        print(f&quot;Using customized association window file: {region_file}&quot;)
    elif region_list and os.path.isfile(region_list):
        region_file = region_list
        print(f&quot;Using region list file: {region_file}&quot;)
    
    # Load region definitions from the file
    name_to_region_map = {}
    with open(region_file, &#39;r&#39;) as file:
        for line in file:
            # Skip empty lines and comments
            if not line.strip() or line.startswith(&quot;#&quot;):
                continue
                
            parts = line.strip().split()
            if len(parts) &gt;= 4:  # Ensure there&#39;s at least 4 columns
                # Extract ID column (4th column)
                region_id = parts[3]
                
                # Extract chromosome, start, and end positions
                chrom = parts[0].replace(&quot;chr&quot;, &quot;&quot;)  # Remove &#39;chr&#39; prefix if present
                try:
                    # Create the region info
                    parsed_region = [int(chrom) if chrom.isdigit() else chrom, 
                                    int(parts[1]), 
                                    int(parts[2])]
                    
                    # Include the ID
                    parsed_region.append(parts[3])
                    
                    # Add to the mapping
                    name_to_region_map[region_id] = parsed_region
                except ValueError:
                    # Skip lines with non-integer positions
                    print(f&quot;Warning: Skipping invalid region definition: {line.strip()}&quot;)
    
    # Process each region name
    for region in region_name:
        # Check if this region name exists in our mapping
        if region in name_to_region_map:
            parsed_region = name_to_region_map[region]
        else:
            # Try to parse it as a coordinate string as a last resort
            try:
                parsed_region = parse_region(region)
                print(f&quot;Warning: Region &#39;{region}&#39; not found in file, parsing as coordinate string&quot;)
            except ValueError:
                raise ValueError(f&quot;Could not parse region &#39;{region}&#39; and it was not found in the region file&quot;)
        
        # Format the region key
        region_key = f&quot;chr{parsed_region[0]}:{parsed_region[1]}-{parsed_region[2]}&quot;
        if region_key not in region_dict:
            region_dict[region_key] = parsed_region
    
    return region_dict

def load_regional_rss_data(gwas_meta_data, gwas_name, gwas_data, column_mapping, ld_data_name, region_name=None, region_list=None):
    &quot;&quot;&quot;
    Extracts data from GWAS metadata files and additional GWAS data provided. 
    Uses the same region information as load_regional_data to ensure consistent
    region identification across both data structures.
    
    IMPORTANT: This function processes the same regions as load_regional_data and 
    formats the region keys in regional_rss_data[&quot;regions&quot;] to exactly match the 
    2nd element of regional_data[&quot;meta_info&quot;] tuples (chr:start-end format).

    Args:
    - gwas_meta_data (str): File path to the GWAS metadata file.
    - gwas_name (list): Vector of GWAS study names.
    - gwas_data (list): Vector of GWAS data.
    - column_mapping (list, optional): Vector of column mapping files.
    - region_name (list, optional): List of region names (same as in load_regional_data).
    - region_list (str, required): File path to a file containing region mapping between names and coordinates (same file used in load_regional_data).

    Returns:
    - GWAS Dictionary: Maps study IDs to a list containing chromosome number, 
      GWAS file path, and optional column mapping file path.
    - Region Dictionary: Maps region names to lists [chr, start, end] using the same
      key format as regional_data[&quot;meta_info&quot;][1] (chr:start-end).

    Raises:
    - FileNotFoundError: If any specified file path does not exist.
    - ValueError: If required columns are missing in the input files or vector lengths mismatch.
    &quot;&quot;&quot;
    # Check vector lengths
    if len(gwas_name) != len(gwas_data):
        raise ValueError(&quot;gwas_name and gwas_data must be of equal length&quot;)
    
    if len(column_mapping) &gt; 0 and len(column_mapping) != len(gwas_name):
        raise ValueError(&quot;If column_mapping is provided, it must be of the same length as gwas_name and gwas_data&quot;)

    # Required columns for GWAS file type
    required_gwas_columns = [&#39;study_id&#39;, &#39;chrom&#39;, &#39;file_path&#39;]

    # Base directory of the metadata files
    gwas_base_dir = os.path.dirname(gwas_meta_data)
    
    # Reading the GWAS metadata file
    gwas_df = pd.read_csv(gwas_meta_data, sep=&quot;\t&quot;)
    check_required_columns(gwas_df, required_gwas_columns)
    gwas_dict = OrderedDict()

    # Handle ld_data_name for study_id modifications
    if len(ld_data_name) == 1:
        # If one LD name provided, apply to all studies
        gwas_df[&#39;study_id&#39;] = ld_data_name[0] + &#39;_&#39; + gwas_df[&#39;study_id&#39;]
    elif len(ld_data_name) &gt; 1:
        # If multiple LD names provided, ensure they match the number of studies
        if len(ld_data_name) != gwas_df.shape[0]:
            raise ValueError(f&quot;ld_data_name length ({len(ld_data_name)}) must match the number of studies ({gwas_df.shape[0]})&quot;)
        # Apply specific LD name to each study using vectorized operations
        gwas_df[&#39;study_id&#39;] = [f&quot;{ld}_{sid}&quot; for ld, sid in zip(ld_data_name, gwas_df[&#39;study_id&#39;])]
        ###### FIXME: if multiple LD names provided, ensure they match the number of studies also match the ld_meta_data.
        ###### FIXME: this is also need a match file, ld_meta_data should be unique then save computational for loading LD.
        
    # Process additional GWAS data from vectors
    for name, data, mapping in zip(gwas_name, gwas_data, column_mapping or [None]*len(gwas_name)):
        gwas_dict[name] = {0: [data, mapping]}

    for _, row in gwas_df.iterrows():
        file_path = row[&#39;file_path&#39;]
        mapping_file = row.get(&#39;column_mapping_file&#39;)
        n_sample = row.get(&#39;n_sample&#39;)
        n_case = row.get(&#39;n_case&#39;)
        n_control = row.get(&#39;n_control&#39;)

        # Check if the file and optional mapping file exist
        if not file_exists(file_path, gwas_base_dir) or (mapping_file and not file_exists(mapping_file, gwas_base_dir)):
            raise FileNotFoundError(f&quot;File {file_path} not found for {row[&#39;study_id&#39;]}&quot;)
        
        # Adjust paths if necessary
        file_path = file_path if file_exists(file_path) else os.path.join(gwas_base_dir, file_path)
        if mapping_file:
            mapping_file = mapping_file if file_exists(mapping_file) else os.path.join(gwas_base_dir, mapping_file)
        
        # Create or update the entry for the study_id
        if row[&#39;study_id&#39;] not in gwas_dict:
            gwas_dict[row[&#39;study_id&#39;]] = {}

        # Expand chrom 0 to chrom 1-22 or use the specified chrom
        chrom_range = range(1, 23) if row[&#39;chrom&#39;] == 0 else [row[&#39;chrom&#39;]]
        for chrom in chrom_range:
            if chrom in gwas_dict[row[&#39;study_id&#39;]]:
                existing_entry = gwas_dict[row[&#39;study_id&#39;]][chrom]
                raise ValueError(f&quot;Duplicate chromosome specification for study_id {row[&#39;study_id&#39;]}, chrom {chrom}. &quot;
                                 f&quot;Conflicting entries: {existing_entry} and {[file_path, mapping_file]}&quot;)
            gwas_dict[row[&#39;study_id&#39;]][chrom] = [file_path, mapping_file, n_sample, n_case, n_control]

    # Process region_list and region_name
    region_dict = dict()
 
    if region_name:
        for region in region_name:
            try:
                # First try parsing the region as a coordinate
                parsed_region = parse_region(region)
                region_key = f&quot;chr{parsed_region[0]}:{parsed_region[1]}-{parsed_region[2]}&quot;
                if region_key not in region_dict:
                    region_dict[region_key] = parsed_region
            except ValueError:
                # If that fails, it means it&#39;s a name that needs to be resolved
                resolved_regions = resolve_region_names([region], customized_association_windows, region_list)
                region_dict.update(resolved_regions)
    else:
        # Analyze all regions found in region list
        with open(region_list, &#39;r&#39;) as file:
            for line in file:
                # Skip empty lines and comments
                if not line.strip() or line.startswith(&quot;#&quot;):
                    continue
                    
                parts = line.strip().split()
                if len(parts) == 1:
                    # Format: &quot;chr:start-end&quot;
                    region = parse_region(parts[0])
                elif len(parts) == 3:
                    # Format: chr start end
                    chrom = parts[0]
                    # Ensure &#39;chr&#39; prefix is preserved
                    if not chrom.startswith(&#39;chr&#39;):
                        chrom = f&quot;chr{chrom}&quot;
                    region = [chrom, int(parts[1]), int(parts[2])]
                elif len(parts) &gt;= 4:
                    # Format for eQTL: chr start end gene_id gene_name ...
                    chrom = parts[0]
                    # Ensure &#39;chr&#39; prefix is preserved
                    if not chrom.startswith(&#39;chr&#39;):
                        chrom = f&quot;chr{chrom}&quot;
                    region = [chrom, int(parts[1]), int(parts[2]), parts[3]]
                else:
                    raise ValueError(f&quot;Invalid region format in region_list: {line.strip()}&quot;)
                
                # Create key in the same format as regional_data[&quot;meta_info&quot;][1]
                region_key = f&quot;chr{region[0]}:{region[1]}-{region[2]}&quot;
                region_dict[region_key] = region

    return gwas_dict, region_dict

if gwas_meta_data.is_file():
    # Load GWAS data with region keys formatted to match regional_data[&quot;meta_info&quot;]
    # Using the same region_list and region_name as load_regional_data ensures consistency
    gwas_dict, region_dict = load_regional_rss_data(gwas_meta_data, gwas_name, gwas_data, column_mapping, ld_data_name, region_name, region_list)
    regional_rss_data = dict([(&quot;GWAS&quot;, gwas_dict), (&quot;regions&quot;, region_dict)])
    
    # The keys in regional_rss_data[&quot;regions&quot;] are now formatted as &quot;chr:start-end&quot;
    # to match the second element of each tuple in regional_data[&quot;meta_info&quot;],
    # with both formats ensuring the chromosome includes the &#39;chr&#39; prefix.
    # Since we use the same region_list and region_name parameters for both 
    # load_regional_data and load_regional_rss_data, we guarantee consistent
    # region identification across both data structures.
    # The expected format for shared keys is: &quot;chr1:12345-67890&quot;
else:
    regional_rss_data = dict()
</pre></div>
</div>
</div>
</div>
</section>
<section id="colocboost-analysis">
<h2>ColocBoost analysis<a class="headerlink" href="#colocboost-analysis" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-sos notranslate"><div class="highlight"><pre><span></span>[colocboost]
depends: sos_variable(&quot;regional_data&quot;), sos_variable(&quot;regional_rss_data&quot;)
# Check if both &#39;data&#39; and &#39;meta_info&#39; are empty lists
stop_if(len(regional_data[&#39;data&#39;]) == 0, f&#39;Either genotype or phenotype data are not available for region {&quot;, &quot;.join(region_name)}.&#39;)
meta_info = regional_data[&#39;meta_info&#39;]
input: regional_data[&quot;data&quot;], group_by = lambda x: group_by_region(x, regional_data[&quot;data&quot;]), group_with = &quot;meta_info&quot;

base_dir = f&#39;{cwd:a}&#39;
chr_info = _meta_info[0].split(&quot;:&quot;)[0]
gene_id = _meta_info[2]
base_filename = f&#39;{name}.{chr_info}_{gene_id}&#39;

# Initialize output_files list
output_files = []

# Default case: if all analysis flags are False, save data
if not xqtl_coloc and not joint_gwas and not separate_gwas:
    save_data = True

if save_data:
    output_files.append(f&#39;{base_dir}/data/{base_filename}.cb_data.rds&#39;)

if xqtl_coloc:
    output_files.append(f&#39;{base_dir}/colocboost/{base_filename}.cb_xqtl.rds&#39;)

if joint_gwas:
    output_files.append(f&#39;{base_dir}/colocboost/{base_filename}.cb_xqtl_joint_gwas.rds&#39;)

if separate_gwas and &quot;GWAS&quot; in regional_rss_data and regional_rss_data[&quot;GWAS&quot;]:
    for study_name in regional_rss_data[&quot;GWAS&quot;].keys():
        output_files.append(f&#39;{base_dir}/colocboost/{base_filename}.cb_xqtl_{study_name}.rds&#39;)
   
output: output_files
task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f&#39;{step_name}_{_output[0]:bnn}&#39;
R: expand = &#39;${ }&#39;, stdout = f&quot;{_output[0]:nn}.colocboost.stdout&quot;, stderr = f&quot;{_output[0]:nn}.colocboost.stderr&quot;, container = container, entrypoint = entrypoint
    options(warn=1)
    
    #### FIXME later: need to install current version of pecotmr
    library(tidyverse)
    library(data.table)
    library(vroom)
    library(vctrs)
    library(susieR)
    library(matrixStats)
    for(file in list.files(&quot;/home/xc2270/COLOCBoost/pipline/pecotmr_code&quot;, full.names = T)) {source(file)}
    source(&quot;/home/xc2270/COLOCBoost/pipline/colocboost_pipline.R&quot;)
    for(file in list.files(&quot;/home/xc2270/COLOCBoost/code_COLOCBoost/colocboost_updating&quot;, full.names = T)) {source(file)}
  
    ##### ======= set up all input parameters ====== #####
  
    # individual level data
    region = ${(&quot;&#39;%s&#39;&quot; % _meta_info[0]) if int(_meta_info[0].split(&#39;-&#39;)[-1])&gt;0 else &#39;NULL&#39;} # if the end position is zero return NULL
    genotype_list = ${_input[0]:anr}
    phenotype_list = c(${&quot;,&quot;.join([&#39;&quot;%s&quot;&#39; % x.absolute() for x in _input[1:len(_input)//2+1]])})
    covariate_list = c(${&quot;,&quot;.join([&#39;&quot;%s&quot;&#39; % x.absolute() for x in _input[len(_input)//2+1:]])})
    conditions_list_individual = c(${&quot;,&quot;.join([&#39;&quot;%s&quot;&#39; % x for x in _meta_info[4:]])})
    maf_cutoff = ${maf}
    mac_cutoff = ${mac}
    imiss_cutoff = ${imiss}
    association_window = &quot;${_meta_info[1]}&quot;
    extract_region_name = list(${&quot;,&quot;.join([(&quot;c(&#39;&quot;+x+&quot;&#39;)&quot;) if isinstance(x, str) else (&quot;c&quot;+ str(x)) for x in _meta_info[3]])})
    region_name_col = ${&quot;4&quot; if int(_meta_info[0].split(&#39;-&#39;)[-1])&gt;0 else &quot;1&quot;}
    keep_indel = ${&quot;TRUE&quot; if indel else &quot;FALSE&quot;}
    # extract subset of samples
    keep_samples = NULL
    if (${&quot;TRUE&quot; if keep_samples.is_file() else &quot;FALSE&quot;}) {
      keep_samples = unlist(strsplit(readLines(${keep_samples:ar}), &quot;\\s+&quot;))
      message(paste(length(keep_samples), &quot;samples are selected to be loaded for analysis&quot;))
    }
    phenotype_header = ${&quot;4&quot; if int(_meta_info[0].split(&#39;-&#39;)[-1])&gt;0 else &quot;1&quot;}
    scale_residuals = FALSE
    keep_variants = ${&#39;&quot;%s&quot;&#39; % keep_variants if not keep_variants.is_dir() else &quot;NULL&quot;} # use &quot;not keep_variants.is_dir()&quot; in case user input filename is wrong without realizing
    
    # - summary statistics
    sumstat_path_list = c(${paths([regional_rss_data[&#39;GWAS&#39;][x][regional_rss_data[&#39;regions&#39;][_meta_info[1]][0]][0] for x in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else []):r,})
    column_file_path_list = c(${paths([regional_rss_data[&#39;GWAS&#39;][x][regional_rss_data[&#39;regions&#39;][_meta_info[1]][0]][1] for x in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else []):r,})
    LD_meta_file_path_list = &quot;${ld_meta_data}&quot;
    # Replace _regions with _meta_info[1] which is the association window region
    n_samples = c(${paths([regional_rss_data[&#39;GWAS&#39;][x][regional_rss_data[&#39;regions&#39;][_meta_info[1]][0]][2] for x in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else []):r,}) %&gt;% as.numeric
    n_cases = c(${paths([regional_rss_data[&#39;GWAS&#39;][x][regional_rss_data[&#39;regions&#39;][_meta_info[1]][0]][3] for x in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else []):r,}) %&gt;% as.numeric
    n_controls = c(${paths([regional_rss_data[&#39;GWAS&#39;][x][regional_rss_data[&#39;regions&#39;][_meta_info[1]][0]][4] for x in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else []):r,}) %&gt;% as.numeric
    target = &quot;${target}&quot;
    target_column_index = ${target_column_index}
    comment_string = ${&quot;NULL&quot; if comment_string == &quot;NULL&quot; else f&quot;&#39;{comment_string}&#39;&quot;}
    qc_method = ${&quot;NULL&quot; if qc_method == &quot;NULL&quot; else &quot;&#39;%s&#39;&quot; % qc_method}
    impute = ${&quot;TRUE&quot; if impute else &quot;FALSE&quot;}
    impute_opts = list(rcond = ${rcond}, R2_threshold = ${R2_threshold}, minimum_ld = ${minimum_ld}, lamb=${lamb})
    ### FIXME: there is no remove_indels in rss analysis pipline should we ignore this?
    remove_indels = FALSE
  
    # Summary stats data - Using the 2nd element (association window) from _meta_info directly
    studies = c(${&#39;, &#39;.join([&#39;&quot;{}&quot;&#39;.format(item) for item in regional_rss_data[&quot;GWAS&quot;].keys()] if &quot;GWAS&quot; in regional_rss_data else [])})
    ld_data_name &lt;- c(${&#39;, &#39;.join([&#39;&quot;{}&quot;&#39;.format(item) for item in ld_data_name] if &quot;GWAS&quot; in regional_rss_data else [])})

    ### FIXME when we have multiple LD reference in the future we need to revisit this
    match_LD_sumstat &lt;- list()
    # If we have any LD data names
    if (length(ld_data_name) &gt; 0) {
      if (length(ld_data_name) == 1) {
        match_LD_sumstat[[ld_data_name[1]]] &lt;- studies
      } else {
        # Otherwise, match studies to their respective LD references
        # Assuming 1:1 ordered matching which is completed due to the previous python codes preprocessed
        for (ld in unique(ld_data_name)) {
          # Find which positions have this LD name
          matches &lt;- which(ld_data_name == ld)
          # Assign matching studies to this LD
          match_LD_sumstat[[ld]] &lt;- studies[matches]
        }
      }
    }
    # About analysis
    xqtl_coloc = ${&quot;TRUE&quot; if xqtl_coloc else &quot;FALSE&quot;}
    joint_gwas = ${&quot;TRUE&quot; if joint_gwas else &quot;FALSE&quot;}
    separate_gwas = ${&quot;TRUE&quot; if separate_gwas else &quot;FALSE&quot;}
    # About QC parameters
    pip_cutoff_to_skip_ind = unlist(list(${&quot;,&quot;.join(skip_analysis_pip_cutoff)})[conditions_list_individual])
    pip_cutoff_to_skip_sumstat = rep(${skip_sumstats_analysis_pip_cutoff}, length(studies)) %&gt;% setNames(studies)
    event_filter_rules = ${&quot;NULL&quot; if not event_filter_rules.is_file() else &quot;&#39;%s&#39;&quot; % event_filter_rules}
    if (!is.null(event_filter_rules)) {
        event_filters &lt;- read.table(&quot;${event_filter_rules}&quot;)
        event_filters &lt;- lapply(1:nrow(event_filters), function(ii) as.list(event_filters[ii,] %&gt;% unlist))
    } else { event_filters &lt;- NULL }
  
    # Add computational time
    computing_time = list()
    # Load regional multitask data
    t1 &lt;- Sys.time()
    tryCatch({
        fdat = load_multitask_regional_data(region = region, 
                                            # individual
                                            genotype_list = genotype_list,
                                            phenotype_list = phenotype_list, 
                                            covariate_list = covariate_list, 
                                            conditions_list_individual = conditions_list_individual,
                                            maf_cutoff = maf_cutoff, mac_cutoff = mac_cutoff,
                                            imiss_cutoff = imiss_cutoff,
                                            association_window = association_window, 
                                            extract_region_name = extract_region_name,
                                            region_name_col = region_name_col,
                                            keep_indel = keep_indel, keep_samples = keep_samples,
                                            phenotype_header = phenotype_header, scale_residuals = scale_residuals,
                                            keep_variants = keep_variants,
                                            # summary stats
                                            sumstat_path_list = sumstat_path_list,
                                            column_file_path_list = column_file_path_list,
                                            LD_meta_file_path_list = LD_meta_file_path_list,
                                            match_LD_sumstat = match_LD_sumstat,
                                            conditions_list_sumstat = studies,
                                            n_samples = n_samples, n_cases = n_cases, n_controls = n_controls,
                                            target = target, target_column_index = target_column_index,
                                            comment_string = comment_string)
    }, NoSNPsError = function(e) {
        message(&quot;Error: &quot;, paste(e$message, &quot;${_meta_info[2] + &#39;@&#39; + _meta_info[1]}&quot;))
        quit(save=&quot;no&quot;)
    })   
    t2 &lt;- Sys.time()
    computing_time$Loading = t2 - t1

  
    # save data-set
    if (${&quot;TRUE&quot; if save_data else &quot;FALSE&quot;}) {
        saveRDS(list(${_meta_info[2]} = fdat), &quot;${_output[0]:ann}.cb_data.rds&quot;, compress=&#39;xz&#39;)
    }
    if (&quot;${_meta_info[2]}&quot; != &quot;${_meta_info[3]}&quot;) {
        region_name = c(&quot;${_meta_info[2]}&quot;, c(${&quot;,&quot;.join([(&quot;c(&#39;&quot;+x+&quot;&#39;)&quot;) if isinstance(x, str) else (&quot;c&quot;+ str(x)) for x in _meta_info[3]])}))
    } else {
        region_name = &quot;${_meta_info[2]}&quot;
    }
  
    region_info = list(region_coord=parse_region(&quot;${_meta_info[0]}&quot;), grange=parse_region(&quot;${_meta_info[1]}&quot;), region_name=region_name)
    res &lt;- colocboost_analysis_pipline(region_data = fdat, 
                                        event_filters = event_filters,
                                        # - analysis
                                        xqtl_coloc = xqtl_coloc,
                                        joint_gwas = joint_gwas,
                                        separate_gwas = separate_gwas,
                                        # - individual QC
                                        maf_cutoff = maf_cutoff, 
                                        pip_cutoff_to_skip_ind = pip_cutoff_to_skip_ind,
                                        # - sumstat QC
                                        pip_cutoff_to_skip_sumstat = pip_cutoff_to_skip_sumstat,
                                        qc_method = qc_method,
                                        impute = impute, 
                                        impute_opts = impute_opts)

    # Reorganize outputs
    computing_time &lt;- c(computing_time, res$computing_time)
    if (xqtl_coloc) {
      res$xqtl_coloc$region_info &lt;- region_info
      res$xqtl_coloc$computing_time &lt;- computing_time
      saveRDS(list(&quot;${_meta_info[2]}&quot; = res$xqtl_coloc), &quot;${_output[0]:ann}.cb_xqtl.rds&quot;, compress=&#39;xz&#39;)
    }
    if (joint_gwas) {
      res$joint_gwas$region_info &lt;- region_info
      res$joint_gwas$computing_time &lt;- computing_time
      saveRDS(list(&quot;${_meta_info[2]}&quot; = res$joint_gwas), &quot;${_output[0]:ann}.cb_xqtl_joint_gwas.rds&quot;, compress=&#39;xz&#39;)
    }
    if (separate_gwas) {
      for (name in names(res$separate_gwas)) {
          res$separate_gwas[[name]]$region_info &lt;- region_info
          res$separate_gwas[[name]]$computing_time &lt;- computing_time
          saveRDS(list(&quot;${_meta_info[2]}&quot; = res$separate_gwas[[name]]), paste0(&quot;${_output[0]:ann}.cb_xqtl_&quot;, name, &quot;.rds&quot;), compress=&#39;xz&#39;)
        }
    }
    
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "sos"
        },
        kernelOptions: {
            name: "sos",
            path: "./code/mnm_analysis/mnm_methods"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'sos'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../../pecotmr_integration/twas_ctwas.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">TWAS, cTWAS and MR</p>
      </div>
    </a>
    <a class="right-next"
       href="../../enrichment/eoo_enrichment.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chromosome-Specific Enrichment Analysis of Annotations Using Block Jackknife</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#description">Description</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input">Input</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-genotype-phenotype-and-association-analysis-windows">Example genotype, phenotype and association analysis windows</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-summary-statistics-and-ld-reference">Example summary statistics and LD reference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#about-indels">About indels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimal-working-example-steps">Minimal Working Example Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#troubleshooting">Troubleshooting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#command-interface">Command interface</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflow-implementation">Workflow implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#colocboost-analysis">ColocBoost analysis</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The NIH/NIA Alzheimer's Disease Sequencing Project Functional Genomics xQTL Consortium
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2021+, FunGen xQTL Analysis Working Group.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>