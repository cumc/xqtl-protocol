{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diagnostic-phenomenon",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Genotype data reformat\n",
    "\n",
    "**FIXME: should iclude both data format conversion and region extraction for genotypes**\n",
    "\n",
    "This is the plink 2 vcf part of data processing pipeline for xqtl workflow, containing the generation of:\n",
    ". vcf genome type file\n",
    "\n",
    "### Input\n",
    "The input for this workflow is the collection of data for 1 conditions as described in the readme of this git repo\n",
    "1. 1 collection of genotype data in plink format, partitioned by chrm\n",
    "2. A list of genotype file documenting the location of 1.\n",
    "\n",
    "### Output\n",
    "For each collection, the output is 23 sets of :\n",
    "1. genotype file in compress vcf format\n",
    "2. tbi index for the compressed vcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developmental-raleigh",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: wd = path\n",
    "# The filename name for containers\n",
    "parameter: container = 'gaow/twas'\n",
    "# namefor the analysis output\n",
    "parameter: name= str\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# List of Genotype file in plink trio format\n",
    "parameter: genotype_list = path\n",
    "geno_inventory = dict([x.strip().split() for x in open(genotype_list).readlines() if x.strip() and not x.strip().startswith('#')])\n",
    "\n",
    "chrom_list = [x.strip().split() for x in open(genotype_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(chrom_list)))\n",
    "\n",
    "import os\n",
    "def get_genotype_file(chrom, genotype_list, geno_inventory):\n",
    "    chrom = f'{chrom}'\n",
    "    if chrom.startswith('chr'):\n",
    "        chrom = chrom[3:]\n",
    "    if chrom not in geno_inventory:\n",
    "        geno_file = f'{chrom}'\n",
    "    else:\n",
    "        geno_file = geno_inventory[chrom]\n",
    "    if not os.path.isfile(geno_file):\n",
    "        # relative path\n",
    "        if not os.path.isfile(f'{genotype_list:ad}/' + geno_file):\n",
    "            raise ValueError(f\"Cannot find genotype file {geno_file}\")\n",
    "        else:\n",
    "            geno_file = f'{genotype_list:ad}/' + geno_file\n",
    "    return path(geno_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-earth",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Process of Genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-mouth",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "polar-howard",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Plink to VCF transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-generator",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink2vcf_1]\n",
    "input: genotype_list, for_each = \"chrom\"\n",
    "geno_file = get_genotype_file(_chrom,genotype_list,geno_inventory) \n",
    "output: f'{wd:a}/{name}_vcf_geno/{name}_chr{_chrom}.vcf.gz',\n",
    "        f'{wd:a}/{name}_vcf_geno/{name}_chr{_chrom}.vcf.gz.tbi'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, volumes = [f'{genotype_list:ad}:{genotype_list:ad}']\n",
    "    plink --bfile $[geno_file:n] \\\n",
    "    --recode vcf-iid       --out $[_output[0]:nn] \n",
    "    bgzip $[_output[0]:n]  \n",
    "    tabix -f -p vcf $[_output[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-backup",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink2vcf_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{wd:a}/{name}_vcf_geno/{name}.vcf_geno_list.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '20G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, volumes = [f'{genotype_list:ad}:{genotype_list:ad}']\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"modelr\")\n",
    "    library(\"purrr\")\n",
    "    chrom = c($[\",\".join(chrom)])\n",
    "    dir = \"$[_output:nn]\"\n",
    "    geno_list = tibble(`#chr` = chrom, dir = map_chr(`#chr`,~paste(c(dir,\"_chr\",.x,\".vcf.gz\"),collapse =\"\")))%>%arrange(`#chr`)\n",
    "    geno_list%>%write_delim(\"$[_output]\",\"\\t\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
