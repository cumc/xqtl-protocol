{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forbidden-ocean",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# xQTL-GWAS pairwise enrichment and colocalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-salon",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "This workflow processes fine-mapping results for xQTL, generated by `susie_twas` in the `mnm_regression.ipynb` notebook for cis xQTL, and GWAS fine-mapping results produced by `susie_rss` in the `rss_analysis.ipynb` notebook. It is designed to perform enrichment and colocalization analysis, particularly when fine-mapping results originate from different regions in the case of cis-xQTL and GWAS. The pipeline is capable to integrate and analyze data across these distinct regions. Originally tailored for cis-xQTL and GWAS integration, this pipeline can be applied to other pairwise integrations. An example of such application is in trans analysis, where the fine-mapped regions might be identical between trans-xQTL and GWAS, representing a special case of this broader implementation.\n",
    "\n",
    "## Input\n",
    "\n",
    "Lists of SuSiE fine-mapping output objects, in RDS format, of `class(susie)` in R. \n",
    "- For xQTL the list is meta-data of format: `chr`, `start`, `end`, `original_data`, `conditions_top_loci`, `block_top_loci` where `original_data` is an RDS file, `conditions_top_loci` is showing which contexts have top loci table (potential signals) `block_top_loci` is the blocks have overlapped top loci variant with xQTL data. That file could be output from `fine_mapping_post_processing/overlap_qtl_gwas`.\n",
    "- For GWAS the list is meta-data of format: `chr`, `start`, `end`, `original_data`, `block_top_loci...` where `original_data` is an RDS file. That file could be output from `fine_mapping_post_processing/gwas_results_export`.\n",
    "- Context meta is a metafile that shows the analysis_names and the contained contexts. It can be used to identify the corresponding raw data for each context. \n",
    "\n",
    "## Analytical Logic\n",
    "- Enrichment \n",
    "\n",
    "1. **Identify GWAS Blocks:** Select GWAS blocks with top loci from Bellenguez data and using a single variant regression method. Locate the original filenames (`original_data`) for these blocks and map the analysis regions to identify **overlapping gene analysis regions** and corresponding QTL files with top loci table (`condition_top_loci`).\n",
    "   \n",
    "2. **Contexts in xQTL Meta-data:** Find contexts within the xQTL meta-data that include top loci results for each gene. Retrieve the corresponding original xQTL files (`original_data`) by referencing the context meta-data.\n",
    "\n",
    "3. **Execute xQTL GWAS Enrichment:** Perform `xqtl_gwas_enrichment` analysis to generate enrichment parameters (a0, a1) and calculate priors (p1, p2, p12).\n",
    "\n",
    "- Coloc\n",
    "1. **xQTL Meta-data Contexts:** Within the xQTL meta-data, identify contexts that include top loci results for each gene, indicated by `condition_top_loci`. Retrieve the corresponding original xQTL files (`original_data`) by referring back to the context meta-data. (Optional) Subset the QTL table with specifies gene list. \n",
    "\n",
    "2. **Original GWAS Files:** Identify GWAS blocks that contain **overlapping top loci variants** for each gene (`block_top_loci`) in above file. Utilize the GWAS list to locate the original filenames (`original_data`) for the identified GWAS block candidates.\n",
    "\n",
    "3. **Enrichment and Coloc Analysis:** Automatically execute `xqtl_gwas_enrichment` to enable enrichment analysis, generating priors for subsequent coloc analysis through logic defined in `enrichment`. Then, apply `susie_coloc` for coloc analysis on the selected xQTL and GWAS original files, analyzing each gene under each identified condition.\n",
    "\n",
    "## Output\n",
    "\n",
    "1. Enrichment analysis results --- this is a global enrichment estimate that combines all input data for each context. \n",
    "2. Colocalization results for regions of interest --- if `ld_meta_file_path` is provided, would also report coloc cs by coloc postprocessing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8d7a2-cfde-4221-9431-0ced7eab6957",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example\n",
    "enrichment\n",
    "```\n",
    "sos run ~/codes/xqtl-pipeline/pipeline/SuSiE_enloc.ipynb xqtl_gwas_enrichment   \\\n",
    "    --gwas_meta_data  /mnt/vast/hpc/csg/rf2872/Work/pecotmr/encoloc_test/gwas.block_results_db.tsv     \\\n",
    "    --xqtl_meta_data  /mnt/vast/hpc/csg/rf2872/Work/Multivariate/gwas/overlap_test/ROSMAP_eQTL.overlapped.gwas.tsv         \\\n",
    "    --xqtl_finemapping_obj preset_variants_result susie_result_trimmed              \\\n",
    "    --xqtl_varname_obj preset_variants_result variant_names             \\\n",
    "    --gwas_finemapping_obj AD_Bellenguez_2022 single_effect_regression susie_result_trimmed          \\\n",
    "    --gwas_varname_obj  AD_Bellenguez_2022 single_effect_regression variant_names         \\\n",
    "    --xqtl_region_obj  region_info   grange   \\\n",
    "    --qtl-path /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/rds_files         \\\n",
    "    --gwas_path /mnt/vast/hpc/csg/hs3393/RSS_QC/GWAS_finemapping_Feb22_7dataset/SuSiE_RSS \\\n",
    "    --context_meta /mnt/vast/hpc/homes/rf2872/codes/fungen-xqtl-analysis/resource/context_meta.tsv \n",
    "```\n",
    "\n",
    "coloc (would trigger enrichment automatically)\n",
    "```\n",
    " sos run ~/codes/xqtl-pipeline/pipeline/SuSiE_enloc.ipynb susie_coloc    \\\n",
    "    --gwas_meta_data  /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/demo_gwas/demo_gwas.block_results_db.tsv    \\\n",
    "    --xqtl_meta_data  /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/demo_overlap/demo_overlap.overlapped.gwas.tsv   \\\n",
    "    --xqtl_finemapping_obj preset_variants_result susie_result_trimmed              \\\n",
    "    --xqtl_varname_obj preset_variants_result variant_names             \\\n",
    "    --gwas_finemapping_obj AD_Bellenguez_2022 RSS_QC_RAISS_imputed susie_result_trimmed              \\\n",
    "    --gwas_varname_obj  AD_Bellenguez_2022 RSS_QC_RAISS_imputed variant_names             \\\n",
    "    --xqtl_region_obj  region_info   grange       \\\n",
    "    --qtl-path /mnt/vast/hpc/homes/rf2872/aws/rds_files    \\\n",
    "    --gwas_path /home/hs3393/RSS_QC/GWAS_finemapping_Apr9/univariate_rss    \\\n",
    "    --context_meta /mnt/vast/hpc/homes/rf2872/codes/xqtl-analysis/resource/context_meta.tsv      \\\n",
    "    --ld_meta_file_path /mnt/vast/hpc/csg/data_public/20240120_ADSP_LD_matrix/ld_meta_file.tsv \\\n",
    "    --cwd demo_coloc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4434e2-65d3-4ac0-b249-1fd445b71e77",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "- eg: `gwas_meta_data`    \n",
    "output from `fine_mapping_post_processing/gwas_results_export`\n",
    "\n",
    "```\n",
    "#chr\tstart\tend\tregion_id\tTSS\toriginal_data\tcombined_data\tcombined_data_sumstats\tconditions\tconditions_top_loci\n",
    "chr1\t101384274\t104443097\t1_101384274-104443097\tNA\t1_101384274-104443097.susie_rss.rds\tgwas.1_101384274-104443097.cis_results_db.export.rds\tgwas.1_101384274-104443097.cis_results_db.export_sumstats.rds\tNA\tNA\n",
    "chr19\t44935906\t46842901\t19_44935906-46842901\tNA\t19_44935906-46842901.susie_rss.rds\tgwas.19_44935906-46842901.cis_results_db.export.rds\tgwas.19_44935906-46842901.cis_results_db.export_sumstats.rds\tAD_Bellenguez_2022,AD_Jansen_2021,AD_Kunkle_Stage1_2019,AD_Wightman_Full_2021,AD_Wightman_Excluding23andMe_2021,AD_Wightman_ExcludingUKBand23andME_2021\tAD_Wightman_ExcludingUKBand23andME_2021.qc_impute,AD_Wightman_ExcludingUKBand23andME_2021.qc_only\tAD_Wightman_ExcludingUKBand23andME_2021.qc_impute\n",
    "```\n",
    "\n",
    "\n",
    "- eg: `xqtl_meta_data` \n",
    "\n",
    "\n",
    "\n",
    "for enrichment: output from `fine_mapping_post_processing/cis_results_export`; for coloc: output from `fine_mapping_post_processing/overlap_qtl_gwas`, the difference between them is without or with last 2 columns: `block_top_loci`, `final_combined_data` to document overlapped block info at variant level\n",
    "\n",
    "\n",
    "```\n",
    "#chr\tstart\tend\tregion_id\tTSS\toriginal_data\tcombined_data\tcombined_data_sumstats\tconditions\tconditions_top_loci\tblock_top_loci\tfinal_combined_data\n",
    "chr1\t167600000\t171480000\tENSG00000000457\t169894266\tMSBB_eQTL.ENSG00000000457.univariate_susie_twas_weights.rds, ROSMAP_Kellis_eQTL.ENSG00000000457.univariate_susie_twas_weights.rds\tFungen_xQTL.ENSG00000000457.cis_results_db.export.rds\tFungen_xQTL.ENSG00000000457.cis_results_db.export_sumstats.rds\tBM_10_MSBB_eQTL,BM_22_MSBB_eQTL,BM_36_MSBB_eQTL,BM_44_MSBB_eQTL,Ast_Kellis_eQTL\tBM_22_MSBB_eQTL,BM_44_MSBB_eQTL\t\t\n",
    "chr19\t41840000\t47960000\tENSG00000130203\t44905790\tROSMAP_Kellis_eQTL.ENSG00000130203.univariate_susie_twas_weights.rds, ROSMAP_Bennett_Klein_pQTL.ENSG00000130203.univariate_susie_twas_weights.rds\tFungen_xQTL.ENSG00000130203.cis_results_db.export.rds\tFungen_xQTL.ENSG00000130203.cis_results_db.export_sumstats.rds\tMic_Kellis_eQTL,DLPFC_Bennett_pQTL\tMic_Kellis_eQTL\t19_44935906-46842901\tFungen_xQTL.ENSG00000130203.cis_results_db.export.overlapped.gwas.rds\n",
    "chr20\t49934867\t53560000\tENSG00000000419\t50958554\tMSBB_eQTL.ENSG00000000419.univariate_susie_twas_weights.rds\tFungen_xQTL.ENSG00000000419.cis_results_db.export.rds\tFungen_xQTL.ENSG00000000419.cis_results_db.export_sumstats.rds\tBM_10_MSBB_eQTL,BM_22_MSBB_eQTL\tBM_22_MSBB_eQTL\tFungen_xQTL.ENSG00000000419.cis_results_db.export.overlapped.gwas.rds\n",
    "```\n",
    "- eg: `context_meta` \n",
    "\n",
    "should be updated as more analysis is done, we used analysis_name and context in this analysis\n",
    "```\n",
    "analysis_name\tcohort\tcontext\n",
    "KNIGHT_pQTL\tKNIGHT\tKnight_pQTL_brain,Knight_eQTL_brain\n",
    "MSBB_eQTL\tMSBB\tBM_10_MSBB_eQTL,BM_22_MSBB_eQTL,BM_36_MSBB_eQTL,BM_44_MSBB_eQTL\n",
    "MIGA_eQTL\tMIGA\tMiGA_GTS_eQTL,MiGA_SVZ_eQTL,MiGA_THA_eQTL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-implement",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Workdir\n",
    "parameter: cwd = path(\"output\")\n",
    "# A list of file paths for fine-mapped GWAS results. \n",
    "parameter: gwas_meta_data = path\n",
    "# A list of file paths for fine-mapped xQTL results. \n",
    "parameter: xqtl_meta_data = path\n",
    "# Optional: if a region list is provide the enrichment analysis will be focused on provided region. \n",
    "# The LAST column of this list will contain the ID of regions to focus on\n",
    "parameter: region_list = path()\n",
    "# Optional: if a region name is provided \n",
    "# the analysis would be focused on the union of provides region list and region names\n",
    "parameter: region_name = []\n",
    "# It is required to input the name of the analysis\n",
    "parameter: name = f\"{xqtl_meta_data:bnn}.{gwas_meta_data:bnn}\"\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 200\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5m\"\n",
    "# Memory expected: quite large for enrichment analysis but small for xQTL colocalization\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "#Optional table name in xQTL RDS files to get fine mapping results (eg 'susie_result_trimmed ').\n",
    "parameter: xqtl_finemapping_obj = []\n",
    "#Optional table name in xQTL RDS files to get variable names (eg ' variant_names ').\n",
    "parameter: xqtl_varname_obj = []\n",
    "#Optional table name in GWAS RDS files to get fine mapping results (eg 'AD_Bellenguez_2022 single_effect_regression susie_result_trimmed ').\n",
    "parameter: gwas_finemapping_obj = []\n",
    "#Optional table name in GWAS RDS files to get variable names(eg 'AD_Bellenguez_2022 single_effect_regression variant_names ').\n",
    "parameter: gwas_varname_obj = []\n",
    "#Optional table name in xQTL RDS files to get region info (eg 'susie_result_trimmed region_info grange ').\n",
    "parameter: xqtl_region_obj = []\n",
    "#Optional table name in GWAS RDS files to get region info (eg 'AD_Bellenguez_2022 single_effect_regression region_info grange ').\n",
    "parameter: gwas_region_obj = []\n",
    "#Directory path for GWAS orignal finemapping results \n",
    "parameter: gwas_path = ''\n",
    "#Directory path for xQTL orignal finemapping results \n",
    "parameter: qtl_path = ''\n",
    "# a meta file showing the context and corresponding analysis_name\n",
    "parameter: context_meta = path()\n",
    "# Optional: if a region list is provide the analysis will be focused on provided region. \n",
    "# The LAST column of this list will contain the ID of regions to focus on\n",
    "# Otherwise, all regions with both genotype and phenotype files will be analyzed\n",
    "parameter: region_list = path()\n",
    "# Optional: if a region name is provided \n",
    "# the analysis would be focused on the union of provides region list and region names\n",
    "parameter: region_name = []\n",
    "# use conditions_top_loci_minp column or not, which can reduce a lot computing resource by pick top 1 isoform\n",
    "parameter: minp = False\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "def group_by_region(lst, partition):\n",
    "    # from itertools import accumulate\n",
    "    # partition = [len(x) for x in partition]\n",
    "    # Compute the cumulative sums once\n",
    "    # cumsum_vector = list(accumulate(partition))\n",
    "    # Use slicing based on the cumulative sums\n",
    "    # return [lst[(cumsum_vector[i-1] if i > 0 else 0):cumsum_vector[i]] for i in range(len(partition))]\n",
    "    return partition\n",
    "\n",
    "def make_unique_data(data):\n",
    "    return ','.join(set(data.split(',')))\n",
    "\n",
    "def generate_meta_dataframe(meta_data_path):\n",
    "    \"\"\"Generate a new long metadata by converting to context:analysis_name (1:1).\"\"\"\n",
    "    meta = pd.read_csv(meta_data_path, sep='\\t')\n",
    "    new_meta = pd.DataFrame()\n",
    "    contexts = pd.unique(meta['context'].str.split(',', expand=True).stack().str.strip())\n",
    "\n",
    "    for context in contexts:\n",
    "        mask = meta['context'].str.contains(context)\n",
    "        tmp = pd.DataFrame({\n",
    "            'context': [context],\n",
    "            'analysis_name': [','.join(meta.loc[mask, 'analysis_name'])]\n",
    "        })\n",
    "        new_meta = pd.concat([new_meta, tmp], ignore_index=True)\n",
    "\n",
    "    return new_meta\n",
    "\n",
    "def generate_condition_based_dataframe(xqtl_df, minp):\n",
    "    \"\"\"Generate a new long table by converting to condition and region:original_data (1:1).\"\"\"\n",
    "    # only consider the QTL contexts that have top loci data\n",
    "    condition_column = 'conditions_top_loci_minp' if minp else 'conditions_top_loci'\n",
    "    conditions = pd.unique(xqtl_df[condition_column].str.split(',', expand=True).stack().str.strip())\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    for condition in conditions:\n",
    "        escaped_condition = re.escape(condition)\n",
    "        mask = xqtl_df[condition_column].str.contains(escaped_condition, case=False, regex=True)\n",
    "        \n",
    "        # Iterate through each unique region in the filtered data\n",
    "        unique_regions = pd.unique(xqtl_df.loc[mask, 'region_id'])\n",
    "        for region_id in unique_regions:\n",
    "            region_mask = (xqtl_df['region_id'] == region_id) & mask\n",
    "            tmp = pd.DataFrame({\n",
    "                'condition': [condition],\n",
    "                'region_id': [region_id],\n",
    "                'QTL_original_data': [','.join(xqtl_df.loc[region_mask, 'original_data'])],\n",
    "                'GWAS_original_data': [','.join(xqtl_df.loc[region_mask, 'block_data'])]\n",
    "            })\n",
    "            new_df = pd.concat([new_df, tmp], ignore_index=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def merge_and_filter_dfs(new_df, new_meta):\n",
    "    \"\"\"Merge and filter the dataframes based on condition/context where context is a substring of condition, and analysis_name to pick the corresponding original files.\"\"\"\n",
    "    # Explode the QTL data into separate rows\n",
    "    new_df = new_df.set_index(['condition', 'region_id', 'GWAS_original_data'])['QTL_original_data'].str.split(',', expand=True).stack().reset_index(name='QTL_original_data').drop('level_3', axis=1)\n",
    "    new_df['analysis_name_prefix'] = new_df['QTL_original_data'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "    # Create a custom merge logic to match context as a substring of condition\n",
    "    def custom_merge(row, df_meta):\n",
    "        # Filter meta dataframe to find any context that is part of the condition string\n",
    "        sub_df = df_meta[df_meta['context'].apply(lambda x: x in row['condition'])]\n",
    "        if not sub_df.empty:\n",
    "            return sub_df\n",
    "        else:\n",
    "            return pd.DataFrame(columns=df_meta.columns)  # Return an empty DataFrame with the same columns if no match found\n",
    "\n",
    "    # Apply custom merge function row-wise and concatenate results\n",
    "    results = [custom_merge(row, new_meta) for index, row in new_df.iterrows()]\n",
    "    merged_df = pd.concat(results, keys=new_df.index).reset_index(level=1, drop=True).join(new_df, how='outer')\n",
    "\n",
    "    # Filter rows where analysis_name_prefix matches analysis_name exactly\n",
    "    filtered_df = merged_df[merged_df['analysis_name_prefix'].str.strip() == merged_df['analysis_name'].str.strip()]\n",
    "\n",
    "    # Drop unnecessary columns and duplicates\n",
    "    filtered_df = filtered_df.drop(columns=['analysis_name_prefix', 'context']).drop_duplicates()\n",
    "    filtered_df['GWAS_original_data'] = filtered_df['GWAS_original_data'].apply(make_unique_data)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def prepare_final_paths(filtered_df, qtl_path, gwas_path):\n",
    "    \"\"\"Prepare final paths for QTL and GWAS original data.\"\"\"\n",
    "    filtered_df['QTL_original_data'] = filtered_df['QTL_original_data'].apply(\n",
    "        lambda x: ','.join(f\"{qtl_path}/{file_name.strip()}\" for file_name in x.split(','))\n",
    "    )\n",
    "    filtered_df['GWAS_original_data'] = filtered_df['GWAS_original_data'].apply(\n",
    "        lambda x: ','.join(f\"{gwas_path}/{file_name.strip()}\" for file_name in x.split(','))\n",
    "    )\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9aca6-2acb-480c-973d-9cbbc199f41a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# get overlapped regions by gene and block region for enrichment analysis\n",
    "[get_analysis_regions: shared = \"regional_data\"]\n",
    "import pandas as pd\n",
    "\n",
    "def process_dataframes_with_toploci(xqtl_meta_data, gwas_meta_data):\n",
    "    \"\"\"Process the XQTL and GWAS dataframes.\"\"\"\n",
    "    xqtl_df = pd.read_csv(xqtl_meta_data, sep=\"\\t\")\n",
    "    # filter xQTL data with the ones have overlapped top loci variants with GWAS data\n",
    "    xqtl_df = xqtl_df[xqtl_df['conditions_top_loci_minp' if minp else 'conditions_top_loci'].notna()]\n",
    "\n",
    "    gwas_df = pd.read_csv(gwas_meta_data, sep=\"\\t\")\n",
    "    gwas_df = gwas_df[gwas_df['conditions_top_loci'].notna()]\n",
    "    # e.g. gwas_finemapping_obj = ['AD_Bellenguez_2022', 'single_effect_regression', 'susie_result_trimmed']\n",
    "    # filter gwas data with find variants in specified cohort 'AD_Bellenguez_2022' and method 'single_effect_regression'\n",
    "    gwas_finemapping_obj_filtered = [obj for obj in gwas_finemapping_obj if obj != 'susie_result_trimmed']\n",
    "    if len(gwas_finemapping_obj_filtered) > 0:\n",
    "        pattern = '|'.join(gwas_finemapping_obj_filtered)\n",
    "        gwas_df = gwas_df[gwas_df['conditions_top_loci'].str.contains(pattern)]\n",
    "\n",
    "    xqtl_df = overlapped_analysis_region(xqtl_df, gwas_df)\n",
    "    return xqtl_df, gwas_df\n",
    "\n",
    "\n",
    "\n",
    "def overlapped_analysis_region(xqtl_df, gwas_df):\n",
    "    # Create an empty dataframe to store overlapping xQTL records\n",
    "    overlapped_xqtl_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each row in the GWAS dataframe\n",
    "    for index, gwas_row in gwas_df.iterrows():\n",
    "        gwas_chr = gwas_row['#chr']\n",
    "        gwas_start = gwas_row['start']\n",
    "        gwas_end = gwas_row['end']\n",
    "        gwas_block_id = gwas_row['original_data']  # Assuming each GWAS row has a unique block ID\n",
    "        \n",
    "        # Filter xQTL dataframe for the same chromosome\n",
    "        same_chr_xqtl_df = xqtl_df[xqtl_df['#chr'] == gwas_chr]\n",
    "        \n",
    "        # Find overlapping xQTL regions with the current GWAS region\n",
    "        overlapping_xqtl = same_chr_xqtl_df[((same_chr_xqtl_df['start'] <= gwas_end) & \n",
    "                                             (same_chr_xqtl_df['end'] >= gwas_start))].copy() # Add .copy() to avoid SettingWithCopyWarning\n",
    "        \n",
    "        # Check if there are any overlapping xQTLs\n",
    "        if not overlapping_xqtl.empty:\n",
    "            # Use .loc to safely assign 'block_data' to avoid the SettingWithCopyWarning\n",
    "            overlapping_xqtl.loc[:, 'block_data'] = gwas_block_id\n",
    "            \n",
    "            # Append the overlapping xQTLs to the accumulated dataframe\n",
    "            overlapped_xqtl_df = pd.concat([overlapped_xqtl_df, overlapping_xqtl], ignore_index=True)\n",
    "        \n",
    "    # Group by xQTL region and concatenate 'block_data'\n",
    "    overlapped_xqtl_df['block_data'] = overlapped_xqtl_df.groupby(['#chr', 'start', 'end'])['block_data'].transform(lambda x: ','.join(x))\n",
    "    overlapped_xqtl_df = overlapped_xqtl_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return overlapped_xqtl_df\n",
    "\n",
    "\n",
    "xqtl_df, gwas_df = process_dataframes_with_toploci(xqtl_meta_data, gwas_meta_data)\n",
    "\n",
    "region_ids=[]\n",
    "# If region_list is provided, read the file and extract IDs\n",
    "if not region_list.is_dir():\n",
    "    if region_list.is_file():\n",
    "        region_list_df = pd.read_csv(region_list, sep='\\t', header=None, comment = \"#\")\n",
    "        region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs\n",
    "    else:\n",
    "        raise ValueError(\"The region_list path provided is not a file.\")\n",
    "        \n",
    "if len(region_name) > 0:\n",
    "    region_ids = list(set(region_ids).union(set(region_name)))\n",
    "    \n",
    "if len(region_ids) > 0:\n",
    "    xqtl_df = xqtl_df[xqtl_df['region_id'].isin(region_ids)]\n",
    "    \n",
    "new_df = generate_condition_based_dataframe(xqtl_df, minp)\n",
    "\n",
    "# if there is only one original data file, we don't have to map to context meta\n",
    "if (new_df['QTL_original_data'].str.split(',').apply(lambda x: len(x) in [0, 1]).all() and not context_meta.is_file()):\n",
    "    filtered_df = new_df.copy()\n",
    "    filtered_df['GWAS_original_data'] = filtered_df['GWAS_original_data'].apply(make_unique_data)\n",
    "else:\n",
    "    filtered_df = merge_and_filter_dfs(new_df, generate_meta_dataframe(context_meta))\n",
    "\n",
    "filtered_df = prepare_final_paths(filtered_df, qtl_path, gwas_path)\n",
    "filtered_df = filtered_df.groupby('condition').agg({\n",
    "    'GWAS_original_data': lambda x: ','.join(x),\n",
    "    'QTL_original_data': lambda x: ','.join(x)\n",
    "}).reset_index()\n",
    "regional_data = {\n",
    "    'data': [row['QTL_original_data'].split(',') for _, row in filtered_df.iterrows()],\n",
    "    'conditions': [(f\"{row['condition']}\", *row['GWAS_original_data'].split(',')) for _, row in filtered_df.iterrows()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885fc43-2777-4e2c-9345-e3fa1f1911d3",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get overlapped regions from flatten table, to get the regions with overlapped variants and select those regions for coloc analysis\n",
    "[get_overlapped_analysis_regions: shared = \"overlapped_regional_data\"]\n",
    "import pandas as pd\n",
    "def map_blocks_to_data(blocks, mapping_dict):\n",
    "    \"\"\"Map blocks to data using a provided mapping dictionary.\"\"\"\n",
    "    mapped_data = ','.join(mapping_dict.get(block.strip(), 'NA') for block in blocks.split(','))\n",
    "    return mapped_data\n",
    "\n",
    "def process_dataframes(xqtl_meta_data, gwas_meta_data):\n",
    "    \"\"\"Process the XQTL and GWAS dataframes.\"\"\"\n",
    "    xqtl_df = pd.read_csv(xqtl_meta_data, sep=\"\\t\")\n",
    "    # filter xQTL data with the ones have overlapped top loci variants with GWAS data\n",
    "    xqtl_df = xqtl_df[xqtl_df['block_top_loci'].notna()]\n",
    "\n",
    "    gwas_df = pd.read_csv(gwas_meta_data, sep=\"\\t\")    \n",
    "    gwas_df = gwas_df[gwas_df['conditions_top_loci'].notna()]\n",
    "    # e.g. gwas_finemapping_obj = ['AD_Bellenguez_2022', 'single_effect_regression', 'RSS_QC_RAISS_imputed']\n",
    "    # filter gwas data with find variants in specified cohort 'AD_Bellenguez_2022' and method 'RSS_QC_RAISS_imputed'\n",
    "    gwas_finemapping_obj_filtered = [obj for obj in gwas_finemapping_obj if obj != 'susie_result_trimmed' and obj != 'RSS_QC_RAISS_imputed']\n",
    "    if len(gwas_finemapping_obj_filtered) > 0:\n",
    "        pattern = '|'.join(gwas_finemapping_obj_filtered)\n",
    "        gwas_df = gwas_df[gwas_df['conditions_top_loci'].str.contains(pattern)]\n",
    "\n",
    "    gwas_df = gwas_df[gwas_df['region_id'].isin(xqtl_df['block_top_loci'].str.split(',').explode().unique())]\n",
    "\n",
    "    region_to_combined_data = dict(zip(gwas_df['region_id'], gwas_df['original_data']))\n",
    "    # and only consider the overlapped GWAS blocks\n",
    "    xqtl_df['block_data'] = xqtl_df['block_top_loci'].apply(map_blocks_to_data, args=(region_to_combined_data,))\n",
    "    xqtl_df['block_data'] = xqtl_df['block_data'].str.replace(',NA', '').str.replace('NA,', '')\n",
    "\n",
    "    return xqtl_df, gwas_df\n",
    "\n",
    "xqtl_df, gwas_df = process_dataframes(xqtl_meta_data, gwas_meta_data)\n",
    "\n",
    "region_ids=[]\n",
    "# If region_list is provided, read the file and extract IDs\n",
    "if not region_list.is_dir():\n",
    "    if region_list.is_file():\n",
    "        region_list_df = pd.read_csv(region_list, sep='\\t', header=None, comment = \"#\")\n",
    "        region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs\n",
    "    else:\n",
    "        raise ValueError(\"The region_list path provided is not a file.\")\n",
    "        \n",
    "if len(region_name) > 0:\n",
    "    region_ids = list(set(region_ids).union(set(region_name)))\n",
    "    \n",
    "if len(region_ids) > 0:\n",
    "    xqtl_df = xqtl_df[xqtl_df['region_id'].isin(region_ids)]\n",
    "    \n",
    "    \n",
    "new_df = generate_condition_based_dataframe(xqtl_df, minp)\n",
    "\n",
    "# if there is only one original data file, we don't have to map to context meta\n",
    "if (new_df['QTL_original_data'].str.split(',').apply(lambda x: len(x) in [0, 1]).all() and not context_meta.is_file()):\n",
    "    filtered_df = new_df.copy()\n",
    "    filtered_df['GWAS_original_data'] = filtered_df['GWAS_original_data'].apply(make_unique_data)\n",
    "else:\n",
    "    filtered_df = merge_and_filter_dfs(new_df, generate_meta_dataframe(context_meta))\n",
    "\n",
    "filtered_df = prepare_final_paths(filtered_df, qtl_path, gwas_path)\n",
    "\n",
    "overlapped_regional_data = {\n",
    "    'data': [row['QTL_original_data'].split(',') for _, row in filtered_df.iterrows()],\n",
    "    'conditions': [(f\"{row['condition']}@{row['region_id']}\", *row['GWAS_original_data'].split(',')) for _, row in filtered_df.iterrows()]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-carnival",
   "metadata": {
    "kernel": "SoS",
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[xqtl_gwas_enrichment]\n",
    "depends: sos_variable(\"regional_data\")\n",
    "stop_if(len(regional_data['data']) == 0, f'No files left for analysis')\n",
    "\n",
    "meta = regional_data['conditions']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta\"\n",
    "output: f'{cwd:a}/{name}.{_meta[0]}.enrichment.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(tidyverse)\n",
    "    library(pecotmr)\n",
    "    # RDS files for GWAS data\n",
    "    gwas_finemapped_data = c(${paths([x for x in _meta[1:len(_meta)]]):r,})\n",
    "    # RDS files for xQTL data\n",
    "    xqtl_finemapped_data = c(${paths([x for x in _input]):r,})\n",
    "    enrich_result = xqtl_enrichment_wrapper(gwas_files = gwas_finemapped_data, xqtl_files = xqtl_finemapped_data, \n",
    "                                                xqtl_finemapping_obj =  c(\"${_meta[0]}\",${\",\".join(['\"%s\"' % x  for x in xqtl_finemapping_obj]) if len(xqtl_finemapping_obj) != 0 else \"NULL\"}), \n",
    "                                                xqtl_varname_obj =   c(\"${_meta[0]}\",${\",\".join(['\"%s\"' % x  for x in xqtl_varname_obj]) if len(xqtl_varname_obj) != 0 else \"NULL\"}), \n",
    "                                                gwas_finemapping_obj =  c(${\",\".join(['\"%s\"' % x for x in gwas_finemapping_obj]) if len(gwas_finemapping_obj) != 0 else \"NULL\"}), \n",
    "                                                gwas_varname_obj =  c(${\",\".join(['\"%s\"' % x for x in gwas_varname_obj]) if len(gwas_varname_obj) != 0 else \"NULL\"}))\n",
    "    saveRDS(enrich_result, ${_output:ar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-benchmark",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_coloc]\n",
    "depends: sos_variable(\"overlapped_regional_data\")\n",
    "# depends: sos_step(\"xqtl_gwas_enrichment\") #changed\n",
    "stop_if(len(overlapped_regional_data['data']) == 0, f'No files left for analysis')\n",
    "# skip enrichment or not\n",
    "parameter: skip_enrich=False\n",
    "# filter lbf by cs as default in susie coloc. default is False means filtering by V > prior_tol\n",
    "parameter: filter_lbf_cs = False\n",
    "# ld reference path for postprocessing \n",
    "parameter: ld_meta_file_path = path()\n",
    "meta = overlapped_regional_data['conditions']\n",
    "input: overlapped_regional_data[\"data\"], group_by = lambda x: group_by_region(x, overlapped_regional_data[\"data\"]), group_with = \"meta\"\n",
    "# output: f'{cwd:a}/{step_name[:-2]}/{name}.{_meta[0]}.coloc.rds'\n",
    "output: f'{cwd:a}/{step_name}/{name}.{_meta[0]}.coloc.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(tidyverse)\n",
    "    library(pecotmr)\n",
    "    library(coloc) \n",
    "    # RDS files for xQTL data\n",
    "     # RDS files for xQTL data\n",
    "    xqtl_finemapped_datas = c(${paths([x for x in _input]):r,})\n",
    "    coloc_res <- list()\n",
    "    # are we doing something like this? that means results are by each context, and each one has \n",
    "    for(xqtl_finemapped_data in xqtl_finemapped_datas){\n",
    "      qtl_dat <- readRDS(xqtl_finemapped_data)\n",
    "      gene = names(qtl_dat)\n",
    "      context = \"${_meta[0]}\" %>% str_split(.,\"@\",simplify = T) %>% .[,1] \n",
    "      gene_region = pecotmr:::get_nested_element(qtl_dat[[1]],  c(context,\"region_info\", \"grange\"))\n",
    "  \n",
    "      # Step 1: find relevant GWAS regions that overlap each the xQTL region of interest\n",
    "      gwas_finemapped_datas <- c(${ \",\".join(['\"%s\"' % x for x in _meta[1:]])}) \n",
    "      gwas_finemapped_datas <- gwas_finemapped_datas[grep('rds$',gwas_finemapped_datas)]\n",
    " \n",
    "      gwas_regions <- gwas_finemapped_datas %>% basename %>% str_extract(., \"chr\\\\d+_\\\\d+_\\\\d+\")\n",
    "      overlap_index <- NULL\n",
    "      for (i in 1:length(gwas_regions)) {\n",
    "        region <- gwas_regions[i]\n",
    "        split_region <- unlist(strsplit(region, \"_\"))\n",
    "        block_chrom <- as.numeric(split_region[1] %>% gsub(\"chr\",\"\",.))\n",
    "        block_start <- as.numeric(split_region[2] %>% strsplit(., \"-\") %>% unlist %>% .[1])\n",
    "        block_end <- as.numeric(split_region[2] %>% strsplit(., \"-\") %>% unlist %>% .[2])\n",
    "        if (gene_region$chrom == block_chrom && (gene_region$start <= block_end |  gene_region$end >= block_start)) {\n",
    "          overlap_index <- c(overlap_index, i)\n",
    "        }\n",
    "      }\n",
    "  \n",
    "     if (!is.null(overlap_index)) {\n",
    "       gwas_finemapped_data <- gwas_finemapped_datas[overlap_index]\n",
    "  \n",
    "       # Step 2: load enrichment analysis results\n",
    "       # Extract values for p1, p2, and p12\n",
    "     if(${\"FALSE\" if skip_enrich else \"TRUE\"}){\n",
    "       enrich_file = paste0('${cwd:a}','/', '${name}', '.' ,context,'.enrichment.rds')\n",
    "       p1 <-  readRDS(enrich_file)[[1]]$`Alternative (coloc) p1`\n",
    "       p2 <-  readRDS(enrich_file)[[1]]$`Alternative (coloc) p2`\n",
    "       p12 <-  readRDS(enrich_file)[[1]]$`Alternative (coloc) p12`\n",
    "      \n",
    "       message(\"Priors are P1:\", p1, \"; p2: \", p2, \"; p12: \", p12)\n",
    "     } else {\n",
    "       p1 = 1e-4\n",
    "       p2 = 1e-4\n",
    "       p12 = 5e-6\n",
    "       message(\"Priors are using default, P1: 1e-4, P2: 1e-4, P12: 5e-6\" )\n",
    "     }\n",
    "       # Step 3: Apply colocalization analysis between each condition and GWAS\n",
    "       coloc_res[[gene]] <- coloc_wrapper(xqtl_file = xqtl_finemapped_data, gwas_files = gwas_finemapped_data, \n",
    "                                          xqtl_finemapping_obj =  c(context,${\",\".join(['\"%s\"' % x  for x in xqtl_finemapping_obj]) if len(xqtl_finemapping_obj) != 0 else \"NULL\"}), \n",
    "                                          xqtl_varname_obj =   c(context,${\",\".join(['\"%s\"' % x  for x in xqtl_varname_obj]) if len(xqtl_varname_obj) != 0 else \"NULL\"}), \n",
    "                                          gwas_finemapping_obj =  c(${\",\".join(['\"%s\"' % x for x in gwas_finemapping_obj]) if len(gwas_finemapping_obj) != 0 else \"NULL\"}), \n",
    "                                          gwas_varname_obj =  c(${\",\".join(['\"%s\"' % x for x in gwas_varname_obj]) if len(gwas_varname_obj) != 0 else \"NULL\"}),\n",
    "                                          xqtl_region_obj =   c(context,${\",\".join(['\"%s\"' % x  for x in xqtl_region_obj]) if len(xqtl_region_obj) != 0 else \"NULL\"}), \n",
    "                                          gwas_region_obj =  c(${\",\".join(['\"%s\"' % x for x in gwas_region_obj]) if len(gwas_region_obj) != 0 else \"NULL\"}),\n",
    "                                          p1 = p1, p2 = p2, p12 = p12, filter_lbf_cs = ${\"FALSE\" if skip_enrich else \"TRUE\"})\n",
    "\n",
    "        if (${\"TRUE\" if ld_meta_file_path.is_file() else \"FALSE\"}) {\n",
    "          if(length(coloc_res[[gene]]) > 2) {\n",
    "              coloc_res[[gene]] <- coloc_post_processor(coloc_res[[gene]], LD_meta_file_path = ${ld_meta_file_path:r}, analysis_region = coloc_res[[gene]]$analysis_region)\n",
    "            if(!is.null(coloc_res[[gene]]$sets$cs))  writeLines(coloc_res[[gene]]$sets$cs %>% unlist, gsub(\"rds$\",\"coloc_res\",\"${_output}\"))\n",
    "          } else { message(\"No coloc results were generated.\") }\n",
    "        }\n",
    "      \n",
    "      } else {\n",
    "        message(\"No overlap was found between GWAS blocks and QTL analysis region.\")\n",
    "        coloc_res <-  \"No overlap was found between GWAS blocks and QTL analysis region.\"\n",
    "      }\n",
    "    }\n",
    "    saveRDS(coloc_res, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
