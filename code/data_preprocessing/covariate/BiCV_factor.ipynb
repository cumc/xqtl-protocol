{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integrated-reference",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Factor analysis using Bi-Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-visibility",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This module use an implement of the following paper\n",
    "> Owen, Art & Wang, Jingshu. (2015). Bi-Cross-Validation for Factor Analysis. Statistical Science. 31. 10.1214/15-STS539. \n",
    "\n",
    "The software used is \n",
    "> A versatile toolkit for molecular QTL mapping and meta-analysis at scale\n",
    "Corbin Quick, Li Guan, Zilin Li, Xihao Li, Rounak Dey, Yaowu Liu, Laura Scott, Xihong Lin\n",
    "bioRxiv 2020.12.18.423490; doi: https://doi.org/10.1101/2020.12.18.423490\n",
    "\n",
    "\n",
    "## Cautions\n",
    "\n",
    "- Notice that the command options are different from those on the APEX website documentation. The commands on the documentation page does not work (last updated September 2021). The commands below were constructed and tested by our team based on our understanding of the program, without input from APEX authors.\n",
    "\n",
    "\n",
    "## Input and output\n",
    "\n",
    "1. An indexed bed.gz file with the same format as [PEER factor analysis](https://cumc.github.io/xqtl-pipeline/code/data_preprocessing/covariate/PEER_factor.html).\n",
    "2. A cov file with the same format as [PEER factor analysis](https://cumc.github.io/xqtl-pipeline/code/data_preprocessing/covariate/PEER_factor.html).\n",
    "3. An indexed vcf.gz file.\n",
    "\n",
    "## Output \n",
    "\n",
    "1. A cov.gz file with the same format as [PEER factor analysis](https://cumc.github.io/xqtl-pipeline/code/data_preprocessing/covariate/PEER_factor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-effort",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n",
    " \n",
    "Both of the `ALL.log2cpm.bed.chr12.mol_phe.bed.gz` and `ALL.log2cpm.bed.chr12.mol_phe.bed.gz.tbi` are needed. \n",
    "\n",
    "Because the MWE only contains 10 genes but 400+ samples. The computed N will be far greater than the number of genes. Therefore in the MWE the N is fixed to be 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506cb7b-2e5d-4250-bb16-beb42f122cd3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/BiCV_factor.ipynb BiCV \\\n",
    "   --cwd output \\\n",
    "   --phenoFile ALL.log2cpm.bed.chr12.mol_phe.bed.gz  \\\n",
    "   --container containers/apex.sif  \\\n",
    "   --N 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2d98d-9fcd-4cf7-9130-dabcb231095a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954282ec-ce9f-40ad-b277-7499d4ddcbef",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run BiCV_factor.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  fake_vcf\n",
      "  BiCV\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd output (as path)\n",
      "                        The output directory for generated files. MUST BE FULL\n",
      "                        PATH\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        The molecular phenotype matrix\n",
      "  --covFile . (as path)\n",
      "                        The covariate file\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --container ''\n",
      "                        Software container option\n",
      "  --name ''\n",
      "  --N 0 (as int)\n",
      "                        N factors, if not specify, calculated based on sample\n",
      "                        size according to GTeX\n",
      "  --iteration 10 (as int)\n",
      "                        The number of iteration\n",
      "\n",
      "Sections\n",
      "  fake_vcf:\n",
      "  BiCV:\n"
     ]
    }
   ],
   "source": [
    "sos run BiCV_factor.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-photographer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files. MUST BE FULL PATH\n",
    "parameter: cwd = path(\"output\")\n",
    "# The molecular phenotype matrix\n",
    "parameter: phenoFile = path\n",
    "# The covariate file\n",
    "parameter: covFile = path(\".\")\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "parameter: entrypoint={('micromamba run -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "parameter: name = \"\"\n",
    "# N factors, if not specify, calculated based on sample size according to GTeX\n",
    "parameter: N = 0\n",
    "# The number of iteration\n",
    "parameter: iteration = 10\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(phenoFile,\"\\t\",index_col = 3).drop([\"#chr\",\"start\",\"end\"],axis = 1)\n",
    "if N == 0:\n",
    "    if len(data.columns) < 150:\n",
    "        N = 15\n",
    "    elif len(data.columns) < 250:\n",
    "        N = 30\n",
    "    elif len(data.columns) < 350:\n",
    "        N = 45\n",
    "    else:\n",
    "        N = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0eaf6-9baa-4eee-b5b1-caf34dee21c3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fake_vcf]\n",
    "# For cluster jobs, number commands to run per job\n",
    "import time\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.fake.vcf.gz'\n",
    "#task: trunk_workers = 1,trunk_size = job_size , walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container, expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    ## Add fake header\n",
    "    cat(paste(\"##fileformat=VCFv4.2\\n##fileDate=$[time.strftime(\"%Y%m%d\",time.localtime())]\\n##source=FAKE\\n\"), file=$[_output:nr], append=FALSE)\n",
    "    ## Add colnames based on bed\n",
    "    pheno = read_delim(\"$[_input]\", delim = \"\\t\",n_max = 1)\n",
    "    colnames(pheno)[1:3] = c(\"#CHROM\",\"POS\",\"ID\") \n",
    "    pheno = cbind(pheno[1:3]%>%mutate(REF = \"A\", ALT = \"C\", QUAL = \".\",FILTER = \".\", INFO = \"PR\", FORMAT = \"GT\"),pheno[,5:ncol(pheno)])\n",
    "    pheno%>%write_delim($[_output:nr],delim = \"\\t\",col_names = T, append = T)\n",
    "bash: container=container, expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', entrypoint = entrypoint\n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p vcf $[_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guided-circumstances",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[BiCV]\n",
    "input:  output_from(\"fake_vcf\"),phenoFile\n",
    "output: f'{cwd:a}/{_input[1]:bnn}.BiCV.cov.gz'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container, expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', entrypoint = entrypoint\n",
    "    apex factor \\\n",
    "        --out $[_output[0]:nn] \\\n",
    "        --iter $[iteration] \\\n",
    "        --factors $[N] \\\n",
    "        --bed $[_input[1]] \\\n",
    "        --vcf $[_input[0]] \\\n",
    "        --threads $[numThreads]  $[ f'--cov {covFile}' if covFile.is_file() else '']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
