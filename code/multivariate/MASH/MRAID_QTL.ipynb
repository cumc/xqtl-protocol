{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0409bbe-1ed5-4340-a2b4-4a3d39fe334e",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# MRAID For QTLs\n",
    "This notebook is to perform MRAID analysis for different targets with QTL data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60354146-50c1-4ae8-b9f0-804209b52e55",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    }
   ],
   "source": [
    "wc -l ~/Work/MR/2023.4_MR/output/metabolics/Metabolon_Bile_Biocrate_targets_df.csv|cut -f1 -d ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592d3ea-99ca-42ed-9a77-7d21d560de1e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run ~/codes/xqtl-pipeline/pipeline/MRAID_QTL.ipynb/ mraid_qtl    \\\n",
    "    --n 840 \\\n",
    "    --targets_df \"~/Work/MR/2023.4_MR/output/metabolics/Metabolon_Bile_Biocrate_targets_df.csv\"  \\\n",
    "    --con \"metabolics_pval_beta_0.001\"    \\\n",
    "    --qtl \"metaQTL\"    \\\n",
    "    --p_cut 0.001 \\\n",
    "    --pval_beta 1 \\\n",
    "    -s build -J 200 -q csg -c ~/test/csg.yml   &> mraid_meta_1.2.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8cdca3-ee61-429e-9734-a803e8af5f2f",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "wc -l /mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv|cut -f1 -d ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740647e-4caa-4f56-8942-377b4705574d",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "for i in 0.01 0.001 0.0001 0.00001;\n",
    "do\n",
    "    nohup sos run ~/codes/xqtl-pipeline/pipeline/MRAID_QTL.ipynb/ mraid_qtl \\\n",
    "        --n 19 \\\n",
    "        --targets_df \"/mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv\" \\\n",
    "        --con ADlist_lit_eQTL_GWAS_${i} \\\n",
    "        --qtl \"eQTL\" \\\n",
    "        --p_cut ${i} \\\n",
    "        --pval_beta 0 \\\n",
    "        -s build -J 200 -q csg -c ~/test/csg.yml &> mraid_eQTL_${i}.log &\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a040bcd2-ac6a-4597-a66f-2c63a284b772",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "for i in 0.01 0.001 0.0001 0.00001;\n",
    "do\n",
    "    n=$(($(wc -l < /mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv) - 1))\n",
    "    nohup sos run ~/codes/xqtl-pipeline/pipeline/MRAID_QTL.ipynb/ mraid_qtl \\\n",
    "        --n $n \\\n",
    "        --targets_df \"/mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv\" \\\n",
    "        --con ADlist_lit_eQTL_GWAS_${i} \\\n",
    "        --qtl \"eQTL\" \\\n",
    "        --p_cut ${i} \\\n",
    "        --pval_beta 0 \\\n",
    "        -s build -J 200 -q csg -c ~/test/csg.yml &> mraid_eQTL_${i}.log &\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163bb19-e168-4d6b-96f8-747452b00192",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "for i in 0.01 0.001 0.0001 0.00001;\n",
    "do\n",
    "    n=$(($(wc -l < /mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv) - 1))\n",
    "    nohup sos run ~/codes/xqtl-pipeline/pipeline/MRAID_QTL.ipynb/ mraid_qtl \\\n",
    "        --n $n \\\n",
    "        --targets_df \"/mnt/vast/hpc/csg/rf2872/Work/MR/2023.4_MR/output/ADlist_lit/Causal_AD_genes_from_literature_targets_df.csv\" \\\n",
    "        --con ADlist_lit_pQTL_GWAS_${i} \\\n",
    "        --qtl \"pQTL\" \\\n",
    "        --p_cut ${i} \\\n",
    "        --pval_beta 0 \\\n",
    "        -s build -J 200 -q csg -c ~/test/csg.yml &> mraid_eQTL_${i}.log &\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913b5aa-eb96-4742-ab79-1505c66f8254",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f676c2-3143-4155-a68a-9cdd436c675c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./')\n",
    "# The filename prefix for output data\n",
    "parameter: name=\"test\"\n",
    "parameter: job_size = 1\n",
    "parameter: container = ''\n",
    "parameter: table_name = \"\"\n",
    "parameter: con = str\n",
    "parameter: qtl = str\n",
    "parameter: p_cut = 0.001\n",
    "parameter: targets_df = path\n",
    "parameter: per_chunk = 10\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: datadir = \"\"\n",
    "import pandas as pd\n",
    "#parameter: analysis_units = path\n",
    "parameter: pval_beta = 0\n",
    "# handle N = per_chunk data-set in one job\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('target')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f1ca2-ec26-4d76-9d78-9ab5c8b6138f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# perform mraid analysis with QTL data\n",
    "[mraid_qtl_1]\n",
    "import os\n",
    "import pandas as pd\n",
    "#parameter: analysis_units = path\n",
    "#regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('target')]\n",
    "parameter: n = 10\n",
    "n  = [x+1 for x in range(n)]\n",
    "input: for_each = 'n'\n",
    "output: f\"{cwd:a}/{con}/{qtl}/sig_{p_cut}/res_mraid_{con}_p_cut_{p_cut}_{_n}.csv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '24h',  mem = '80G', tags = f'{_output:bn}'  \n",
    "\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout' \n",
    "    library(data.table)\n",
    "    library(tidyverse)\n",
    "    library(UpSetR)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    library(\"data.table\")\n",
    "    library(stringr)\n",
    "    library(RcppCNPy)\n",
    "    library(arrow)\n",
    "    library(reticulate)\n",
    "    library(MRAID)    \n",
    "    find_SNP_from_sum<-function(ref,refpath,SNP,ID=\"variant\",full_chr=FALSE,snp.df=NULL,ref_with_fullpath=NULL,IDsep=\":\",suffix='.norminal.cis_long_table.txt',IDsep_in_sum=\"_\"){\n",
    "        chr<-unique(stringr::str_split(SNP,IDsep,simplify=T)[,1])\n",
    "        if(isTRUE(full_chr))chr.use<-chr else chr.use<-gsub(\"chr\",\"\",chr)\n",
    "        for(i in 1:length(chr.use))try({\n",
    "            c<-chr.use[i]\n",
    "            use.ref<-ref[grep(paste0(\"[.]\",c,suffix),ref)]\n",
    "            if(isTRUE(ref_with_fullpath)){\n",
    "                tmp.f <- data.table::fread(use.ref[i],sep=\"\\t\",header=T)} else {\n",
    "                tmp.f <- data.table::fread(paste0(refpath,\"/\",use.ref),sep=\"\\t\",header=T)\n",
    "            }\n",
    "            if(stringr::str_split_fixed(tmp.f[[ID]],IDsep,n=2)[1,1]!=chr[i]){\n",
    "                tmp.f[[ID]]<-sub(IDsep_in_sum,IDsep,tmp.f[[ID]])\n",
    "            }\n",
    "            tmp.f<-tmp.f[tmp.f[[ID]] %in% SNP,]\n",
    "            snp.df<-rbind(snp.df,tmp.f)    \n",
    "        })\n",
    "        return(snp.df)\n",
    "    }\n",
    "        # mraid function\n",
    "        mraid <- function(target,path, qtl, res = NULL, p_cut = 1, targets_df, con = \"ADGWAS\",outcome=\"GWAS\",pval_beta=FALSE) {\n",
    "        chr=targets_df[targets_df$targets == target, \"chromosome\"]%>%unique()\n",
    "            if (qtl == \"eQTL\") {\n",
    "                exp.chr <- fread(paste0(\"~/Work/MR/2023.4_MR/data/sumtats/eQTL/dlpfc_batch_all.rnaseqc.low_expression_filtered.outlier_removed.tmm.expression.bed.processed_phenotype.per_chrom_dlpfc_batch_all.rnaseqc.ROSMAP_covariates.ROSMAP_NIA_WGS.pca.PEER.txt.\", chr, \".norminal.cis_long_table.txt\"))\n",
    "            }\n",
    "            if (qtl == \"pQTL\") {\n",
    "                exp.chr <- fread(paste0(\"~/Work/MR/2023.4_MR/data/sumtats/pQTL/rf_standard/pheno_recipe_pheno.rosmap_cov.ROSMAP_NIA_WGS.leftnorm.filtered.filtered.prune.pca.resid.PEER.\", chr, \".norminal.cis_long_table.txt\"))\n",
    "                # there are so many duplicated rows in exp matrix\n",
    "                exp.chr <- exp.chr[-which(duplicated(exp.chr)), ]\n",
    "                # in pQTL files, the snps are chrx_tacg_... but in most files should be chrx:tacg_...\n",
    "                exp.chr$variant <- sub(\"_\", \":\", exp.chr$variant)\n",
    "            }\n",
    "            if (qtl == \"mQTL\") {\n",
    "                exp.chr <- fread(paste0(\"~/Work/MR/2023.4_MR/data/sumtats/mQTL/ROSMAP_arrayMethylation_covariates.sesame.methyl.beta.sample_matched.bed_BMIQ.bed.filter_na.bed.softImputed.bed.processed_phenotype.per_chrom_methy.peer.pca.chr\", chr, \".norminal.cis_long_table.txt\"))\n",
    "                exp.chr <- exp.chr %>% rename(\"chromosome\" = \"chrom\", \"position\" = \"pos\")\n",
    "                exp.chr$chromosome <- gsub(\"chr\", \"\", exp.chr$chromosome)\n",
    "            }\n",
    "            if (qtl == \"haQTL\") {\n",
    "                exp.chr <- fread(paste0(\"~/Work/MR/2023.4_MR/data/sumtats/haQTL/h3k9ac_bed_recipe_h3k9ac_whole.k9_cov.xqtl_protocol_data.filtered.related.filtered.extracted.pca.projected.resid.PEER.merged.\", chr, \".norminal.cis_long_table.txt\"))\n",
    "                exp.chr <- exp.chr %>% rename(\"chromosome\" = \"chrom\", \"position\" = \"pos\")\n",
    "                exp.chr$chromosome <- gsub(\"chr\", \"\", exp.chr$chromosome)\n",
    "            }\n",
    "            if (qtl == \"metaQTL\") {\n",
    "                exp.chr <- fread(list.files(paste0(\"~/Work/MR/2023.4_MR/data/sumtats/metaQTL/\", chr,\"/rf/\"),\"_rf.norminal.trans_long_table.txt$\",full.names = T))\n",
    "                exp.chr <- exp.chr %>% rename(\"chromosome\" = \"chrom\", \"position\" = \"pos\")\n",
    "                exp.chr$chromosome <- gsub(\"chr\", \"\", exp.chr$chromosome)\n",
    "                exp.chr$position <- str_split(exp.chr$position,\":\",simplify = T)[,2]%>%as.numeric()\n",
    "            }\n",
    "                ## 2. prapare the input for MR\n",
    "                ### 2.1 exposure GWAS sumstats\n",
    "                # get qtl Data\n",
    "                exp <- exp.chr[molecular_trait_id == target]\n",
    "                snps_ana_gene <- exp$variant\n",
    "                if(pval_beta==1){exp <- exp[pval_beta < p_cut, ]} else exp <- exp[pvalue < p_cut, ]\n",
    "                snps_asso_gene <- exp$variant\n",
    "                res <- data.table(target = target, n_snps_ana = length(snps_ana_gene), p_cut = p_cut, n_snps_asso = length(snps_asso_gene))\n",
    "                message(length(snps_asso_gene), \" SNPs associated with \", target)\n",
    "                if (length(snps_asso_gene) > 0) {\n",
    "                    ### 2.2 outcome GWAS sumstats\n",
    "                    # get snps' GWAS data\n",
    "                    if (outcome == \"GWAS\") {\n",
    "                        path <- \"/home/rf2872/Work/MR/2023.4_MR/data/sumtats/GWAS/\"\n",
    "                        out <- find_SNP_from_sum(ref = list.files(path), refpath = path, SNP = snps_asso_gene, suffix = \".sumstat.tsv\", full_chr = T, IDsep_in_sum = \"_\")\n",
    "                    } else {\n",
    "                        out.path <- paste0(\"/home/rf2872/Work/MR/2023.4_MR/data/sumtats/\",outcome)\n",
    "                        out <- find_SNP_from_sum(ref = list.files(out.path), refpath = out.path, SNP = snps_asso_gene, full_chr = F, IDsep_in_sum = \"_\")\n",
    "                        int_snps <- intersect(snps_asso_gene, out$variant)\n",
    "                    }\n",
    "                    int_snps <- intersect(snps_asso_gene, out$variant)\n",
    "                    if(length(int_snps)>0){\n",
    "                    ### 2.3/2.4 exposure LD matrix\n",
    "                    # since the LD files are saved separately accrodding to their postions, I'd like to use bedtools to map the SNPs to LD files\n",
    "                    LD <- read.table(\"/mnt/vast/hpc/csg/molecular_phenotype_calling/LD/output/1300_hg38_EUR_LD_blocks_LD/ROSMAP_NIA_WGS.leftnorm.filtered.filtered.ld.list\", header = F, sep = \"\\t\")\n",
    "                    LD.bed <- str_split(LD$V1, \"_\", simplify = T) %>% cbind(., LD)\n",
    "                    \n",
    "                    # if(qtl == \"eQTL\" | qtl == \"pQTL\"){\n",
    "                    exp_LD.bed <- data.frame(chrome = paste0(\"chr\", exp$chromosome), start = exp$position, end = (exp$position + nchar(exp$ref) - 1))\n",
    "                    # }\n",
    "                    # if(qtl == \"mQTL\"){\n",
    "                    # exp_LD.bed <- data.frame(chrome = exp$chrom, start = exp$pos, end = (exp$pos + nchar(exp$ref) - 1))\n",
    "                    # }\n",
    "                    options(bedtools.path = \"/home/rf2872/software/bedtools2/bin/\")\n",
    "                    LD.files <- bedtoolsr::bt.intersect(a = LD.bed, b = exp_LD.bed)\n",
    "                      \n",
    "                    # load python tools to read npz files, but there would be an error for npz1$f[[\"arr_1\"]], so I need to read the bim file to locate the snps. (Hao says they are in sam order)\n",
    "                    np <- import(\"numpy\")\n",
    "                    LD_files <- unique(LD.files$V5)\n",
    "                    \n",
    "                    # some snp sets could locate in more than 1 ld files. so I have to read those files separately and combine them (I don't know which function can do this easily, so I just write a new one)\n",
    "                    LD.list <- list()\n",
    "                    for (f in 1:length(LD_files)) {\n",
    "                        npz1 <- np$load(LD_files[f])\n",
    "                        ld.mtx <- npz1$f[[\"arr_0\"]]\n",
    "                        ld.snps <- stringr::str_split(LD_files[f], \"[.]\", simplify = T) %>%\n",
    "                            .[, -c(length(.), (length(.) - 1))] %>%\n",
    "                            paste(., collapse = \".\") %>%\n",
    "                            paste0(., \".bim\") %>%\n",
    "                            read.table(.) %>%\n",
    "                            .[, 2]\n",
    "                        colnames(ld.mtx) <- rownames(ld.mtx) <- ld.snps\n",
    "                        LD.list[[f]] <- as.data.frame(ld.mtx)\n",
    "                        realsnps.tmp <- intersect(colnames(LD.list[[f]]), int_snps)\n",
    "                        if(length(realsnps.tmp)>0) {\n",
    "                    LD.list[[f]] <- LD.list[[f]][realsnps.tmp, realsnps.tmp]%>%as.data.frame()\n",
    "                    colnames(LD.list[[f]]) <- rownames(LD.list[[f]]) <- realsnps.tmp} else LD.list[[f]]<-NA \n",
    "                        \n",
    "                    }      \n",
    "                    LD.list[sapply(LD.list,function(x) all(is.na(x)))] <- NULL\n",
    "                    \n",
    "                    if(length(LD.list)>0){\n",
    "                    u <- LD.list[[1]]\n",
    "                    if (length(LD.list) > 1) {\n",
    "                        for (x in 2:length(LD.list)) {\n",
    "                            t.col <- ncol(u) + ncol(LD.list[[x]])\n",
    "                            u.n <- matrix(ncol = t.col, nrow = t.col, 0)\n",
    "                            u.n[1:ncol(u), 1:ncol(u)] <- as.matrix(u)\n",
    "                            u.n[(ncol(u) + 1):ncol(u.n), (ncol(u) + 1):ncol(u.n)] <- as.matrix(LD.list[[x]])\n",
    "                            colnames(u.n) <- rownames(u.n) <- c(colnames(u), colnames(LD.list[[x]]))\n",
    "                            u <- u.n\n",
    "                        }\n",
    "                    }\n",
    "                      \n",
    "                    # the snps in LD matrix and sumstats files are not exactly same, so I need to get the overlapped ones\n",
    "                    realsnps <- intersect(colnames(u), int_snps)\n",
    "                    LD.out.m <- LD.exp.m <- as.matrix(u[realsnps, realsnps])\n",
    "                    res[, n_snps_real := length(realsnps)]\n",
    "                    message(length(realsnps), \" SNPs in \", target, \" analyzed in MRAID\")\n",
    "                      \n",
    "                    ### 2.5 exposure sample size\n",
    "                    # from [DLPFC ROSMAP](https://github.com/cumc/fungen-xqtl-analysis/blob/main/data/descriptor/qtl/ROSMAP_DLPFC_expression_qtl.md) (The number on this page is wrong on 4/11/2023, it should be ~950, let's set 900 for now)\n",
    "                    samplen1 <- 900\n",
    "                    ### 2.6 outcome sample size\n",
    "                    # from [Bellenguez GWAS paper](https://pubmed.ncbi.nlm.nih.gov/35379992/)(111,326 AD cases and 677,663 controls)\n",
    "                    samplen2 <- 788989\n",
    "                      \n",
    "                    ## 3. RUN MRAID\n",
    "                    exp.real <- exp[exp$variant %in% realsnps, ]\n",
    "                    exp.z <- as.numeric(exp.real$beta) / as.numeric(exp.real$se)\n",
    "                      \n",
    "                    out.real <- out[out$variant %in% realsnps, ]\n",
    "                    out.z <- as.numeric(out.real$beta) / as.numeric(out.real$se)\n",
    "                      \n",
    "                    res[, n_snps_real := length(realsnps)]\n",
    "                        \n",
    "                    # you can check the parameters info for MRAID  in [here](https://github.com/yuanzhongshang/MRAID/blob/main/man/MRAID.Rd)\n",
    "                    message(target, \" MRAID analysis...\")\n",
    "                      \n",
    "                    # running MRAID with a big LD matrix would cost so much time, I would like to document the time used\n",
    "                    start.time <- Sys.time()\n",
    "                    result <- tryCatch(MRAID(exp.z, out.z, LD.exp.m, LD.out.m, samplen1, samplen2,\n",
    "                        Gibbsnumber = 1000, burninproportion = 0.2, pi_beta_shape = 0.5,\n",
    "                        pi_beta_scale = 4.5, pi_c_shape = 0.5, pi_c_scale = 9.5, pi_1_shape = 0.5, pi_1_scale = 1.5, pi_0_shape = 0.05, pi_0_scale = 9.95\n",
    "                    ), error = function(x) {\n",
    "                        message(\"Can't get a valid LD matrix for \", target)\n",
    "                        return(NA)\n",
    "                    })\n",
    "                    end.time <- Sys.time()\n",
    "                    } else {\n",
    "                    res[, n_snps_real := 0]\n",
    "                    result <- NA\n",
    "                }\n",
    "                    } else {\n",
    "                    res[, n_snps_real := 0]\n",
    "                    result <- NA\n",
    "                }\n",
    "                } else {\n",
    "                    res[, n_snps_real := 0]\n",
    "                    result <- NA\n",
    "                }\n",
    "                \n",
    "                if (is.na(result[[1]])) {\n",
    "                    result <- matrix(nrow = 1, ncol = 7, NA)\n",
    "                    colnames(result) <- c(\"causal_effect\", \"causal_pvalue\", \"correlated_pleiotropy_effect\", \"sigmabeta\", \"sigmaeta\", \"sigma_error_1\", \"sigma_error_2\")\n",
    "                }\n",
    "                \n",
    "                result <- as.data.table(result)[, target := target]\n",
    "    \n",
    "                res <- tryCatch(merge(res, result, by = \"target\"), error = function(x) {\n",
    "                    return(res)\n",
    "                })\n",
    "                # I am afraid of receiveing error in final result, so I'd like to save the result per target....\n",
    "                #fwrite(res, paste0(outpath, \"res_mraid_\", qtl, \"_\", con, \"_p_cut_\", p_cut, \"_\", target, \".csv.gz\"))\n",
    "                return(res)\n",
    "          }\n",
    "      #out<-data.frame()\n",
    "      #for (f in c(${_input:r,})) {\n",
    "       targets_df<-data.table::fread(\"${targets_df}\")\n",
    "       target=targets_df$targets[${_n}+1]\n",
    "       eqtl.mr <- mraid(target=target,path=paste0(\"${cwd:a}\",\"/\"),qtl=\"${qtl}\",p_cut=${p_cut},con=\"${con}\",targets_df=targets_df,pval_beta=${pval_beta})\n",
    "       #fwrite(eqtl.mr, paste0(\"${_output:d}\",\"res_mraid_\",\"${con}\",\"_p_cut_\",\"{p_cut}\",f,\".csv\"))\n",
    "       #out<-rbind(out,eqtl.mr)\n",
    "      #}\n",
    "    fwrite(eqtl.mr, ${_output:r})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca89a002-308d-4599-92c5-4e85935e9400",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mraid_qtl_2]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{con}/{qtl}/sig_{p_cut}/all_res_mraid_{con}_p_cut_{p_cut}.csv\"\n",
    "task: trunk_workers = 1, walltime = '2h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "\n",
    "  \n",
    "bash: expand ='${ }', stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "     cd ${_input[0]:d}\n",
    "     echo 'target,n_snps_ana,p_cut,n_snps_asso,n_snps_real,causal_effect,causal_pvalue,correlated_pleiotropy_effect,sigmabeta,sigmaeta,sigma_error_1,sigma_error_2' > ${_output:r}\n",
    "     cat *.csv|grep -v n_snps_ana >> ${_output:r}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88385fc1-18ca-4943-b8aa-0a6305762947",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
