{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-ontario",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Genotype data formatting\n",
    "\n",
    "This module implements a collection of workflows used to format genotype data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-biotechnology",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-labor",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "The module streamlines conversion between PLINK and VCF formats (possibly more to add), specifically:\n",
    "\n",
    "1. Conversion between VCF and PLINK formats\n",
    "2. Split data (by specified input, by chromosomes, by genes)\n",
    "3. Merge data (by specified input, by chromosomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-balance",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-jewelry",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Depending on the analysis task, input files are specified in one of the following formats:\n",
    "\n",
    "1. A single Whole genome data in VCF format, or in PLINK bim/bed/fam bundle; Or,\n",
    "2. A list of VCF or PLINK bed file\n",
    "3. A singular column file containing a list of VCF or PLINK bed file\n",
    "4. A two column file containing a list of per chromosome VCF or PLINK bed file where the first column is chrom and 2nd column is file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-honduras",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "Genotype data after reformatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-hamilton",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Examples\n",
    "\n",
    "Minimal working example data-set as well as the singularity container `bioinfo.sif` can be downloaded from [Google Drive](https://drive.google.com/drive/u/0/folders/1ahIZGnmjcGwSd-BI91C9ayd_Ya8sB2ed).\n",
    "\n",
    "### PLINK file merger\n",
    "\n",
    "```\n",
    "sos run genotype_formatting.ipynb merge_plink \\\n",
    "    --genoFile data/genotype/chr1.bed data/genotype/chr6.bed \\\n",
    "    --cwd output/genotype \\\n",
    "    --name chr1_chr6 \\\n",
    "    --container container/bioinfo.sif\n",
    "```\n",
    "\n",
    "### Split by genes\n",
    "\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sterling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convertible-colony",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run genotype_formatting.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  plink_to_vcf\n",
      "  vcf_to_plink\n",
      "  plink_by_gene\n",
      "  plink_by_chrom\n",
      "  merge_plink\n",
      "  merge_vcf\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        Work directory & output directory\n",
      "  --container ''\n",
      "                        The filename name for containers\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 5h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --genoFile  paths\n",
      "\n",
      "                        the path to a bed file or VCF file, a vector of bed\n",
      "                        files or VCF files, or a text file listing the bed files\n",
      "                        or VCF files to process\n",
      "\n",
      "Sections\n",
      "  plink_to_vcf:\n",
      "  vcf_to_plink:\n",
      "  plink_by_gene_1:\n",
      "    Workflow Options:\n",
      "      --window 500000 (as int)\n",
      "                        cis window size\n",
      "      --region-list VAL (as path, required)\n",
      "                        Region definition\n",
      "  plink_by_chrom_1:\n",
      "    Workflow Options:\n",
      "      --chrom VAL VAL ... (as type, required)\n",
      "  plink_by_chrom_2, plink_by_gene_2:\n",
      "  merge_plink:\n",
      "    Workflow Options:\n",
      "      --name VAL (as str, required)\n",
      "                        File prefix for the analysis output\n",
      "  merge_vcf:\n",
      "    Workflow Options:\n",
      "      --name VAL (as str, required)\n",
      "                        File prefix for the analysis output\n"
     ]
    }
   ],
   "source": [
    "sos run genotype_formatting.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-fellowship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path\n",
    "# The filename name for containers\n",
    "parameter: container = ''\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# the path to a bed file or VCF file, a vector of bed files or VCF files, or a text file listing the bed files or VCF files to process\n",
    "parameter: genoFile = paths\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size\n",
    "cwd = f\"{cwd:a}\"\n",
    "\n",
    "import os\n",
    "def get_genotype_file(geno_file_paths):\n",
    "    #\n",
    "    def valid_geno_file(x):\n",
    "        suffixes = path(x).suffixes\n",
    "        if suffixes[-1] == '.bed':\n",
    "            return True\n",
    "        if len(suffixes)>1 and ''.join(suffixes[-2:]) == \".vcf.gz\":\n",
    "            return True\n",
    "        return False\n",
    "    #\n",
    "    def complete_geno_path(x, geno_file):\n",
    "        if not valid_geno_file(x):\n",
    "            raise ValueError(f\"Genotype file {x} should be VCF (end with .vcf.gz) or PLINK bed file (end with .bed)\")\n",
    "        if not os.path.isfile(x):\n",
    "            # relative path\n",
    "            if not os.path.isfile(f'{geno_file:ad}/' + x):\n",
    "                raise ValueError(f\"Cannot find genotype file {x}\")\n",
    "            else:\n",
    "                x = f'{geno_file:ad}/' + x\n",
    "        return x\n",
    "    # \n",
    "    def format_chrom(chrom):\n",
    "        if chrom.startswith('chr'):\n",
    "            chrom = chrom[3:]\n",
    "        return chrom\n",
    "    # Inputs are either VCF or bed, or a vector of them \n",
    "    if len(geno_file_paths) > 1:\n",
    "        if all([valid_geno_file(x) for x in geno_file_paths]):\n",
    "            return paths(geno_file_paths)\n",
    "        else: \n",
    "            raise ValueError(f\"Invalid input {geno_file_paths}\")\n",
    "    # Input is one genotype file or text list of genotype files\n",
    "    geno_file = geno_file_paths[0]\n",
    "    if valid_geno_file(geno_file):\n",
    "        return path(geno_file)\n",
    "    else: \n",
    "        units = [x.strip().split() for x in open(geno_file).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "        if all([len(x) == 1 for x in units]):\n",
    "            return paths([complete_geno_path(x[0], geno_file) for x in units])\n",
    "        elif all([len(x) == 2 for x in units]):\n",
    "            genos = dict([(format_chrom(x[0]), path(complete_geno_path(x[1], geno_file))) for x in units])\n",
    "        else:\n",
    "            raise ValueError(f\"{geno_file} should contain one column of file names, or two columns of chrom number and corresponding file name\")\n",
    "        return genos\n",
    "                        \n",
    "genoFile = get_genotype_file(genoFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-dispatch",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## PLINK to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spanish-fundamentals",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_to_vcf]\n",
    "if isinstance(genoFile, dict):\n",
    "    genoFile = genoFile.values()\n",
    "\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.vcf.gz', \n",
    "        f'{cwd}/{_input:bn}.vcf.gz.tbi'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, volumes = [f'{_input:ad}:{_input:ad}']\n",
    "    plink --bfile ${_input:n} \\\n",
    "        --recode vcf-iid  \\\n",
    "        --out ${_output[0]:nn} \\\n",
    "        --threads ${numThreads} \\\n",
    "        --memory ${int(expand_size(mem) * 0.9)/1e06}\n",
    "\n",
    "    bgzip -l 9 ${_output[0]:n}  \n",
    "    tabix -f -p vcf ${_output[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-result",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## VCF to PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-headset",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[vcf_to_plink]\n",
    "if isinstance(genoFile, dict):\n",
    "    genoFile = genoFile.values()\n",
    "\n",
    "input: genoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:nn}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container = container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink --vcf ${_input} \\\n",
    "        --vcf-half-call m \\\n",
    "        --vcf-require-gt \\\n",
    "        --allow-extra-chr \\\n",
    "        --make-bed --out ${_output:n} \\\n",
    "        --threads ${numThreads} \\\n",
    "        --memory ${int(expand_size(mem) * 0.9)/1e06}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-preference",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Split PLINK by genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-answer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_gene_1]\n",
    "# cis window size\n",
    "parameter: window = 500000\n",
    "# Region definition\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "input: genoFile, for_each = 'regions'\n",
    "output: f'{cwd}/{region_list:bn}_plink_files/{_input[_regions[0]]:bn}.{_regions[3]}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{region_list:ad}:{region_list:ad}']\n",
    "    plink --bfile ${_input[_regions[0]]:an} \\\n",
    "        --make-bed \\\n",
    "        --out ${_output[0]:n} \\\n",
    "        --chr ${_regions[0]} \\\n",
    "        --from-bp ${f'1' if (int(_regions[1]) - window) < 0 else f'{(int(_regions[1]) - window)}'} \\\n",
    "        --to-bp ${int(_regions[2]) + window} \\\n",
    "        --allow-no-sex || touch ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-productivity",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Split PLINK by Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-fault",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_chrom_1]\n",
    "stop_if(len(genoFile)>1, msg = \"This workflow expects one input genotype file.\")\n",
    "parameter: chrom = list\n",
    "input: genoFile, for_each = \"chrom\"\n",
    "output: f'{cwd}/{_input:bn}_per_chrom/{_input:bn}.chrom_{_chrom}.bed'\n",
    "# look up for genotype file\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container, volumes = [f'{genoFile:ad}:{genoFile:ad}']\n",
    "    ##### Get the locus genotypes for $[_chrom]\n",
    "    plink --bfile $[_input:an] \\\n",
    "    --make-bed \\\n",
    "    --out $[_output[0]:n] \\\n",
    "    --chr $[_chrom] \\\n",
    "    --allow-no-sex || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-pressure",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_by_chrom_2, plink_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{_input[0]:d}/plink_files_list.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    cd ${_input[0]:d} && ls *.bed > ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-instrument",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Split VCF by Chromosome\n",
    "\n",
    "**FIXME: add this as needed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-issue",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge PLINK files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-development",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_plink]\n",
    "skip_if(len(genoFile) == 1)\n",
    "# File prefix for the analysis output\n",
    "parameter: name = str\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0.0\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 1e-06\n",
    "input: genoFile, group_by = 'all'\n",
    "output: f\"{cwd}/{name}.merge_list\", f\"{cwd}/{name}.bed\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[1]:bn}'\n",
    "\n",
    "with open(_output[0], 'w') as f:\n",
    "    f.write('\\n'.join([str(f'{x:n}') for x in _input[1:]]))\n",
    "\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[1]:n}.stderr', stdout = f'{_output[1]:n}.stdout'\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output[0]} \\\n",
    "    --make-bed \\\n",
    "    ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "    ${('--max-maf %s' % maf_max_filter) if maf_max_filter > 0 else ''} \\\n",
    "    ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "    ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "    ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "    --out ${_output[1]:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)/1e06}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-profit",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge VCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-listening",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_vcf]\n",
    "skip_if(len(genoFile) == 1)\n",
    "# File prefix for the analysis output\n",
    "parameter: name = str\n",
    "input: genoFile, group_by = 'all'\n",
    "output:  f\"{cwd}/{name}.vcf.gz\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    bcftools concat -Oz ${_input} > ${_output}\n",
    "    tabix -p vcf ${_output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
