{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# TensorQTL QTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook implements a workflow for using [tensorQTL](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1836-7) to perform QTL association testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- List of molecular phenotype files: a list of `bed.gz` files containing the table for the molecular phenotype. It should have a companion index file in `tbi` format.\n",
    "- List of genotypes in VCF format for each chromosome, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze.\n",
    "\n",
    "## Output\n",
    "\n",
    "For each chromosome, several of summary statistics files are generated, including both nominal test statistics for each test, as well as region (gene) level association evidence.\n",
    "\n",
    "The columns of nominal association result are as follows:\n",
    "\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance: Distance of the SNP to the gene transcription start site (TSS)\n",
    "- af: The allele frequency of this SNPs\n",
    "- ma_samples: Number of samples carrying the minor allele\n",
    "- ma_count: Total number of minor alleles across individuals\n",
    "- pval: Nominal P-value from linear regression\n",
    "- beta: Slope of the linear regression\n",
    "- se: Standard error of beta\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "\n",
    "\n",
    "The column specification of region (gene) level association evidence are as follows:\n",
    "\n",
    "- phenotype_id - Molecular trait identifier. (gene)\n",
    "- num_var - Total number of variants tested in cis\n",
    "- beta_shape1 - First parameter value of the fitted beta distribution\n",
    "- beta_shape2 - Second parameter value of the fitted beta distribution\n",
    "- true_df - Effective degrees of freedom the beta distribution approximation\n",
    "- pval_true_df - Empirical P-value for the beta distribution approximation\n",
    "- variant_id - ID of the top variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance - Distance of the SNP to the gene transcription start site (TSS)\n",
    "- ma_samples - Number of samples carrying the minor allele\n",
    "- ma_count - Total number of minor alleles across individuals\n",
    "- maf - Minor allele frequency in MiGA cohort\n",
    "- ref_factor - Flag indicating if the alternative allele is the minor allele in the cohort (1 if AF <= 0.5, -1 if not)\n",
    "- pval_nominal - Nominal P-value from linear regression\n",
    "- slope - Slope of the linear regression\n",
    "- slope_se - Standard error of the slope\n",
    "- pval_perm - First permutation P-value directly obtained from the permutations with the direct method\n",
    "- pval_beta - Second permutation P-value obtained via beta approximation. This is the one to use for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run TensorQTL.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  TensorQTL_cis\n",
      "  TensorQTL_trans\n",
      "\n",
      "Global Workflow Options:\n",
      "  --molecular-pheno-list VAL (as path, required)\n",
      "                        Path to the input molecular phenotype file, per chrm, in\n",
      "                        bed.gz format.\n",
      "  --covariate VAL (as path, required)\n",
      "                        Covariate file, in similar format as the molecular_pheno\n",
      "  --genotype-file-list VAL (as path, required)\n",
      "                        Genotype file in plink trio format, per chrm\n",
      "  --region-list . (as path)\n",
      "                        An optional subset of region list containing a column of\n",
      "                        ENSG gene_id to limit the analysis\n",
      "  --cwd . (as path)\n",
      "                        Path to the work directory of the analysis.\n",
      "  --job-size 2 (as int)\n",
      "                        Specify the number of jobs per run.\n",
      "  --container ''\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "  --window 1000000 (as int)\n",
      "                        Specify the scanning window for the up and downstream\n",
      "                        radius to analyze around the region of interest, in\n",
      "                        units of bp\n",
      "\n",
      "Sections\n",
      "  TensorQTL_cis_1:\n",
      "  TensorQTL_trans_1:\n",
      "    Workflow Options:\n",
      "      --batch-size 10000 (as int)\n",
      "      --pval-threshold 1e-05 (as float)\n",
      "      --maf-threshold 0.05 (as float)\n",
      "  TensorQTL_cis_2:\n",
      "  TensorQTL_trans_2:\n"
     ]
    }
   ],
   "source": [
    "sos run TensorQTL.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-list plink_files_list.txt \\\n",
    "    --phenotype-list MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd . \\\n",
    "    --container containers/TensorQTL.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to the input molecular phenotype file, per chrom, in bed.gz format.\n",
    "parameter: phenotype_list = path\n",
    "# Covariate file\n",
    "parameter: covariate_file = path\n",
    "# Genotype file in VCF format, per chrom\n",
    "parameter: genotype_list = path\n",
    "# An optional subset of regions of molecular features to analyze\n",
    "parameter: region_list = path()\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('.')\n",
    "# Prefix for the analysis output\n",
    "parameter: name = f\"{phenotype_list:bn}_{covariate_file:bn}\"\n",
    "# Specify the number of jobs per run.\n",
    "parameter: job_size = 2\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest, in units of bp\n",
    "parameter: window = 1000000\n",
    "\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = '12h'\n",
    "parameter: mem = '16G'\n",
    "\n",
    "import pandas as pd\n",
    "molecular_pheno_chr_inv = pd.read_csv(phenotype_list,sep = \"\\t\")\n",
    "geno_chr_inv = pd.read_csv(genotype_list,sep = \"\\t\")\n",
    "input_inv = molecular_pheno_chr_inv.merge(geno_chr_inv, on = \"#id\")\n",
    "input_inv = input_inv.values.tolist()\n",
    "chr_inv = [x[0] for x in input_inv]\n",
    "file_inv = [x[1:] for x in input_inv ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## cisQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_cis_1]\n",
    "input: file_inv, group_by = len(file_inv[0]), group_with = \"chr_inv\"\n",
    "output: f'{cwd:a}/{name}.cis_qtl_pairs.{_chr_inv}.parquet', # This design is necessary to match the pattern of map_norminal output\n",
    "        f'{cwd:a}/{name}.emprical.cis_sumstats.txt',\n",
    "        long_table = f'{cwd:a}/{name}.norminal.cis_long_table.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    import os, time\n",
    "    os.stderr.write(f\"cisQTL association testing starts at {time.asctime(time.localtime())}\")\n",
    "    \n",
    "    ## Define parameter\n",
    "    plink_prefix_path = $[_input[1]:nr]\n",
    "    expression_bed = $[_input[0]:r]\n",
    "    covariates_file = \"$[covariate_file]\"\n",
    "\n",
    "    ## Load Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    ### Filter by the optional keep gene\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list]\",\"\\t\")\n",
    "        keep_gene = region[\"gene_ID\"].to_list()\n",
    "        phenotype_df = phenotype_df.query('gene_ID in keep_gene')\n",
    "        phenotype_pos_df = phenotype_pos_df.query('gene_ID in keep_gene')\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    if \"chr\" not in variant_df.chrom[0]:\n",
    "        phenotype_pos_df.chr = [x.replace(\"chr\",\"\") for x in phenotype_pos_df.chr]\n",
    "    ## cis-QTL mapping: nominal associations for all variant-phenotype pairs\n",
    "    cis.map_nominal(genotype_df, variant_df,\n",
    "                phenotype_df,\n",
    "                phenotype_pos_df,\n",
    "                \"$[_output[0]:nnn]\", covariates_df=covariates_df, window=$[window] )\n",
    "\n",
    "    ## Load the parquet and save it as txt\n",
    "    pairs_df = pd.read_parquet(\"$[_output[0]]\")\n",
    "    pairs_df.columns.values[6]  = \"pval\"\n",
    "    pairs_df.columns.values[7]  = \"beta\"\n",
    "    pairs_df.columns.values[8]  = \"se\"\n",
    "    pairs_df = pairs_df.assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-1])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-2])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0].split(\":\")[1])).assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0]))\n",
    "    pairs_df.to_csv(\"$[_output[2]]\", sep='\\t',index = None)\n",
    "    cis_df = cis.map_cis(genotype_df, variant_df, \n",
    "                     phenotype_df,\n",
    "                     phenotype_pos_df,\n",
    "                     covariates_df=covariates_df, seed=999, window=$[window] )\n",
    "    cis_df.index.name = \"gene_id\"\n",
    "    cis_df.to_csv(\"$[_output[1]]\", sep='\\t')\n",
    "    os.stderr.write(f\"cisQTL association testing ends at {time.asctime(time.localtime())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## TransQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_trans_1]\n",
    "input: file_inv,group_by = len(file_inv[0]), group_with = \"chr_inv\"\n",
    "output: f'{cwd:a}/{path(_input[0]):bnnn}.trans_sumstats.txt'\n",
    "parameter: batch_size = 10000\n",
    "parameter: pval_threshold = 1e-5\n",
    "parameter: maf_threshold = 0.05\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', container = container,stdout = f'{_output[0]}.stdout'\n",
    "    touch  $[_output[0]].time_stamp\n",
    "python: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container =container \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    ## Defineing parameter\n",
    "    plink_prefix_path = $[path(_input[1]):nr]\n",
    "    expression_bed = $[path(_input[0]):r]\n",
    "    covariates_file = \"$[covariate_file]\"\n",
    "\n",
    "    # FIXME: this is not being used\n",
    "    Prefix = \"$[_output[0]:nnn]\"\n",
    "    ## Loading Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "\n",
    "\n",
    "    ##### Filter by the optional keep gene\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list]\",\"\\t\")\n",
    "        keep_gene = region[\"gene_ID\"].to_list()\n",
    "        phenotype_df = phenotype_df.query('gene_ID  in keep_gene')\n",
    "        phenotype_pos_df = phenotype_pos_df.query('gene_ID  in keep_gene')\n",
    "\n",
    "\n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    ## Trans analysis\n",
    "    trans_df = trans.map_trans(genotype_df, phenotype_df, covariates_df, batch_size=$[batch_size],\n",
    "                           return_sparse=True, pval_threshold=$[pval_threshold], maf_threshold=$[maf_threshold])\n",
    "    ## Filter out cis signal\n",
    "    trans_df = trans.filter_cis(trans_df, phenotype_pos_df.T.to_dict(), variant_df, window=$[window])\n",
    "    ## Output\n",
    "    trans_df.columns.values[1]  = \"gene_ID\"\n",
    "    trans_df.columns.values[2]  = \"pval\"\n",
    "    trans_df.columns.values[3]  = \"beta\"\n",
    "    trans_df.columns.values[4]  = \"se\"\n",
    "    trans_df = trans_df.assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0])).assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[2])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[1])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0]))\n",
    "    trans_df.to_csv(\"$[_output]\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association results processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_cis_2]\n",
    "input:  group_by = \"all\"\n",
    "output: f'{cwd:a}/TensorQTL_recipe.tsv',f'{cwd:a}/TensorQTL_column_info.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import csv\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#chr\" : [int(x.split(\".\")[-4].replace(\"chr\",\"\")) for x in  [$[_input[\"long_table\"]:r,]]],\n",
    "    \"sumstat_dir\" : [$[_input[\"long_table\"]:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"GENE,CHR,POS,A0,A1\",\n",
    "          \"CHR\": \"chrom\",\n",
    "          \"POS\": \"pos\",\n",
    "          \"A0\": \"ref\",\n",
    "          \"A1\": \"alt\",\n",
    "          \"SNP\": \"variant_id\",\n",
    "          \"STAT\": \"beta\",\n",
    "          \"SE\": \"se\",\n",
    "          \"P\": \"pval\",\n",
    "          \"TSS_D\": \"tss_distance\",\n",
    "          \"AF\": \"af\",\n",
    "          \"MA_SAMPLES\": \"ma_samples\",\n",
    "          \"MA_COUNT\": \"ma_count\",\n",
    "          \"GENE\": \"phenotype_id\"}), columns = [\"TensorQTL\"] )\n",
    "    data_tempt.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL_trans_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd:a}/TensorQTL_recipe.tsv',f'{cwd:a}/TensorQTL_column_info.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    import csv\n",
    "    import pandas as pd \n",
    "    data_tempt = pd.DataFrame({\n",
    "    \"#chr\" : [int(x.split(\".\")[-3].replace(\"chr\",\"\")) for x in  [$[_input:r,]]],\n",
    "    \"sumstat_dir\" : [$[_input:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"GENE,CHR,POS,A0,A1\",\n",
    "          \"CHR\": \"chrom\",\n",
    "          \"POS\": \"pos\",\n",
    "          \"A0\": \"ref\",\n",
    "          \"A1\": \"alt\",\n",
    "          \"SNP\": \"variant_id\",\n",
    "          \"STAT\": \"beta\",\n",
    "          \"SE\": \"se\",\n",
    "          \"P\": \"pval\",\n",
    "          \"AF\": \"af\",\n",
    "          \"GENE\": \"gene_ID\"}), columns = [\"TensorQTL\"] )\n",
    "    data_tempt.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
