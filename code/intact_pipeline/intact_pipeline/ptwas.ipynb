{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# PTWAS Implementation in R\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This module contains the software implementations to perform transcriptome-wide association analysis (TWAS). These methods are designed to perform rigorous causal inference connecting genes to complex traits. The statistical models and the key algorithms are described in the (manuscript](https://www.biorxiv.org/content/10.1101/808295v1).     \n",
    "**PTWAS using the ouptut from DAPG and is written by C++. Here we are going to use susie objects instead and convert the codes into R.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### NOTE 1\n",
    "double check the following code:\n",
    "```\n",
    "susie_df <- data.frame(\n",
    "                gene_id = gene_name,\n",
    "                variant = row.names(as.data.frame(susie_susie_obj$pip)),\n",
    "                weight = round(susie_susie_obj$mu[length(susie_susie_obj$sets$cs),], 4), \n",
    "                tissue =  \"${tissue}\")\n",
    "```\n",
    "\n",
    "1. should we use mu or coef.value\n",
    "2. should we use total length of cs or the corresponding index of CS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of this module is to perform PTWAS analysis from SuSiE objects, including:\n",
    "1. Extract weights from eQTL susie objects. \n",
    "2. Conversion of GWAS sumstats to the format with z-scores. \n",
    "3. Run PTWAS with R codes.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Input\n",
    "1. QTL susie tableï¼š\n",
    "    - This table has two columns for `moleculart_trait_id` and `susie_file`: target gene and corresponding susie output rds respectively.\n",
    "2. GWAS sumstats results (tsv format)\n",
    "3. region list \n",
    "4. LD refrence \n",
    "\n",
    "### Ouput\n",
    "1. susie weight table\n",
    "2. PTWAS results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Example\n",
    "We now run an example of this using the vcf file generated from the sample of susie eQTLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd /mnt/vast/hpc/csg/rf2872/Work/INTACT/ptwas_test\n",
    "\n",
    "sos run xqtl-pipeline/code/intact_pipeline/ptwas.ipynb susie_weight \\\n",
    "    --susie-table eqtl_susie_table_head30.txt  \\\n",
    "    --tissue DLPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    " sos run xqtl-pipeline/code/intact_pipeline/ptwas.ipynb gwas_ptwas_prep \\\n",
    "    --ptwas_weights output/DLPFC.eQTL.susie_reformat.txt \\\n",
    "    --gwas_basepath /mnt/vast/hpc/csg/ftp_lisanwanglab_sync/ftp_fgc_xqtl/projects/ADGWAS_Bellenguez_2022/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sos run /xqtl-pipeline/code/intact_pipeline/ptwas.ipynb ptwas_scan \\\n",
    "    --ptwas_weights output/DLPFC.eQTL.susie_reformat.txt \\\n",
    "    --gwas_path output/ADGWAS_Bellenguez_2022.gambitgwas.txt \\\n",
    "    --region_list /mnt/vast/hpc/csg/molecular_phenotype_calling/eqtl/dlpfc_region_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Workdir\n",
    "parameter: cwd = path(\"output\")\n",
    "# susie_table is the table of eQTL fine mapped results, which has two columns for gene and susie_fils\n",
    "parameter: susie_table = \"\"\n",
    "# This vcf is derived from the conversion of the susie rds for each gene, with the relevant information noted in the INFO column.\n",
    "#parameter: out_vcf = \"\"\n",
    "# file_table is the table of GWAS fine mapped results, which has two columns for LD blocks and susie_fils\n",
    "parameter: file_table = \"\"\n",
    "# out_file is a temporary file in the environment\n",
    "parameter: out_file = \"\"\n",
    "# the prefix of fastENLOC output \n",
    "parameter: out_pre = \"\"\n",
    "# the zipped file of out_vcf, which is derived from the conversion of the susie rds for each gene\n",
    "parameter: eqtl_vcf = \"\"\n",
    "# dataset \n",
    "parameter: tissue = ''\n",
    "# QTL data type\n",
    "parameter: QTL = 'eQTL'\n",
    "parameter: container = ''\n",
    "parameter: entrypoint={('micromamba run -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = \"5h\"\n",
    "parameter: mem = \"8G\"\n",
    "parameter: numThreads = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SuSiE weight \n",
    "\n",
    "The exsiting pipeline is using mu from SuSiE object. \n",
    "If we are going to use coef.value/posterior mean, we can skip this part and use the output from susie_post_processing instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[susie_weight_1]\n",
    "import pandas as pd\n",
    "df = pd.read_csv(susie_table)\n",
    "file_paths = []\n",
    "for i, group in df.groupby(df.index // 100):\n",
    "    output_file_path = f'{cwd}/cache/{tissue}.{QTL}.chunk_{i}.csv'\n",
    "    group.to_csv(output_file_path, index=False)\n",
    "    file_paths.append(output_file_path)  \n",
    "input: file_paths, group_by = 1\n",
    "output: f'{cwd}/cache/{_input:bn}.susie_reformat.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(susieR)\n",
    "    library(stringr)\n",
    "    library(tidyverse)\n",
    "    \n",
    "    susie_tbl = read.csv(\"${_input}\", sep = \"\\t\")\n",
    "    susie_files = susie_tbl$susie_file\n",
    "    genes = susie_tbl$molecular_trait_id\n",
    "    \n",
    "    vcf_out = data.frame(chr=NULL, pos=NULL, var_id=NULL, ref = NULL, alt = NULL, info=NULL)\n",
    "    cumu_susie_r_df <- data.frame(matrix(nrow = 0, ncol = 4))\n",
    "    for(i in seq(1, length(genes))) {\n",
    "        susie_susie_obj <- readRDS(susie_files[i])$dlpfc_eqtl ##FIX\n",
    "        if ( length(susie_susie_obj$sets$cs)) {\n",
    "            \n",
    "            susie_df <- data.frame(\n",
    "                gene_id = genes[i],\n",
    "                variant = row.names(as.data.frame(susie_susie_obj$pip)),\n",
    "                weight = round(susie_susie_obj$mu[length(susie_susie_obj$sets$cs),], 4), \n",
    "                tissue =  \"${tissue}\")\n",
    "            if (nrow(cumu_susie_r_df) < 1) cumu_susie_r_df <- susie_df else cumu_susie_r_df <- rbind(cumu_susie_r_df, susie_df)\n",
    "        }\n",
    "    }\n",
    "    saveRDS(cumu_susie_r_df,\"${_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "[susie_weight_2]\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/{_input[0]:bnnn}.susie_reformat.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(susieR)\n",
    "    library(stringr)\n",
    "    library(tidyverse)\n",
    "    cumu_susie_r_df  <- NULL\n",
    "    all.list <- stringr::str_split(\"${_input}\", \" \", simplify = T)\n",
    "    for (i in all.list) {\n",
    "        tmp_cumu_susie_r_df <- readRDS(i)\n",
    "        # Print the feature scores for each condition\n",
    "        if (!is.null(tmp_cumu_susie_r_df)) {\n",
    "            if (is.null(cumu_susie_r_df)) {\n",
    "                cumu_susie_r_df <- tmp_cumu_susie_r_df\n",
    "            } else {\n",
    "                cumu_susie_r_df <- rbind(ocumu_susie_r_dfut, tmp_cumu_susie_r_df)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    formatted_r_data <- cumu_susie_r_df %>%\n",
    "        filter(abs(weight) > 0) %>%\n",
    "        distinct(gene_id, variant, tissue, .keep_all = TRUE) %>%\n",
    "        mutate(\n",
    "            CHR = sapply(strsplit(variant, \":\"), \"[[\", 1),\n",
    "            chrnum = as.numeric(gsub(\"chr\", \"\", CHR)),\n",
    "            pos = as.numeric(sapply(strsplit(variant, \"[:|_]\")), \"[[\", 2) )) %>%\n",
    "        arrange(chrnum, pos) %>%\n",
    "        select(-chrnum, -CHR, -pos)\n",
    "    formatted_r_data$weight <- format(formatted_r_data$weight, scientific = FALSE)\n",
    "    #write.table(cumu_susie_r_df,\"${_output}\", sep =\"\\t\", quote = F, row.names = F, col.names = F)\n",
    "    write_delim(formatted_r_data, \"${_output}\", delim = \"\\t\", append = FALSE, col_names = TRUE, quote = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "**output_1**: susie weight table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash",
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_id\tvariant\tweight\ttissue\n",
      "ENSG00000001460\tchr1:24080045_G_A\t 0.0641\tDLPFC\n",
      "ENSG00000001461\tchr1:24080045_G_A\t-0.0159\tDLPFC\n",
      "ENSG00000001460\tchr1:24080157_G_A\t-0.0335\tDLPFC\n",
      "ENSG00000001461\tchr1:24080157_G_A\t 0.0243\tDLPFC\n",
      "ENSG00000001460\tchr1:24080563_C_T\t-0.0210\tDLPFC\n",
      "ENSG00000001461\tchr1:24080563_C_T\t-0.0038\tDLPFC\n",
      "ENSG00000001460\tchr1:24080644_C_T\t-0.0335\tDLPFC\n",
      "ENSG00000001461\tchr1:24080644_C_T\t 0.0243\tDLPFC\n",
      "ENSG00000001460\tchr1:24080863_G_A\t-0.0357\tDLPFC\n"
     ]
    }
   ],
   "source": [
    "cd /mnt/vast/hpc/csg/rf2872/Work/INTACT/ptwas_test\n",
    "head output/DLPFC.eQTL.susie_reformat.txt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## GWAS data_prep \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[gwas_ptwas_prep]\n",
    "parameter: ptwas_weights=\"\"\n",
    "parameter: gwas_basepath=\"\"\n",
    "input: ptwas_weights, gwas_basepath\n",
    "output: f'{cwd}/{_input[1]:bn}.gambitgwas.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(tidyverse)\n",
    "    target_variants <- read_delim(\n",
    "        \"${ptwas_weights}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE) %>%\n",
    "        mutate(id = gsub(\":\", \"_\", variant)) %>%\n",
    "        pull(id) %>%\n",
    "        unique()\n",
    "\n",
    "    gwas_basepath <- \"${gwas_basepath}\"\n",
    "    gwas <- data.frame(matrix(ncol=12, nrow=0))\n",
    "\n",
    "    for (gwasfile in list.files(gwas_basepath)) {\n",
    "        gwaschr <- read_delim(\n",
    "            paste0(gwas_basepath, gwasfile),\n",
    "            delim = \"\\t\",\n",
    "            show_col_types = FALSE) %>%\n",
    "            filter(variant %in% target_variants)\n",
    "        gwas <- if (nrow(gwas) < 1) gwaschr else rbind(gwas, gwaschr)\n",
    "    }\n",
    "\n",
    "    #gwas$chromosome <- paste0('chr', gwas$chromosome)\n",
    "    gwas$ZSCORE <- gwas$beta/gwas$se\n",
    "    gwas$N <- gwas$n_cases + gwas$n_controls\n",
    "    gwas$SNP_ID <- gwas$variant\n",
    "    gambitgwas <- gwas %>% subset(select=c(\"chromosome\", \"position\", \"ref\", \"alt\", \"SNP_ID\", \"N\", \"ZSCORE\"))\n",
    "    colnames(gambitgwas) <- c(\"#CHR\", \"POS\", \"REF\", \"ALT\", \"SNP_ID\", \"N\", \"ZSCORE\")\n",
    "\n",
    "    write_delim(\n",
    "        gambitgwas,\n",
    "        \"${_output}\",\n",
    "        delim = \"\\t\",\n",
    "        append = TRUE,\n",
    "        col_names = TRUE,\n",
    "        quote = \"none\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## PTWAS scan\n",
    "This portion contains code for running the PTWAS scan as implemented in GAMBIT. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "### Input\n",
    "\n",
    "- eQTL Weights\n",
    "    File susiet contains eQTL weights (formatting is up-for-debate). Maybe column 1 is SNP and column 2 is the weight.\n",
    "- GWAS Z-Scores\n",
    "    File that contains GWAS z-scores (or what makes up the z-scores). Column 1 is SNP, column 2 can be z-scores.\n",
    "- LD reference\n",
    "- region list\n",
    "\n",
    "\n",
    "### Output\n",
    "\n",
    "Same output as GAMBIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#[ptwas_scan_1]\n",
    "parameter: ptwas_weights=\"\"\n",
    "parameter: gwas_path=\"\"\n",
    "parameter: region_list=\"\"\n",
    "input: ptwas_weights, gwas_path, region_list\n",
    "output: f'{cwd}/cache/input_dataframe.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(tidyverse)\n",
    "    library(harmonicmeanp)\n",
    "    handle_weights <- function(gwas_ids, weight_ids) {\n",
    "        return(unlist(lapply(\n",
    "            strsplit(gwas_ids, ':'),\n",
    "            function(x) {\n",
    "                POSs  <- as.double(sapply(strsplit(weight_ids, ':'), '[[', 2))\n",
    "                REFs <- sapply(strsplit(weight_ids, ':'), '[[', 3)\n",
    "                ALTs <- sapply(strsplit(weight_ids, ':'), '[[', 4)\n",
    "                for (i in 1:length(REFs)) {\n",
    "                    if (as.double(x[2]) == POSs[i]) {\n",
    "                        if (x[3] == REFs[i] & x[4] == ALTs[i]) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == ALTs[i] & x[4] == REFs[i]) {\n",
    "                            return(-1)\n",
    "                        } else if (x[3] == aflip(REFs[i]) & x[4] == aflip(ALTs[i])) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == aflip(ALTs[i]) & x[4] == aflip(REFs[i])) {\n",
    "                            return(-1)\n",
    "                        } else {\n",
    "                            return(0)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )))\n",
    "    }\n",
    "\n",
    "    debug_print <- function(gwas_ids, modifiers, weights, zscores, stat, denom, output) {\n",
    "        snpdf <- data.frame(\n",
    "            CHROM = sapply(strsplit(gwas_ids, ':'), '[[', 1),\n",
    "            POS = as.double(sapply(strsplit(gwas_ids, ':'), '[[', 2)),\n",
    "            VARIANT = gsub(\":\", \"_\", gwas_ids),\n",
    "            REF = sapply(strsplit(gwas_ids, ':'), '[[', 3),\n",
    "            ALT = sapply(strsplit(gwas_ids, ':'), '[[', 4),\n",
    "            MODIFIERS = modifiers,\n",
    "            WEIGHTS = weights,\n",
    "            ZSCORES = zscores) %>% arrange(POS)\n",
    "        cat(\"\\n\\nSNP info:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        write_delim(\n",
    "            snpdf,\n",
    "            output,\n",
    "            append = TRUE,\n",
    "            col_names = TRUE,\n",
    "            quote = \"none\")\n",
    "        cat(\"\\n\\nmodifiers:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$MODIFIERS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nweights:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$WEIGHTS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nz-stats:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$ZSCORES, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest score = \", stat, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest variance = \", denom, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "    }\n",
    "\n",
    "    burden <- function(weight_ids, gwas_ids, weights, zscores) {\n",
    "        modifiers <- handle_weights(gwas_ids, weight_ids)\n",
    "        weights <- modifiers * weights\n",
    "        \n",
    "        stat <- sum(weights * zscores)\n",
    "        denom <- sum(weights * weights)\n",
    "        zscore <- stat/sqrt(denom)\n",
    "\n",
    "        if (length(zscores) == 1) {\n",
    "            zscore <- zscores[[1]]\n",
    "            if (weights[[1]] < 0) {\n",
    "                zscore <- zscore * -1\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        pval <- pchisq( zscore * zscore, 1, lower.tail = FALSE)\n",
    "        \n",
    "        debug_print(gwas_ids, modifiers, weights, zscores, stat, denom, paste0(output_base, \"ptwas-scan.debug\"))\n",
    "\n",
    "        return(pval)\n",
    "    }\n",
    "\n",
    "    pval_HMP <- function(pvals) {\n",
    "        # https://search.r-project.org/CRAN/refmans/harmonicmeanp/html/pLandau.html\n",
    "        pvalues <- unique(pvals)\n",
    "        L <- length(pvalues)\n",
    "        HMP <- L/sum(pvalues^-1)\n",
    "\n",
    "        LOC_L1 <- 0.874367040387922\n",
    "        SCALE <- 1.5707963267949\n",
    "\n",
    "        return(pLandau(1/HMP, mu = log(L) + LOC_L1, sigma = SCALE, lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "    pcauchy <- function(x) {\n",
    "        return(0.5 + atan(x)/pi)\n",
    "    }\n",
    "\n",
    "    qcauchy <- function(q) {\n",
    "        return(tan(pi*(q - 0.5)))\n",
    "    }\n",
    "\n",
    "    pval_ACAT <- function(pvals) {\n",
    "        if (length(pvals) == 1) {\n",
    "            return(pvals[0])\n",
    "        }\n",
    "        stat <- 0.00\n",
    "        pval_min <- 1.00\n",
    "\n",
    "        stat <- sum(qcauchy(pvals))\n",
    "        pval_min <- min(pval_min, min(qcauchy(pvals)))\n",
    "\n",
    "        return(pcauchy(stat/length(pvals), lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "\n",
    "    globalPvalue <- function(pvals, comb_method = \"HMP\", naive=FALSE) {\n",
    "        # assuming sstats has tissues as columns and rows as pvals\n",
    "        min_pval <- min(pvals)\n",
    "        n_total_tests <- pvals %>% unique() %>% length() # There should be one unique pval per tissue\n",
    "        global_pval <- if (comb_method == \"HMP\") pval_HMP(pvals) else pval_ACAT(pvals) # pval vector\n",
    "        naive_pval <- min(n_total_tests*min_pval, 1.0)\n",
    "        return(if (naive) naive_pval else global_pval) # global_pval and naive_pval\n",
    "    }\n",
    "\n",
    "            \n",
    "    generate_index <- function(variant) {\n",
    "        return(\n",
    "            unlist(lapply(\n",
    "                strsplit(variant, '[:|_]'),\n",
    "                function(x) {\n",
    "                    alleles <- list(c(x[3], x[4]), c(aflip(x[3]), aflip(x[4])), c(x[4], x[3]), c(aflip(x[4]), aflip(x[3])))\n",
    "                    alleles <- alleles[order(sapply(alleles, '[[', 1))]\n",
    "                    return(\n",
    "                        paste(\n",
    "                            c(\n",
    "                                x[1],\n",
    "                                x[2],\n",
    "                                paste(sapply(alleles, '[[', 1), collapse = \"|\"),\n",
    "                                paste(sapply(alleles, '[[', 2), collapse = \"|\")\n",
    "                            ),\n",
    "                            collapse = \":\"\n",
    "                        ))\n",
    "                })))\n",
    "    }\n",
    "            \n",
    "    aflip <- function(allele) {\n",
    "        if( allele == \"A\" ) {\n",
    "            return(\"T\")\n",
    "        }\n",
    "        else if( allele == \"C\" ) {\n",
    "            return(\"G\")\n",
    "        }\n",
    "        else if( allele == \"T\" ) {\n",
    "            return(\"A\")\n",
    "        }\n",
    "        else if( allele == \"G\" ) {\n",
    "            return(\"C\")\n",
    "        }\n",
    "        else {\n",
    "            return(\"\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ptwas_weights <- read_delim(\n",
    "        \"${ptwas_weights}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE) %>% \n",
    "        mutate(\n",
    "            uber_id = generate_index(variant))\n",
    "    gwas <- read_delim(\n",
    "        \"${gwas_path}\", delim = \"\\t\", comment = \"##\", show_col_types = FALSE) %>%\n",
    "        rename(Z = ZSCORE) %>%\n",
    "        mutate(\n",
    "            `#CHR` = as.character(`#CHR`),             \n",
    "            `#CHR` = ifelse(!startsWith(`#CHR`, \"chr\"), paste0(\"chr\", `#CHR`), `#CHR`),\n",
    "            SNP_ID = gsub(\"_\", \":\", SNP_ID),\n",
    "            uber_id = generate_index(SNP_ID))\n",
    "\n",
    "    regionlist <- read_delim(\n",
    "        \"${region_list}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE)\n",
    "    colnames(regionlist) <- c(\"#CHR\", \"start\", \"end\", \"gene_id\", \"gene_name\")\n",
    "\n",
    "    input_dataframe <- merge(\n",
    "        regionlist,\n",
    "        merge(ptwas_weights, gwas, by = c(\"uber_id\"), all = FALSE),\n",
    "        by = c(\"#CHR\", \"gene_id\"), all = FALSE)\n",
    "\n",
    "    write.table(input_dataframe, \"${_output}\", col.names = T, row.names = F, quote = F, sep='\\t')    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#[ptwas_scan_2]\n",
    "parameter: vcf_path_prefix=\"/mnt/vast/hpc/csg/rf2872/data/1000Genome/LD_panel_Travyse_NoQualityGuarantee/EUR.\"\n",
    "parameter: vcf_path_suffix=\".shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz\"\n",
    "parameter: region_list=\"\"\n",
    "import pandas as pd\n",
    "# Extract unique values, remove 'chr', convert to int, sort, and then add 'chr' back\n",
    "input_df = file_target(f'{cwd}/cache/input_dataframe.txt')\n",
    "input_dataframe = pd.read_csv(f'{cwd}/cache/input_dataframe.txt', sep='\\t')\n",
    "chroms = [\"chr\" + str(x) for x in sorted([int(chrom.replace(\"chr\", \"\")) for chrom in input_dataframe[\"#CHR\"].unique()])]\n",
    "chroms_LD = [f\"{vcf_path_prefix}{chrom}{vcf_path_suffix}\" for chrom in chroms]\n",
    "\n",
    "input: chroms_LD, group_by = 1\n",
    "output: f'{cwd}/{tissue}.{_input}.ptwas.output'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(tidyverse)\n",
    "    library(harmonicmeanp)\n",
    "    LDRef <- read_delim(\n",
    "        \"${_input}\",\n",
    "        delim = \"\\t\",\n",
    "        comment = \"##\",\n",
    "        show_col_types = FALSE)\n",
    "    \n",
    "    LDRef$FORM_ID <- paste0(tolower(gsub(\"${vcf_path_prefix}\",\"\",\"${_input}\")%>%gsub(\"${vcf_path_suffix}\",\"\",.)), ':', LDRef$POS, ':', LDRef$REF, ':', LDRef$ALT)\n",
    "    LDRef <- LDRef %>% \n",
    "        mutate(uber_id = generate_index(FORM_ID))\n",
    "\n",
    "    results <- input_dataframe %>%\n",
    "        filter(uber_id %in% LDRef$uber_id) %>%\n",
    "        mutate(weight = as.double(weight)) %>%\n",
    "        group_by(gene_id, tissue) %>%\n",
    "        mutate(nsnps = length(variant), burden_pval = burden(variant, SNP_ID, weight, Z)) %>%\n",
    "        ungroup() %>%\n",
    "        group_by(gene_id) %>%\n",
    "        mutate(\n",
    "            global_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=FALSE),\n",
    "            naive_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=TRUE),\n",
    "            min_pval = min(burden_pval)) %>%\n",
    "        ungroup()\n",
    "    \n",
    "    write_delim(\n",
    "        results %>%\n",
    "            subset(select=c(\"gene_id\", \"tissue\", \"nsnps\", \"burden_pval\", \"global_pval\", \"naive_pval\", \"min_pval\")) %>%\n",
    "            distinct(gene_id, tissue, .keep_all = TRUE),\n",
    "        \"{_output}\",\n",
    "        delim = \"\\t\",\n",
    "        append = FALSE,\n",
    "        quote = \"none\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sos run /xqtl-pipeline/code/intact_pipeline/ptwas.ipynb ptwas_scan \\\n",
    "    --ptwas_weights output/DLPFC.eQTL.susie_reformat.txt \\\n",
    "    --gwas_path output/ADGWAS_Bellenguez_2022.gambitgwas.txt \\\n",
    "    --region_list /mnt/vast/hpc/csg/molecular_phenotype_calling/eqtl/dlpfc_region_list \\\n",
    "    --chroms_LD `realpath /mnt/vast/hpc/csg/rf2872/data/1000Genome/LD_panel_Travyse_NoQualityGuarantee/*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[ptwas_scan]\n",
    "parameter: ptwas_weights=\"\"\n",
    "parameter: gwas_path=\"\"\n",
    "parameter: region_list=\"\"\n",
    "parameter: chroms_LD=\"\"\n",
    "parameter: vcf_path_prefix=\"/mnt/vast/hpc/csg/rf2872/data/1000Genome/LD_panel_Travyse_NoQualityGuarantee/EUR.\"\n",
    "parameter: vcf_path_suffix=\".shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz\"\n",
    "parameter: region_list=\"\"\n",
    "input: chroms_LD, group_by = 1\n",
    "output: f'{cwd}/{tissue}.ptwas.output'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(tidyverse)\n",
    "    library(harmonicmeanp)\n",
    "    handle_weights <- function(gwas_ids, weight_ids) {\n",
    "        return(unlist(lapply(\n",
    "            strsplit(gwas_ids, ':'),\n",
    "            function(x) {\n",
    "                POSs  <- as.double(sapply(strsplit(weight_ids, ':'), '[[', 2))\n",
    "                REFs <- sapply(strsplit(weight_ids, ':'), '[[', 3)\n",
    "                ALTs <- sapply(strsplit(weight_ids, ':'), '[[', 4)\n",
    "                for (i in 1:length(REFs)) {\n",
    "                    if (as.double(x[2]) == POSs[i]) {\n",
    "                        if (x[3] == REFs[i] & x[4] == ALTs[i]) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == ALTs[i] & x[4] == REFs[i]) {\n",
    "                            return(-1)\n",
    "                        } else if (x[3] == aflip(REFs[i]) & x[4] == aflip(ALTs[i])) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == aflip(ALTs[i]) & x[4] == aflip(REFs[i])) {\n",
    "                            return(-1)\n",
    "                        } else {\n",
    "                            return(0)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )))\n",
    "    }\n",
    "\n",
    "    debug_print <- function(gwas_ids, modifiers, weights, zscores, stat, denom, output) {\n",
    "        snpdf <- data.frame(\n",
    "            CHROM = sapply(strsplit(gwas_ids, ':'), '[[', 1),\n",
    "            POS = as.double(sapply(strsplit(gwas_ids, ':'), '[[', 2)),\n",
    "            VARIANT = gsub(\":\", \"_\", gwas_ids),\n",
    "            REF = sapply(strsplit(gwas_ids, ':'), '[[', 3),\n",
    "            ALT = sapply(strsplit(gwas_ids, ':'), '[[', 4),\n",
    "            MODIFIERS = modifiers,\n",
    "            WEIGHTS = weights,\n",
    "            ZSCORES = zscores) %>% arrange(POS)\n",
    "        cat(\"\\n\\nSNP info:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        write_delim(\n",
    "            snpdf,\n",
    "            output,\n",
    "            append = TRUE,\n",
    "            col_names = TRUE,\n",
    "            quote = \"none\")\n",
    "        cat(\"\\n\\nmodifiers:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$MODIFIERS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nweights:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$WEIGHTS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nz-stats:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$ZSCORES, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest score = \", stat, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest variance = \", denom, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "    }\n",
    "\n",
    "    burden <- function(weight_ids, gwas_ids, weights, zscores) {\n",
    "        modifiers <- handle_weights(gwas_ids, weight_ids)\n",
    "        weights <- modifiers * weights\n",
    "        \n",
    "        stat <- sum(weights * zscores)\n",
    "        denom <- sum(weights * weights)\n",
    "        zscore <- stat/sqrt(denom)\n",
    "\n",
    "        if (length(zscores) == 1) {\n",
    "            zscore <- zscores[[1]]\n",
    "            if (weights[[1]] < 0) {\n",
    "                zscore <- zscore * -1\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        pval <- pchisq( zscore * zscore, 1, lower.tail = FALSE)\n",
    "        \n",
    "        debug_print(gwas_ids, modifiers, weights, zscores, stat, denom, paste0(output_base, \"ptwas-scan.debug\"))\n",
    "\n",
    "        return(pval)\n",
    "    }\n",
    "\n",
    "    pval_HMP <- function(pvals) {\n",
    "        # https://search.r-project.org/CRAN/refmans/harmonicmeanp/html/pLandau.html\n",
    "        pvalues <- unique(pvals)\n",
    "        L <- length(pvalues)\n",
    "        HMP <- L/sum(pvalues^-1)\n",
    "\n",
    "        LOC_L1 <- 0.874367040387922\n",
    "        SCALE <- 1.5707963267949\n",
    "\n",
    "        return(pLandau(1/HMP, mu = log(L) + LOC_L1, sigma = SCALE, lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "    pcauchy <- function(x) {\n",
    "        return(0.5 + atan(x)/pi)\n",
    "    }\n",
    "\n",
    "    qcauchy <- function(q) {\n",
    "        return(tan(pi*(q - 0.5)))\n",
    "    }\n",
    "\n",
    "    pval_ACAT <- function(pvals) {\n",
    "        if (length(pvals) == 1) {\n",
    "            return(pvals[0])\n",
    "        }\n",
    "        stat <- 0.00\n",
    "        pval_min <- 1.00\n",
    "\n",
    "        stat <- sum(qcauchy(pvals))\n",
    "        pval_min <- min(pval_min, min(qcauchy(pvals)))\n",
    "\n",
    "        return(pcauchy(stat/length(pvals), lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "\n",
    "    globalPvalue <- function(pvals, comb_method = \"HMP\", naive=FALSE) {\n",
    "        # assuming sstats has tissues as columns and rows as pvals\n",
    "        min_pval <- min(pvals)\n",
    "        n_total_tests <- pvals %>% unique() %>% length() # There should be one unique pval per tissue\n",
    "        global_pval <- if (comb_method == \"HMP\") pval_HMP(pvals) else pval_ACAT(pvals) # pval vector\n",
    "        naive_pval <- min(n_total_tests*min_pval, 1.0)\n",
    "        return(if (naive) naive_pval else global_pval) # global_pval and naive_pval\n",
    "    }\n",
    "\n",
    "            \n",
    "    generate_index <- function(variant) {\n",
    "        return(\n",
    "            unlist(lapply(\n",
    "                strsplit(variant, '[:|_]'),\n",
    "                function(x) {\n",
    "                    alleles <- list(c(x[3], x[4]), c(aflip(x[3]), aflip(x[4])), c(x[4], x[3]), c(aflip(x[4]), aflip(x[3])))\n",
    "                    alleles <- alleles[order(sapply(alleles, '[[', 1))]\n",
    "                    return(\n",
    "                        paste(\n",
    "                            c(\n",
    "                                x[1],\n",
    "                                x[2],\n",
    "                                paste(sapply(alleles, '[[', 1), collapse = \"|\"),\n",
    "                                paste(sapply(alleles, '[[', 2), collapse = \"|\")\n",
    "                            ),\n",
    "                            collapse = \":\"\n",
    "                        ))\n",
    "                })))\n",
    "    }\n",
    "            \n",
    "    aflip <- function(allele) {\n",
    "        if( allele == \"A\" ) {\n",
    "            return(\"T\")\n",
    "        }\n",
    "        else if( allele == \"C\" ) {\n",
    "            return(\"G\")\n",
    "        }\n",
    "        else if( allele == \"T\" ) {\n",
    "            return(\"A\")\n",
    "        }\n",
    "        else if( allele == \"G\" ) {\n",
    "            return(\"C\")\n",
    "        }\n",
    "        else {\n",
    "            return(\"\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ptwas_weights <- read_delim(\n",
    "        \"${ptwas_weights}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE) %>% \n",
    "        mutate(\n",
    "            uber_id = generate_index(variant))\n",
    "    gwas <- read_delim(\n",
    "        \"${gwas_path}\", delim = \"\\t\", comment = \"##\", show_col_types = FALSE) %>%\n",
    "        rename(Z = ZSCORE) %>%\n",
    "        mutate(\n",
    "            `#CHR` = as.character(`#CHR`),             \n",
    "            `#CHR` = ifelse(!startsWith(`#CHR`, \"chr\"), paste0(\"chr\", `#CHR`), `#CHR`),\n",
    "            SNP_ID = gsub(\"_\", \":\", SNP_ID),\n",
    "            uber_id = generate_index(SNP_ID))\n",
    "\n",
    "    regionlist <- read_delim(\n",
    "        \"${region_list}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE)\n",
    "    colnames(regionlist) <- c(\"#CHR\", \"start\", \"end\", \"gene_id\", \"gene_name\")\n",
    "\n",
    "    input_dataframe <- merge(\n",
    "        regionlist,\n",
    "        merge(ptwas_weights, gwas, by = c(\"uber_id\"), all = FALSE),\n",
    "        by = c(\"#CHR\", \"gene_id\"), all = FALSE)\n",
    "\n",
    "    LDRef <- read_delim(\n",
    "        \"${_input}\",\n",
    "        delim = \"\\t\",\n",
    "        comment = \"##\",\n",
    "        show_col_types = FALSE)\n",
    "    \n",
    "    LDRef$FORM_ID <- paste0(tolower(gsub(\"${vcf_path_prefix}\",\"\",\"${_input}\")%>%gsub(\"${vcf_path_suffix}\",\"\",.)), ':', LDRef$POS, ':', LDRef$REF, ':', LDRef$ALT)\n",
    "    LDRef <- LDRef %>% \n",
    "        mutate(uber_id = generate_index(FORM_ID))\n",
    "\n",
    "    results <- input_dataframe %>%\n",
    "        filter(uber_id %in% LDRef$uber_id) %>%\n",
    "        mutate(weight = as.double(weight)) %>%\n",
    "        group_by(gene_id, tissue) %>%\n",
    "        mutate(nsnps = length(variant), burden_pval = burden(variant, SNP_ID, weight, Z)) %>%\n",
    "        ungroup() %>%\n",
    "        group_by(gene_id) %>%\n",
    "        mutate(\n",
    "            global_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=FALSE),\n",
    "            naive_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=TRUE),\n",
    "            min_pval = min(burden_pval)) %>%\n",
    "        ungroup()\n",
    "    \n",
    "    write_delim(\n",
    "        results %>%\n",
    "            subset(select=c(\"gene_id\", \"tissue\", \"nsnps\", \"burden_pval\", \"global_pval\", \"naive_pval\", \"min_pval\")) %>%\n",
    "            distinct(gene_id, tissue, .keep_all = TRUE),\n",
    "        \"{_output}\",\n",
    "        delim = \"\\t\",\n",
    "        append = FALSE,\n",
    "        quote = \"none\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note 2:\n",
    "We need to download 1000Genome LD panel data\n",
    "For now, I'm using a non quality guarantees data provided by Travyse, just for pipeline testing...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
