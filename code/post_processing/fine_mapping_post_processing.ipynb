{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legislative-cylinder",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# SuSIE results post process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-robertson",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook is to post-process the susie results into different text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-jurisdiction",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Extracting susie results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-routine",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb susie_to_tsv \\\n",
    "    --cwd output/test --rds_path `ls output/test/cache/*rds | head ` --region-list <(head -50  ./dlpfc_region_list) --container containers/stephenslab.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-speed",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Extracting susie_rss results for ADGWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-dayton",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb susie_to_tsv \\\n",
    "    --cwd output/ADGWAS_finemapping_extracted/Bellenguez/ --rds_path `ls GWAS_Finemapping_Results/Bellenguez/ADGWAS2022*rds ` \\\n",
    "    --region-list ~/1300_hg38_EUR_LD_blocks_orig.tsv \\\n",
    "    --container containers/stephenslab.sif \n",
    "\n",
    "sos run pipeline/SuSiE_post_processing.ipynb susie_tsv_collapse \\\n",
    "    --cwd output/ADGWAS_finemapping_extracted --tsv_path `ls output/ADGWAS_finemapping_extracted/*lbf.tsv` \\\n",
    "    --container containers/stephenslab.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-index",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Extracting fsusie results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-broadcast",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_haQTL_pos --rds_path `ls output/f_susie_tad_haQTL_pos/cache/*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-remark",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_meQTL_pos_selected/ --rds_path `ls output/f_susie_tad_meQTL_pos_selected//cache/*1204*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-embassy",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_meQTL_pos_2/ --rds_path `ls output/f_susie_tad_meQTL_pos_2//cache/*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-rwanda",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_meQTL_pos/ --rds_path `ls output/f_susie_tad_meQTL_pos//cache/*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-retailer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_haQTL_pos_check_pure_2 --rds_path `ls output/f_susie_tad_haQTL_pos_check_pure_2/cache/*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-shepherd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb fsusie_to_tsv \\\n",
    "    --cwd output/f_susie_tad_meQTL_pos_2/ --rds_path `ls output/f_susie_tad_meQTL_pos_2//cache/*rds ` \\\n",
    "    --region-list ../eqtl/dlpfc_tad_list \\\n",
    "    --container containers/stephenslab.sif -s build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe78e94-87f7-4de7-b46d-fae572aa1194",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Exporting cis_analysis susie_twas results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c5448-ef4d-4e09-8a55-f87aabf8da1c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "meta file is produced by:\n",
    "```\n",
    "get_condition <- function(conditions, Author, qtl_type){\n",
    "    strings <- c()\n",
    "    for(condition in conditions){\n",
    "        string =  paste(condition, Author, qtl_type, sep = \"_\")  \n",
    "        string = paste(unique(unlist(strsplit(string, \"_\"))), collapse = \"_\")\n",
    "        strings <- c(strings, string)\n",
    "    }\n",
    "    return(strings)\n",
    "}\n",
    "\n",
    "raw_name<- c(\"Mic\",\"Ast\",\"Oli\",\"OPC\",\"Exc\",\"Inh\",\"DLPFC\",\"PCC\",\"AC\")\n",
    "raw_name_kellis<- c(\"Mic_Kellis\",\"Ast_Kellis\",\"Oli_Kellis\",\"OPC_Kellis\",\"Exc_Kellis\",\"Inh_Kellis\",\"Ast.10\",\"Mic.12\",\"Mic.13\")\n",
    "\n",
    "dejager_name <- get_condition(raw_name, \"De_Jager\",\"eQTL\")\n",
    "kellis_name <- get_condition(raw_name_kellis, \"Kellis\",\"eQTL\")\n",
    "eQTL_meta <- data.frame(raw_name = c(raw_name, raw_name_kellis), new_name = c(dejager_name, kellis_name))\n",
    "write_delim(eQTL_meta, \"/mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/eQTL_meta.tsv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd09e57-ee13-4822-a4a7-8a3fc640f999",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_name new_name\n",
      "Mic Mic_De_Jager_eQTL\n",
      "Ast Ast_De_Jager_eQTL\n",
      "Oli Oli_De_Jager_eQTL\n",
      "OPC OPC_De_Jager_eQTL\n",
      "Exc Exc_De_Jager_eQTL\n",
      "Inh Inh_De_Jager_eQTL\n",
      "DLPFC DLPFC_De_Jager_eQTL\n",
      "PCC PCC_De_Jager_eQTL\n",
      "AC AC_De_Jager_eQTL\n"
     ]
    }
   ],
   "source": [
    "head /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/eQTL_meta.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137961b5-1c6c-4c4b-b29a-a27643d5b1d1",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run ~/codes/xqtl-pipeline/pipeline/fine_mapping_post_processing.ipynb  cis_results_export \\\n",
    "    --condition_meta /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024_new/eQTL_meta.tsv \\\n",
    "    --region_list ~/codes/fungen-xqtl-analysis/resource/TADB_enhanced_cis.protein_coding.bed \\\n",
    "    --file_path ./rds_files \\\n",
    "    --prefix ROSMAP_eQTL ROSMAP_eQTL_Kellis \\\n",
    "    --suffix susie_weights_db.rds \\\n",
    "    --name ROSMAP_eQTL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3b184-552a-4ca0-b11d-0e56516ed6ff",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Export gwas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6b547-b86a-4014-9377-07bbad828d62",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run ~/codes/xqtl-pipeline/pipeline/fine_mapping_post_processing.ipynb  gwas_results_export \\\n",
    "    --rds-files ` ls /mnt/vast/hpc/csg/hs3393/RSS_QC/GWAS_finemapping_result/SuSiE_RSS/*rds` \\\n",
    "    --name ADGWAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bcc90-94ef-4d9b-b3eb-57abaacfd5c9",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Overlapped gwas data and eQTL data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efd99d-cd04-4f8d-9d2b-418b67df5d3e",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run ~/codes/xqtl-pipeline/pipeline/fine_mapping_post_processing.ipynb  overlap_qtl_gwas \\\n",
    "    --qtl-files `ls /mnt/vast/hpc/csg/rf2872/Work/Multivariate/susie_2024/data/*/*export.rds  ` \\\n",
    "    --gwas-union-file  /mnt/vast/hpc/csg/rf2872/Work/Multivariate/gwas/output/ADGWAS.union_export.tsv.gz \\\n",
    "    --name ROSMAP_eQTL \\\n",
    "    -c ~/env_files/csg.yml -J 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-measure",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Plotting the pip plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-secretary",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb susie_pip_landscape_plot \\\n",
    "    --cwd output/test/ --plot_list plot_recipe --annot_tibble ~/Annotatr_builtin_annotation_tibble.tsv -s force &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-blackjack",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_post_processing.ipynb susie_upsetR_plot \\\n",
    "    --cwd output/test/ --plot_list plot_recipe_1  -s force &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-drilling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The required input for this step is a tab-delimited plot_recipe file that specifies the path to each of the variant.tsv files generated from this module. Each column represents a molecular phenotype, and each row indicates the files that share common variants. Since one TAD may correspond to multiple genes, additional eQTL are permitted. If there are additional molecular phenotypes or ADGWAS datasets, additional columns can be appended.\n",
    "\n",
    "The built-in Annotatr_builtin_annotation_tibble.tsv can be downloaded from [synapse](https://www.synapse.org/#!Synapse:syn51198526), please download it and specify the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-chancellor",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haQTL\tmQTL\teQTL\teQTL\tADGWAS\n",
      "/mnt/vast/hpc/csg/molecular_phenotype_calling/QTL_fine_mapping/output/f_susie_tad_meQTL_pos//meQTL.yuqi_mqtl.tad100.uni_Fsusie.mixture_normal_per_scale.variant.tsv\t/mnt/vast/hpc/csg/molecular_phenotype_calling/QTL_fine_mapping/output/f_susie_tad_haQTL_pos//haQTL.rosmap_haqtl.tad100.uni_Fsusie.mixture_normal_per_scale.variant.tsv\t/mnt/vast/hpc/csg/molecular_phenotype_calling/eqtl//output/susie_per_gene_tad//demo.ENSG00000117322.unisusie.fit.variant.tsv\t/mnt/vast/hpc/csg/molecular_phenotype_calling/eqtl//output/susie_per_gene_tad//demo.ENSG00000203710.unisusie.fit.variant.tsv\t/mnt/vast/hpc/csg/xqtl_workflow_testing/susie_rss/output/ADGWAS_finemapping_extracted/Bellenguez/ADGWAS2022.chr1.sumstat.chr1_205972031_208461272.unisusie_rss.fit.variant.tsv\n"
     ]
    }
   ],
   "source": [
    "cat /mnt/vast/hpc/csg/molecular_phenotype_calling/QTL_fine_mapping/plot_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-fields",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "import pandas as pd\n",
    "# A region list file documenting the chr_pos_ref_alt of a susie_object\n",
    "parameter: cwd = path(\"output\")\n",
    "parameter: name = \"demo\"\n",
    "\n",
    "## Path to work directory where output locates\n",
    "## Containers that contains the necessary packages\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"96h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"6G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 2\n",
    "parameter: windows = 1000000\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-campbell",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_to_tsv_1]\n",
    "# Input\n",
    "# For complete susie, region_list or tad_list, for susie_rss , LD region list \n",
    "parameter: region_list = path\n",
    "region_tbl = pd.read_csv(region_list,sep = \"\\t\")\n",
    "parameter: rds_path = paths\n",
    "input: rds_path, group_by = 1\n",
    "output: f\"{cwd}/{_input:bn}.variant.tsv\",f\"{cwd}/{_input:bn}.lbf.tsv\",f\"{cwd}/{_input:bn}.effect.tsv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"stringr\")\n",
    "    library(\"susieR\")\n",
    "    extract_lbf = function(susie_obj){\n",
    "    \n",
    "    if(\"variants\" %in% names(susie_obj) ){\n",
    "    ss_bf = tibble(snps = susie_obj$variants, cs_index = ifelse(is.null(susie_obj$sets$cs_index), 0, paste0(susie_obj$sets$cs_index,collapse =\",\")),names = \"${f'{_input:br}'.split('.')[-4]}\")\n",
    "    }\n",
    "      else \n",
    "      {\n",
    "    ss_bf = tibble(snps = susie_obj$variable_name, cs_index = ifelse(is.null(susie_obj$sets$cs_index), 0, paste0(susie_obj$sets$cs_index,collapse =\",\")),names = \"${_input:bnnn}\")\n",
    "     }\n",
    "    \n",
    "    ss_bf = ss_bf%>%cbind(susie_obj$lbf_variable%>%t)%>%as_tibble()\n",
    "    \n",
    "    return(ss_bf)\n",
    "    }\n",
    "    \n",
    "    extract_variants_pip = function(susie_obj,region_list){\n",
    "    susie_tb = tibble( variants =  names(susie_obj$pip)[which( susie_obj$pip >= 0)],\n",
    "                           snps_index = which(( susie_obj$pip >= 0))) %>%\n",
    "        mutate(chromosome = map_chr(variants, ~read.table(text = .x, sep = \":\")$V1%>%str_replace(\"chr\",\"\") ),\n",
    "                position  = map_chr(variants, ~read.table(text = .x, sep = \":\")$V2  ),\n",
    "                ref = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V2  ),\n",
    "                alt = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V3  ),\n",
    "                position  = map_dbl(position , ~read.table(text = .x, sep = \"_\",as.is = T)$V1  )\n",
    "                             )\n",
    "      susie_tb = susie_tb%>%mutate(cs_order =(map(susie_tb$snps_index , ~tryCatch(which(pmap(list( a= susie_obj$sets$cs) , function(a) .x %in% a )%>%unlist()), error = function(e) return(0) )  ))%>%as.character%>%str_replace(\"integer\\\\(0\\\\)\",\"0\"),\n",
    "                         cs_id = map_chr(cs_order,~ifelse(.x ==\"0\", \"None\" ,names(susie_obj$sets$cs)[.x%>%str_split(\":\")%>%unlist%>%as.numeric] ) ),\n",
    "                         log10_base_factor = map_chr(snps_index,~paste0( susie_obj$lbf_variable[,.x],  collapse = \";\")),\n",
    "                         pip = susie_obj$pip,\n",
    "                         posterior_mean = coef.susie(susie_obj)[-1],\n",
    "                         posterior_sd = susie_get_posterior_sd(susie_obj),\n",
    "                         z = posterior_mean/posterior_sd)\n",
    "    \n",
    "          susie_tb =  susie_tb%>%mutate(  molecular_trait_id = region_list$molecular_trait_id,\n",
    "                             finemapped_region_start = region_list$finemapped_region_start,\n",
    "                             finemapped_region_end = region_list$finemapped_region_end)\n",
    "          return(susie_tb)    }\n",
    "          \n",
    "        \n",
    "\n",
    "     extract_effect_pip = function(susie_obj,region_list,susie_tb){\n",
    "      result_tb =  tibble(phenotype = susie_obj$name,\n",
    "        V = susie_obj$V,effect_id = paste0(\"L\",1:length(V) ) ,\n",
    "        cs_log10bf = susie_obj$lbf)\n",
    "        if(is.null(susie_obj$sets$cs)){\n",
    "            cs_min_r2 = cs_avg_r2 =  coverage =  0 \n",
    "            cs = \"None\"} else {         cs = map_chr(susie_obj$sets$cs[result_tb$effect_id],~susie_tb$variants[.x]%>%paste0(collapse = \";\"))\n",
    "        coverage = map(result_tb$effect_id, ~susie_obj$sets$coverage[which(names(susie_obj$sets$cs) == .x )])%>%as.numeric%>%replace_na(0)\n",
    "        cs_min_r2  = (susie_obj$sets$purity[result_tb$effect_id,1])%>%as.numeric%>%replace_na(0)  \n",
    "        cs_avg_r2  = (susie_obj$sets$purity[result_tb$effect_id,2])%>%as.numeric%>%replace_na(0) }\n",
    "        result_tb = result_tb%>%mutate(cs_min_r2 = cs_min_r2,cs_avg_r2 = cs_avg_r2 ,coverage = coverage%>%unlist,cs = cs )            \n",
    "      return(result_tb)\n",
    "      }\n",
    "       \n",
    "  \n",
    "    susie_obj = readRDS(\"${_input:a}\")\n",
    "    if(\"variants\" %in% names(susie_obj) ){susie_obj$variants = susie_obj$variants%>%str_replace(\"_\",\":\")}\n",
    "    if(is.null(names(susie_obj$pip ))){names(susie_obj$pip) = susie_obj$variants}\n",
    "    lbf = extract_lbf(susie_obj)\n",
    "    region_list = read_delim(\"${region_list}\",\"\\t\")\n",
    "    if(ncol(region_list) == 3 ){   region_list =  region_list%>%mutate(`#chr` = `#chr`%>%str_remove_all(\" \") , ID = paste0(`#chr`,\"_\",start,\"_\",end) ) } # LD_list \n",
    "    if(region_list$start[1] - region_list$end[1]  == -1 ){ \n",
    "        region_list = region_list%>%mutate( start = start - ${windows} ,end = start +${windows}) # region_list for fix cis windows  \n",
    "          } \n",
    "      if(\"gene_id\" %in% colnames(region_list)){region_list = region_list%>%mutate(ID = gene_id)  } # region_list for gene\n",
    "    region_list = region_list%>%select(molecular_trait_id = ID, chromosome  = `#chr`,finemapped_region_start = start ,finemapped_region_end = end)  # Formatting\n",
    "    region_list = region_list%>%filter(molecular_trait_id == \"${f'{_input:br}'.split('.')[-4]}\")\n",
    "    variants_pip = extract_variants_pip( susie_obj , region_list)\n",
    "    effect_pip = extract_effect_pip( susie_obj , region_list,variants_pip)\n",
    "    lbf%>%write_delim(\"${_output[1]}\",\"\\t\")\n",
    "    variants_pip%>%write_delim(\"${_output[0]}\",\"\\t\")\n",
    "    effect_pip%>%write_delim(\"${_output[2]}\",\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-florist",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sQTL_susie_to_tsv_1]\n",
    "# Input\n",
    "# For complete susie, region_list or tad_list, for susie_rss , LD region list \n",
    "parameter: region_list = path\n",
    "region_tbl = pd.read_csv(region_list,sep = \"\\t\")\n",
    "parameter: rds_path = paths\n",
    "input: rds_path, group_by = 1\n",
    "input_name=f\"{_input:bn}\"\n",
    "input_name=input_name.replace('*', 'N') # \"*\" in leafcutter2 would be ignored in shell and cause error \n",
    "output: f\"{cwd}/{input_name}.variant.tsv\",f\"{cwd}/{input_name}.lbf.tsv\",f\"{cwd}/{input_name}.effect.tsv\"\n",
    "tags = f'{step_name}_{_output[0]:bn}'\n",
    "tags = tags.replace(':', '_').replace('+', 'ps') # also for other symbols in tag id \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = tags\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"stringr\")\n",
    "    library(\"susieR\")\n",
    "    extract_lbf = function(susie_obj){\n",
    "    \n",
    "    if(\"variants\" %in% names(susie_obj) ){\n",
    "    ss_bf = tibble(snps = susie_obj$variants, cs_index = ifelse(is.null(susie_obj$sets$cs_index), 0, paste0(susie_obj$sets$cs_index,collapse =\",\")),names = \"${f'{_input:br}'.split('.')[-4]}\")\n",
    "    }\n",
    "      else \n",
    "      {\n",
    "    ss_bf = tibble(snps = susie_obj$variable_name, cs_index = ifelse(is.null(susie_obj$sets$cs_index), 0, paste0(susie_obj$sets$cs_index,collapse =\",\")),names = \"${_input:bnnn}\")\n",
    "     }\n",
    "    \n",
    "    ss_bf = ss_bf%>%cbind(susie_obj$lbf_variable%>%t)%>%as_tibble()\n",
    "    \n",
    "    return(ss_bf)\n",
    "    }\n",
    "    \n",
    "    extract_variants_pip = function(susie_obj,region_list){\n",
    "    susie_tb = tibble( variants =  names(susie_obj$pip)[which( susie_obj$pip >= 0)],\n",
    "                           snps_index = which(( susie_obj$pip >= 0))) %>%\n",
    "        mutate(chromosome = map_chr(variants, ~read.table(text = .x, sep = \":\")$V1%>%str_replace(\"chr\",\"\") ),\n",
    "                position  = map_chr(variants, ~read.table(text = .x, sep = \":\")$V2  ),\n",
    "                ref = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V2  ),\n",
    "                alt = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V3  ),\n",
    "                position  = map_dbl(position , ~read.table(text = .x, sep = \"_\",as.is = T)$V1  )\n",
    "                             )\n",
    "      susie_tb = susie_tb%>%mutate(cs_order =(map(susie_tb$snps_index , ~tryCatch(which(pmap(list( a= susie_obj$sets$cs) , function(a) .x %in% a )%>%unlist()), error = function(e) return(0) )  ))%>%as.character%>%str_replace(\"integer\\\\(0\\\\)\",\"0\"),\n",
    "                         cs_id = map_chr(cs_order,~ifelse(.x ==\"0\", \"None\" ,names(susie_obj$sets$cs)[.x%>%str_split(\":\")%>%unlist%>%as.numeric] ) ),\n",
    "                         log10_base_factor = map_chr(snps_index,~paste0( susie_obj$lbf_variable[,.x],  collapse = \";\")),\n",
    "                         pip = susie_obj$pip,\n",
    "                         posterior_mean = coef.susie(susie_obj)[-1],\n",
    "                         posterior_sd = susie_get_posterior_sd(susie_obj),\n",
    "                         z = posterior_mean/posterior_sd)\n",
    "    \n",
    "          susie_tb =  susie_tb%>%mutate(  molecular_trait_id = region_list$molecular_trait_id,\n",
    "                             finemapped_region_start = region_list$finemapped_region_start,\n",
    "                             finemapped_region_end = region_list$finemapped_region_end)\n",
    "          return(susie_tb)    }\n",
    "          \n",
    "        \n",
    "\n",
    "     extract_effect_pip = function(susie_obj,region_list,susie_tb){\n",
    "      result_tb =  tibble(phenotype = susie_obj$name,\n",
    "        V = susie_obj$V,effect_id = paste0(\"L\",1:length(V) ) ,\n",
    "        cs_log10bf = susie_obj$lbf)\n",
    "        if(is.null(susie_obj$sets$cs)){\n",
    "            cs_min_r2 = cs_avg_r2 =  coverage =  0 \n",
    "            cs = \"None\"} else {         cs = map_chr(susie_obj$sets$cs[result_tb$effect_id],~susie_tb$variants[.x]%>%paste0(collapse = \";\"))\n",
    "        coverage = map(result_tb$effect_id, ~susie_obj$sets$coverage[which(names(susie_obj$sets$cs) == .x )])%>%as.numeric%>%replace_na(0)\n",
    "        cs_min_r2  = (susie_obj$sets$purity[result_tb$effect_id,1])%>%as.numeric%>%replace_na(0)  \n",
    "        cs_avg_r2  = (susie_obj$sets$purity[result_tb$effect_id,2])%>%as.numeric%>%replace_na(0) }\n",
    "        result_tb = result_tb%>%mutate(cs_min_r2 = cs_min_r2,cs_avg_r2 = cs_avg_r2 ,coverage = coverage%>%unlist,cs = cs )            \n",
    "      return(result_tb)\n",
    "      }\n",
    "       \n",
    "  \n",
    "    susie_obj = readRDS(\"${_input:a}\")\n",
    "    if(\"variants\" %in% names(susie_obj) ){susie_obj$variants = susie_obj$variants%>%str_replace(\"_\",\":\")}\n",
    "    if(is.null(names(susie_obj$pip ))){names(susie_obj$pip) = susie_obj$variants}\n",
    "    lbf = extract_lbf(susie_obj)\n",
    "    region_list = read_delim(\"${region_list}\",\"\\t\")\n",
    "    if(ncol(region_list) == 3 ){   region_list =  region_list%>%mutate(`#chr` = `#chr`%>%str_remove_all(\" \") , ID = paste0(`#chr`,\"_\",start,\"_\",end) ) } # LD_list \n",
    "    if(region_list$start[1] - region_list$end[1]  == -1 ){ \n",
    "        region_list = region_list%>%mutate( start = start - ${windows} ,end = start +${windows}) # region_list for fix cis windows  \n",
    "          } \n",
    "      if(\"gene_id\" %in% colnames(region_list)){region_list = region_list%>%mutate(ID = gene_id)  } # region_list for gene\n",
    "    region_list = region_list%>%select(molecular_trait_id = ID, chromosome  = `#chr`,finemapped_region_start = start ,finemapped_region_end = end)  # Formatting\n",
    "    mole_id = \"${f'{_input:br}'.split('.')[-4]}\"%>%gsub(\"_N:\",\"_*:\",.)#for sQTL\n",
    "    region_list = region_list%>%filter(molecular_trait_id == mole_id)\n",
    "    variants_pip = extract_variants_pip( susie_obj , region_list)\n",
    "    effect_pip = extract_effect_pip( susie_obj , region_list,variants_pip)\n",
    "    lbf%>%write_delim(\"${_output[1]}\",\"\\t\")\n",
    "    variants_pip%>%write_delim(\"${_output[0]}\",\"\\t\")\n",
    "    effect_pip%>%write_delim(\"${_output[2]}\",\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-wichita",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fsusie_to_tsv_1]\n",
    "# Input\n",
    "# For complete susie, region_list or tad_list, for susie_rss , LD region list \n",
    "parameter: region_list = path\n",
    "region_tbl = pd.read_csv(region_list,sep = \"\\t\")\n",
    "parameter: rds_path = paths\n",
    "input: rds_path, group_by = 1\n",
    "output: f\"{cwd}/{_input:bn}.variant.tsv\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"stringr\")\n",
    "    library(\"susieR\")\n",
    "\n",
    "    extract_variants_pip = function(susie_obj,region_list){\n",
    "        susie_tb = tibble( variants =  names(susie_obj$csd_X),\n",
    "                               snps_index = which(( susie_obj$pip >= 0))) %>%\n",
    "            mutate(chromosome = map_chr(variants, ~read.table(text = .x, sep = \":\")$V1%>%str_replace(\"chr\",\"\") ),\n",
    "                    position  = map_chr(variants, ~read.table(text = .x, sep = \":\")$V2  ),\n",
    "                    ref = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V2  ),\n",
    "                    alt = map_chr(position , ~read.table(text = .x, sep = \"_\",colClasses = \"character\")$V3  ),\n",
    "                    position  = map_dbl(position , ~read.table(text = .x, sep = \"_\",as.is = T)$V1  )\n",
    "                                 )\n",
    "          susie_tb = susie_tb%>%mutate(cs_order =(map(susie_tb$snps_index , ~tryCatch(which(pmap(list( a= susie_obj$cs) , function(a) .x %in% a )%>%unlist()), error = function(e) return(0) )  ))%>%as.character%>%str_replace(\"integer\\\\(0\\\\)\",\"0\"),\n",
    "                             pip = susie_obj$pip)\n",
    "          susie_tb =  susie_tb%>%mutate(  molecular_trait_id = region_list$tad_index,\n",
    "                                 finemapped_region_start = region_list$start,\n",
    "                                 finemapped_region_end = region_list$end)\n",
    "          if(\"purity\" %in% names(susie_obj)){\n",
    "              susie_tb = susie_tb%>%mutate(purity = map_dbl(susie_tb$cs_order, ~ifelse(.x%>%as.numeric > 0, susie_obj$purity[[as.numeric(.x)]], NA ) ), is_dummy = as.numeric(purity < 0.5)  )\n",
    "              }\n",
    "    susie_tb = susie_tb%>%mutate(effect_peak_pos = map_dbl(cs_order, ~ifelse(.x%>%as.numeric > 0, susie_obj$outing_grid[which(abs(susie_obj$fitted_func[[as.numeric(.x)]]) == max(abs(susie_obj$fitted_func[[as.numeric(.x)]])))] , NA ) )) \n",
    "    susie_tb_lbf = cbind(susie_tb%>%select(molecular_trait_id,variants,cs_order),Reduce(cbind, susie_obj$lBF)%>%as.tibble%>%`colnames<-`(1:length(susie_obj$lBF)))\n",
    "          return(list(susie_tb, susie_tb_lbf))    }\n",
    "    susie_obj = readRDS(\"${_input:a}\")\n",
    "    region_list = read_delim(\"${region_list}\",\"\\t\")\n",
    "    region_list = region_list%>%filter(tad_index == \"${f'{_input:br}'.split('.')[-4]}\")\n",
    "    variants_pip = extract_variants_pip( susie_obj , region_list)[[1]]\n",
    "    variants_lbf = extract_variants_pip( susie_obj , region_list)[[2]]\n",
    "    print(paste0(\"fsusie run time is \", round(susie_obj$runtime[[3]]/60),\"min\"))\n",
    "    variants_pip%>%write_delim(\"${_output}\",\"\\t\")\n",
    "    variants_pip%>%write_delim(\"${_output:nn}.lbf.tsv\",\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-extent",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[*_to_tsv_2]\n",
    "parameter: name = f'{_input[0]:b}'.split(\".\")[0]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{name}.all_variants.tsv\"\n",
    "bash: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint\n",
    "    head -1 ${_input[0]} > ${_output}\n",
    "    cat ${_input[0]:d}/*variant.tsv | grep -v cs_order >> ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-festival",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_tsv_collapse]\n",
    "parameter: tsv_path = paths # TSV needs have the name ends with  *.chr1_2_3.unisusie(_rss).lbf.tsv\n",
    "tsv_list  = pd.DataFrame({\"lbf_path\" : [str(x) for x in tsv_path]})\n",
    "chromosome = list(set([f'{x.split(\".\")[-5].split(\"_\")[0].replace(\"chr\",\"\")}'  for x in tsv_list.lbf_path ])) ## Add chr if there is no chr prefix. This is to accomodata chr XY and M\n",
    "input: tsv_path, for_each = \"chromosome\"\n",
    "output: f'{cwd}/{_input[0]:bnnnnnnn}.chr{_chromosome}.unisusie_rss.lbf.tsv'\n",
    "bash: expand = '${ }', stdout = f\"{_output}.stdout\", stderr = f\"{_output}.stderr\", container = container, entrypoint = entrypoint\n",
    "        head -1 ${_input[0]} > ${_output}\n",
    "        cat ${_input[0]:d}/*.chr${_chromosome}_*lbf.tsv | grep -v cs_index >> ${_output}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-praise",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_pip_landscape_plot]\n",
    "parameter: plot_list = path\n",
    "parameter: annot_tibble = path(\"~/Annotatr_builtin_annotation_tibble.tsv\")\n",
    "import pandas as pd\n",
    "plot_list  = pd.read_csv(plot_list,sep = \"\\t\")\n",
    "file_type = plot_list.columns.values.tolist()\n",
    "file_type = [x.split(\".\")[0] for x in file_type ]\n",
    "plot_list = plot_list.to_dict(\"records\")\n",
    "input: plot_list, group_by = len(file_type)\n",
    "output: f'{cwd}/{\"_\".join(file_type)}.{str(_input[0]).split(\".\")[-5]}.pip_landscape_plot.rds',f'{cwd}/{\"_\".join(file_type)}.{str(_input[0]).split(\".\")[-5]}.pip_landscape_plot.pdf'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]}.stdout\", stderr = f\"{_output[0]}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"ggplot2\")\n",
    "    library(\"purrr\")\n",
    "    color = c(\"black\", \"dodgerblue2\", \"green4\", \"#6A3D9A\", \n",
    "          \"#FF7F00\", \"gold1\", \"skyblue2\", \"#FB9A99\", \"palegreen2\",\n",
    "          \"#CAB2D6\", \"#FDBF6F\", \"gray70\", \"khaki2\", \"maroon\", \"orchid1\",\n",
    "          \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \n",
    "          \"yellow4\", \"yellow3\",\"darkorange4\",\"brown\",\"navyblue\",\"#FF0000\",\n",
    "          \"darkgreen\",\"#FFFF00\",\"purple\",\"#00FF00\",\"pink\",\"#0000FF\",\n",
    "          \"orange\",\"#FF00FF\",\"cyan\",\"#00FFFF\",\"#FFFFFF\")\n",
    "    extract_table = function(variant_df,type){ \n",
    "    if(\"purity\" %in% colnames(variant_df) ){\n",
    "      variant_df$purity[is.na(variant_df$purity)] = 0\n",
    "      variant_df[abs(variant_df$purity) < 0.5,7] = 0\n",
    "      }\n",
    "     variant_df = variant_df%>%mutate(CS = (cs_order%>%as.factor%>%as.numeric-1)%>%as.factor)%>%\n",
    "          select( y = pip ,snp = variants,pos = position , CS, molecular_trait_id)%>%mutate(molecular_trait_id = paste0(type,\"_\",molecular_trait_id ) )\n",
    "    return(variant_df)\n",
    "    }\n",
    "    plot_recipe = tibble( type =  c('${\"','\".join(file_type) }'), path = c(${_input:r,}))\n",
    "    plot_list = map2(plot_recipe$type,plot_recipe$path, ~read_delim(.y, guess_max = 10000000)%>%extract_table(.x) )\n",
    "    plot_df = Reduce(rbind,plot_list)\n",
    "    plot_range = (plot_df%>%group_by(molecular_trait_id)%>%summarize(start = (min(pos)), end = (max(pos)))%>%mutate(start = median(start),end = median(end)))[1,c(2,3)]%>%as.matrix\n",
    "    plot_chr = (plot_df$snp[1]%>%stringr::str_split(\":\"))[[1]][1]\n",
    "    plot_df = plot_df%>%mutate(Shared = as.logical(map(snp, ~(plot_df%>%filter( snp ==.x ,   CS%>%as.numeric !=  1 )%>%nrow()) > 1  )))\n",
    "    pip_plot <- plot_df%>%ggplot2::ggplot(aes(y = y, x = pos,\n",
    "                                  col =  CS, shape = Shared )) + facet_grid(molecular_trait_id ~.)+\n",
    "      geom_point(size = 7) +\n",
    "      scale_color_manual(\"CS\",values = color) +\n",
    "      theme(axis.ticks.x = element_blank()) +\n",
    "     ylab(\"Posterior Inclusion Probability (PIP)\")+xlim(plot_range)+\n",
    "      theme(axis.ticks.x = element_blank()) +\n",
    "            theme(strip.text.y.right = element_text(angle = 0))+\n",
    "            xlab(\"\") + \n",
    "            theme(text = element_text(size = 30))+ggtitle(\"Overview of fine-mapping\")\n",
    "  \n",
    "    annot = read_delim(\"${annot_tibble}\")\n",
    "    annot = annot%>%filter(seqnames == plot_chr, start > plot_range[1], end < plot_range[2])\n",
    "    annot_plot   = annot%>%filter(!type%in%c(\"hg38_genes_introns\",\"hg38_genes_1to5kb\"))%>%\n",
    "                        ggplot(aes())+\n",
    "                        geom_segment( aes(x = start,xend = end, y = \"Regulartory Element\", yend = \"Regulartory Element\", color = type ), linewidth =10)+\n",
    "                        ylab(\"\")+xlab(\"\")+xlim(plot_range)+theme(axis.text.x=element_blank(),text = element_text(size = 20))+scale_color_brewer(palette=\"Dark2\")\n",
    "    gene_plot = annot%>%filter(type%in%c(\"hg38_genes_1to5kb\"))%>%group_by(symbol)%>%\n",
    "                            summarise(start = min(start), end = max(end))%>%na.omit%>%\n",
    "                            ggplot(aes())+geom_segment( aes(x = start,xend = end, y = \"Gene\", yend = \"Gene\", color = symbol ), linewidth =10)+\n",
    "                            geom_label(aes(x = (start+end)/2,y = \"Gene\", label = symbol ),size = 5)+ylab(\"\")+xlab(\"POS\")+\n",
    "                            theme(legend.position=\"none\")+theme(text = element_text(size = 20))+xlim(plot_range)\n",
    "      \n",
    "    list(pip_plot,plot_df,annot_plot,gene_plot)%>%saveRDS(\"${_output[0]}\")\n",
    "    cowplot::plot_grid(plotlist = list(pip_plot,annot_plot,gene_plot),ncol = 1, align = \"v\",axis = \"tlbr\",rel_heights = c(8,1,1))%>%ggsave(filename = \"${_output[1]}\",device = \"pdf\",dpi = \"retina\",width = 30, height = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "juvenile-leone",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_upsetR_plot]\n",
    "parameter: plot_list = path\n",
    "import pandas as pd\n",
    "plot_list  = pd.read_csv(plot_list, sep = \"\\t\")\n",
    "file_type = plot_list.columns.values.tolist()\n",
    "file_type = [x.split(\".\")[0] for x in file_type ]\n",
    "plot_list = plot_list.to_dict(\"records\")\n",
    "input: plot_list\n",
    "output: f'{cwd}/{\"_\".join(file_type)}.UpSetR.rds',f'{cwd}/{\"_\".join(file_type)}.UpSetR.pdf'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]}.stdout\", stderr = f\"{_output[0]}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"ggplot2\")\n",
    "    library(\"purrr\")\n",
    "    library(\"UpSetR\")\n",
    "    library(\"ComplexUpset\")\n",
    "    plot_recipe = tibble( type =  c('${\"','\".join(file_type) }'), path = c(${_input:r,}))\n",
    "    plot_list = map2(plot_recipe$type,plot_recipe$path, ~read_delim(.y, guess_max = 10000000)%>%mutate(cs = cs_order != 0 )%>%filter(cs > 0)%>%select(variants,cs)%>%`colnames<-`(c(\"variants\",.x))%>%distinct() )\n",
    "    cs_sharing = Reduce(full_join,plot_list)\n",
    "    cs_upsetR_sharing = cs_sharing\n",
    "    cs_upsetR_sharing[,2:ncol(cs_upsetR_sharing)]%>%mutate_all(as.numeric)-> cs_upsetR_sharing[,2:ncol(cs_upsetR_sharing)]\n",
    "    a = upset(cs_upsetR_sharing%>%as.data.frame,intersect = colnames(cs_upsetR_sharing[2:ncol(cs_upsetR_sharing)]),\n",
    "      keep_empty_groups = F,\n",
    "          base_annotations=list(`Intersection size` = intersection_size( bar_number_threshold = 1, position = position_dodge(0.5), width = 0.3 ,text = list(size = 5)   )  ) ,\n",
    "              themes=upset_default_themes(axis.text=element_text(size=30))     ,\n",
    "              min_degree = 1)\n",
    "    \n",
    "    a%>%ggsave(filename = \"${_output[1]}\",device = \"pdf\",dpi = \"retina\",width=18.5, height=10.5)\n",
    "    list(cs_upsetR_sharing)%>%saveRDS(\"${_output[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-prompt",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_upsetR_cs_plot]\n",
    "parameter: plot_list = path\n",
    "import pandas as pd\n",
    "plot_list  = pd.read_csv(plot_list, sep = \"\\t\")\n",
    "file_type = plot_list.columns.values.tolist()\n",
    "file_type = [x.split(\".\")[0] for x in file_type ]\n",
    "plot_list = plot_list.to_dict(\"records\")\n",
    "parameter: trait_to_select =  1 \n",
    "input: plot_list\n",
    "output: f'{cwd}/{\"_\".join(file_type)}.UpSetR_{file_type[trait_to_select-1]}_cs.rds',f'{cwd}/{\"_\".join(file_type)}.UpSetR_{file_type[trait_to_select-1]}_cs.pdf'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]}.stdout\", stderr = f\"{_output[0]}.stderr\", container = container, entrypoint = entrypoint\n",
    "\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"ggplot2\")\n",
    "    library(\"purrr\")\n",
    "    library(\"UpSetR\")\n",
    "    library(\"ComplexUpset\")\n",
    "\n",
    "    cs_sharing_identifer = function(upsetR_input,df){\n",
    "    inner_join(upsetR_input, df%>%select(variants,molecular_trait_id, cs_order)%>%filter(cs_order != 0))%>%select(-variants)-> dfL_CS_sharing\n",
    "    dfL_CS_sharing[is.na(dfL_CS_sharing)] = FALSE\n",
    "    dfL_CS_sharing = dfL_CS_sharing%>%group_by(molecular_trait_id,cs_order)%>%summarize(across(everything(), list(mean))   )\n",
    "    dfL_CS_sharing = dfL_CS_sharing%>%mutate(across(colnames(dfL_CS_sharing)[3:ncol(dfL_CS_sharing)], ~.x != 0  ))%>%`colnames<-`(c(\"molecular_trait_id\",\"cs_order\",colnames(cs_sharing)[2:ncol(cs_sharing)]))\n",
    "    }\n",
    "  \n",
    "  \n",
    "    plot_recipe = tibble( type =  c('${\"','\".join(file_type) }'), path = c(${_input:r,}))\n",
    "    plot_list = map2(plot_recipe$type,plot_recipe$path, ~read_delim(.y, guess_max = 10000000)%>%mutate(cs = cs_order != 0 )%>%filter(cs > 0)%>%select(variants,cs)%>%`colnames<-`(c(\"variants\",.x))%>%distinct() )\n",
    "    cs_sharing = Reduce(full_join,plot_list)\n",
    "    cs_upsetR_sharing = cs_sharing\n",
    "    cs_upsetR_sharing[,2:ncol(cs_upsetR_sharing)]%>%mutate_all(as.numeric)-> cs_upsetR_sharing[,2:ncol(cs_upsetR_sharing)]\n",
    "\n",
    "    df = read_delim(plot_recipe$path[[${trait_to_select}]]) \n",
    "    \n",
    "    cs_sharing_df = cs_sharing_identifer(cs_upsetR_sharing,df)\n",
    "\n",
    "    a = upset(cs_sharing_df%>%as.data.frame,intersect = colnames(cs_sharing_df[3:ncol(cs_sharing_df)]),\n",
    "          keep_empty_groups = F,\n",
    "          base_annotations=list(`Intersection size` = intersection_size( bar_number_threshold = 1, position = position_dodge(0.5), width = 0.3 ,text = list(size = 8)   )  ),\n",
    "          themes=upset_default_themes(axis.text=element_text(size=30)),\n",
    "          set_size = F  ,  min_degree = 1,wrap = T) + ggtitle( paste0(plot_recipe$type[[${trait_to_select}]],'CS shared with other phenotypes') )   + theme(plot.title = element_text(size = 40, face = \"bold\"))\n",
    "  \n",
    "    a%>%ggsave(filename = \"${_output[1]}\",device = \"pdf\",dpi = \"retina\",width=18.5, height=10.5)\n",
    "    list(cs_sharing_df)%>%saveRDS(\"${_output[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-apartment",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[tmp_annotatation_of_snps_1]\n",
    "parameter: SNP_list = path\n",
    "parameter: annotation_rds = path\n",
    "input: SNP_list\n",
    "output: f'{cwd}/{_input:b}.annotated.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output}.stdout\", stderr = f\"{_output}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"purrr\")\n",
    "    library(\"stringr\")\n",
    "    sharing_snp = readRDS(\"${_input}\")\n",
    "    sharing_snp_fsusie = sharing_snp[[1]]%>%filter(haQTL == 1 | mQTL == 1)\n",
    "    sharing_snp_fsusie = sharing_snp_fsusie%>%mutate(X1 =  read.table(text = sharing_snp_fsusie$variants, sep = \":\")$V1, X2 = read.table(text = read.table(text = sharing_snp_fsusie$variants, sep = \":\")$V2 , sep = \"_\")$V1  )\n",
    "    sharing_snp_fsusie = sharing_snp_fsusie%>%select(variants,chr = X1, pos = X2)\n",
    "    annotation = readRDS(\"${annotation_rds}\")\n",
    "    print(\"data loaded\")\n",
    "    result = sharing_snp_fsusie%>%mutate(annot = map2( chr,pos , ~ annotation%>%filter(X1 == .x, X2 <= .y, X3 >= .y)%>%pull(X5)))%>%mutate(annot = map_chr(annot, ~paste0(.x ,collapse = \",\")) )\n",
    "    print(\"snp annotated\")\n",
    "    result%>%saveRDS(\"${_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-transport",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[tmp_annotatation_of_snps_2]\n",
    "parameter: SNP_list = path\n",
    "parameter: annotation_rds = path\n",
    "output: f'{cwd}/{_input:b}.annotated_rev.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output}.stdout\", stderr = f\"{_output}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"purrr\")\n",
    "    library(\"stringr\")\n",
    "    result = readRDS(${_input:r})\n",
    "    result_rev = tibble(annot = unique(annotation$X5))%>%mutate(variants = map(annot, ~  result%>%filter( str_detect(annot,.x))%>%pull(variants)) )%>%mutate( variants = map_chr(variants,~paste0(.x ,collapse = \",\"))  )\n",
    "    result_rev%>%saveRDS(\"${_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-workplace",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fsusie_extract_effect]\n",
    "parameter: rds_path = paths\n",
    "parameter: annot_tibble = path(\"~/Annotatr_builtin_annotation_tibble.tsv\")\n",
    "input: rds_path, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.estimated_effect.tsv',f'{cwd}/{_input:bn}.estimated_effect.pdf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]}.stdout\", stderr = f\"{_output[0]}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"stringr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"ggplot2\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    color = c(\"black\", \"dodgerblue2\", \"green4\", \"#6A3D9A\", \n",
    "          \"#FF7F00\", \"gold1\", \"skyblue2\", \"#FB9A99\", \"palegreen2\",\n",
    "          \"#CAB2D6\", \"#FDBF6F\", \"gray70\", \"khaki2\", \"maroon\", \"orchid1\",\n",
    "          \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \n",
    "          \"yellow4\", \"yellow3\",\"darkorange4\",\"brown\",\"navyblue\",\"#FF0000\",\n",
    "          \"darkgreen\",\"#FFFF00\",\"purple\",\"#00FF00\",\"pink\",\"#0000FF\",\n",
    "          \"orange\",\"#FF00FF\",\"cyan\",\"#00FFFF\",\"#FFFFFF\")\n",
    "    \n",
    "    effect_extract = function(fsusie){\n",
    "        plot_df = fsusie$fitted_func%>%as_tibble(.name_repair = \"universal\")%>%mutate(pos =  fsusie$outing_grid)%>%`colnames<-`(c(paste0(\"Effect_\",1:length(fsusie$cs)),\"pos\"))%>%mutate(`#chr` = str_split(names(fsusie$csd_X)[[1]],\":\")[[1]][[1]] )%>%select(`#chr`, pos, everything())\n",
    "        plot=  plot_df%>%pivot_longer(cols = 3:ncol(plot_df),names_to = \"effect\", values_to = \"values\"   ) %>%ggplot(aes(x = pos, y = values,color = effect),linewidth = 7)+\n",
    "        geom_line()+ylab(\"Estimated Effect\") + xlab(\"POS\")+facet_grid(effect~. )+\n",
    "            scale_color_manual(\"Credible set\",values = color[2:length(color)])+geom_line(aes(y = 0), color = \"black\")\n",
    "            theme(strip.text.y.right = element_text(angle = 0))+\n",
    "            xlab(\"\") + \n",
    "            ylab(\"Estimated Effect\")+ \n",
    "            theme(text = element_text(size = 50))+\n",
    "            ggtitle(paste0( \"Estimated effect for ${f'{_input:br}'.split('.')[-4]}\"))\n",
    "        return(list(plot_df,plot))\n",
    "        }\n",
    "    susie_obj =  readRDS(\"${_input}\")\n",
    "    output = effect_extract(susie_obj)\n",
    "    effect_tbl = output[[1]]\n",
    "    annot = read_delim(\"${annot_tibble}\")\n",
    "    annot = annot%>%filter(seqnames == (effect_tbl$`#chr`)[[1]], start > min(effect_tbl$pos), end < max(effect_tbl$pos))\n",
    "    plot_range = c(min(effect_tbl$pos),  max(effect_tbl$pos))\n",
    "    annot_plot   = annot%>%filter(!type%in%c(\"hg38_genes_introns\",\"hg38_genes_1to5kb\"))%>%\n",
    "                        ggplot(aes())+\n",
    "                        geom_segment( aes(x = start,xend = end, y = \"Regulartory Element\", yend = \"Regulartory Element\", color = type ), linewidth =10)+\n",
    "                        ylab(\"\")+xlab(\"\")+xlim(plot_range)+theme(axis.text.x=element_blank(),text = element_text(size = 20))+scale_color_brewer(palette=\"Dark2\")\n",
    "    gene_plot = annot%>%filter(type%in%c(\"hg38_genes_1to5kb\"))%>%group_by(symbol)%>%\n",
    "                            summarise(start = min(start), end = max(end))%>%na.omit%>%\n",
    "                            ggplot(aes())+geom_segment( aes(x = start,xend = end, y = \"Gene\", yend = \"Gene\", color = symbol ), linewidth =10)+\n",
    "                            geom_label(aes(x = (start+end)/2,y = \"Gene\", label = symbol ),size = 5)+ylab(\"\")+xlab(\"POS\")+\n",
    "                            theme(legend.position=\"none\")+theme(text = element_text(size = 20))+xlim(plot_range)\n",
    "    cowplot::plot_grid(plotlist = list(output[[2]]),ncol = 1, align = \"v\",axis = \"tlbr\",rel_heights = c(8))%>%ggsave(filename = \"${_output[1]}\",device = \"pdf\",dpi = \"retina\",width = 30, height = 30)\n",
    "    effect_tbl%>%write_delim(\"${_output[0]}\",\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-disabled",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fsusie_affected_region]\n",
    "parameter: rds_path = paths\n",
    "input: rds_path, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.affected_region.tsv',f'{cwd}/{_input:bn}.affected_region.pdf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]}.stdout\", stderr = f\"{_output[0]}.stderr\", container = container, entrypoint = entrypoint\n",
    "    library(\"stringr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\") \n",
    "    library(\"ggplot2\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(susiF.alpha)\n",
    "    library(ashr)\n",
    "    library(wavethresh)\n",
    "    color = c(\"black\", \"dodgerblue2\", \"green4\", \"#6A3D9A\", \n",
    "          \"#FF7F00\", \"gold1\", \"skyblue2\", \"#FB9A99\", \"palegreen2\",\n",
    "          \"#CAB2D6\", \"#FDBF6F\", \"gray70\", \"khaki2\", \"maroon\", \"orchid1\",\n",
    "          \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \n",
    "          \"yellow4\", \"yellow3\",\"darkorange4\",\"brown\",\"navyblue\",\"#FF0000\",\n",
    "          \"darkgreen\",\"#FFFF00\",\"purple\",\"#00FF00\",\"pink\",\"#0000FF\",\n",
    "          \"orange\",\"#FF00FF\",\"cyan\",\"#00FFFF\",\"#FFFFFF\")\n",
    "    ## Define Function\n",
    "    update_cal_credible_band2 <- function(susiF.obj )\n",
    "    {\n",
    "    \n",
    "    \n",
    "    \n",
    "      if(sum( is.na(unlist(susiF.obj$alpha))))\n",
    "      {\n",
    "        stop(\"Error: some alpha value not updated, please update alpha value first\")\n",
    "      }\n",
    "      temp <- wavethresh::wd(rep(0, susiF.obj$n_wac))\n",
    "    \n",
    "    \n",
    "      for ( l in 1:susiF.obj$L)\n",
    "      {\n",
    "        Smat <-  susiF.obj$fitted_wc2[[l]]\n",
    "        W1   <- ((wavethresh::GenW(n=  ncol(Smat )  , filter.number = 10, family = \"DaubLeAsymm\")))\n",
    "        tt   <- diag( W1%*%diag(c(susiF.obj$alpha[[l]]%*%Smat ))%*% t(W1 ))\n",
    "    \n",
    "        up                       <-  susiF.obj$fitted_func[[l]]+ 3*sqrt(tt)\n",
    "        low                      <-  susiF.obj$fitted_func[[l]]- 3*sqrt(tt)\n",
    "        susiF.obj$cred_band[[l]] <- rbind(up, low)\n",
    "      }\n",
    "    \n",
    "    \n",
    "    \n",
    "      return(susiF.obj)\n",
    "    }\n",
    "    \n",
    "    affected_reg <- function( susiF.obj){\n",
    "      outing_grid <- susiF.obj$outing_grid\n",
    "    \n",
    "      reg <-  list()\n",
    "      h <- 1\n",
    "      for (   l in 1:length(susiF.obj$cs)){\n",
    "    \n",
    "        pos_up <-  which(susiF.obj$cred_band[[l]][1,]<0)\n",
    "        pos_low <- which(susiF.obj$cred_band[[l]][2,]>0)\n",
    "    \n",
    "    \n",
    "        reg_up <- split( pos_up,cumsum(c(1,diff( pos_up)!=1)))\n",
    "    \n",
    "        reg_low <- split( pos_low,cumsum(c(1,diff( pos_low)!=1)))\n",
    "        for( k in 1:length(reg_up)){\n",
    "          reg[[h]] <- c(l, outing_grid[reg_up[[k]][1]], outing_grid[reg_up[[k]][length(reg_up[[k]])]])\n",
    "    \n",
    "          h <- h+1\n",
    "        }\n",
    "        for( k in 1:length(reg_low )){\n",
    "          reg[[h]] <- c(l, outing_grid[reg_low [[k]][1]], outing_grid[reg_low [[k]][length(reg_low [[k]])]])\n",
    "    \n",
    "          h <- h+1\n",
    "        }\n",
    "    \n",
    "    \n",
    "      }\n",
    "      reg <-  do.call(rbind, reg)\n",
    "      colnames(reg) <- c(\"CS\", \"Start\",\"End\")\n",
    "      return(reg)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    susiF_obj =  readRDS(\"${_input}\")\n",
    "    susiF_obj = update_cal_credible_band2(susiF_obj)\n",
    "    affected_tbl = affected_reg(susiF_obj)\n",
    "    affected_tbl = affected_tbl%>%as_tibble%>%mutate(analysis = susiF_obj$name,\n",
    "                          chr = (names(susiF_obj$csd_X)[[1]]%>%stringr::str_split(\":\"))[[1]][[1]],\n",
    "                          molecular_trait_id =  \"${f'{_input:br}'.split('.')[-4]}\", \n",
    "                          purity  = purrr::map_dbl(CS,~susiF_obj$purity[[.x]] )  )\n",
    "    \n",
    "    affected_tbl%>%as_tibble%>%write_delim(\"${_output[0]}\",\"\\t\")\n",
    "    plt = plot_susiF(susiF_obj, cred.band = T)\n",
    "    plt%>%ggsave(filename = \"${_output[1]}\",device = \"pdf\",dpi = \"retina\",width = 30, height = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-bangkok",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Into VCF format\n",
    "\n",
    "FIXME: These codes were moved from earlier workflows. To be cleaned up and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-montana",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[uni_susie_2]\n",
    "input: group_with = \"genoFile\"\n",
    "output: f\"{_input:n}.vcf.bgz\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:nn}.stdout\", stderr = f\"{_output:nn}.stderr\", container = container, entrypoint = entrypoint\n",
    "   ## Define create_vcf function\n",
    "           create_vcf = function (chrom, pos, nea, ea, snp = NULL, ea_af = NULL, effect = NULL, \n",
    "        se = NULL, pval = NULL, name = NULL,cs = NULL, pip = NULL) \n",
    "    {\n",
    "        stopifnot(length(chrom) == length(pos))\n",
    "        if (is.null(snp)) {\n",
    "            snp <- paste0(chrom, \":\", pos)\n",
    "        }\n",
    "        snp <- paste0(chrom, \":\", pos)\n",
    "        nsnp <- length(chrom)\n",
    "        gen <- list()\n",
    "        ## Setupt data content for each sample column\n",
    "        if (!is.null(ea_af)) \n",
    "            gen[[\"AF\"]] <- matrix(ea_af, nsnp)\n",
    "        if (!is.null(effect)) \n",
    "            gen[[\"ES\"]] <- matrix(effect, nsnp)\n",
    "        if (!is.null(se)) \n",
    "            gen[[\"SE\"]] <- matrix(se, nsnp)\n",
    "        if (!is.null(pval)) \n",
    "            gen[[\"LP\"]] <- matrix(-log10(pval), nsnp)\n",
    "        if (!is.null(cs)) \n",
    "            gen[[\"CS\"]] <- matrix(cs, nsnp)\n",
    "        if (!is.null(pip)) \n",
    "            gen[[\"PIP\"]] <- matrix(pip, nsnp)\n",
    "        gen <- S4Vectors::SimpleList(gen)\n",
    "        \n",
    "      ## Setup snps info for the fix columns\n",
    "        gr <- GenomicRanges::GRanges(chrom, IRanges::IRanges(start = pos, \n",
    "            end = pos + pmax(nchar(nea), nchar(ea)) - 1, names = snp))\n",
    "         coldata <- S4Vectors::DataFrame(Studies = name, row.names = name)\n",
    "    ## Setup header informations\n",
    "        hdr <- VariantAnnotation::VCFHeader(header = IRanges::DataFrameList(fileformat = S4Vectors::DataFrame(Value = \"VCFv4.2\", \n",
    "            row.names = \"fileformat\")), sample = name)\n",
    "        VariantAnnotation::geno(hdr) <- S4Vectors::DataFrame(Number = c(\"A\", \n",
    "            \"A\", \"A\", \"A\", \"A\", \"A\"), Type = c(\"Float\", \"Float\", \n",
    "            \"Float\", \"Float\", \"Float\", \"Float\"), Description = c(\"Effect size estimate relative to the alternative allele\", \n",
    "            \"Standard error of effect size estimate\", \"-log10 p-value for effect estimate\",  \n",
    "            \"Alternate allele frequency in the association study\",\n",
    "            \"The CS this variate are captured, 0 indicates not in any cs\", \"The posterior inclusion probability to a CS\"), \n",
    "            row.names = c(\"ES\", \"SE\", \"LP\", \"AF\", \"CS\", \"PIP\"))\n",
    "      ## Save only the meta information in the sample columns \n",
    "        VariantAnnotation::geno(hdr) <- subset(VariantAnnotation::geno(hdr), \n",
    "            rownames(VariantAnnotation::geno(hdr)) %in% names(gen))\n",
    "      ## Save VCF \n",
    "        vcf <- VariantAnnotation::VCF(rowRanges = gr, colData = coldata, \n",
    "            exptData = list(header = hdr), geno = gen)\n",
    "        VariantAnnotation::alt(vcf) <- Biostrings::DNAStringSetList(as.list(ea))\n",
    "        VariantAnnotation::ref(vcf) <- Biostrings::DNAStringSet(nea)\n",
    "      ## Add fixed values\n",
    "        VariantAnnotation::fixed(vcf)$FILTER <- \"PASS\"\n",
    "          return(sort(vcf))\n",
    "        }\n",
    "    library(\"susieR\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"stringr\")\n",
    "    \n",
    "    # Get list of cs snps\n",
    "    susie_list = readRDS(${_input:r})\n",
    "    susie_tb_ls = list()\n",
    "    for (i in 1:length(susie_list)){\n",
    "        susie_tb = tibble( snps =  names(susie_list[[1]]$pip)[which( susie_list[[i]]$pip >= 0)], snps_index = which(( susie_list[[i]]$pip >= 0))  )\n",
    "        susie_tb_ls[[i]]= susie_tb%>%mutate( cs = map(snps_index,~which( susie_list[[i]]$sets$cs %in% .x))%>%as.numeric%>%replace_na(0),\n",
    "                                 pip = map_dbl(snps_index,~( susie_list[[i]]$pip[.x])),\n",
    "                                 coef = map_dbl(snps_index,~(coef.susie( susie_list[[i]])[.x+1])))\n",
    "        }\n",
    "    if(length(susie_tb_ls) >= 2){ \n",
    "      for(i in 2:length(susie_tb_ls)){\n",
    "          susie_tb_ls[[i]] = full_join(susie_tb_ls[[i-1]],susie_tb_ls[[i]], by = \"snps\") \n",
    "        }\n",
    "    }\n",
    "    m = c(\"cs\",\"pip\",\"coef\")    \n",
    "    output = list()\n",
    "    for(i in m){\n",
    "    output[[i]] = susie_tb_ls[[length(susie_tb_ls)]]%>%select(contains(i))%>%as.matrix\n",
    "    }\n",
    "    snps_tb = susie_tb_ls[[length(susie_tb_ls)]]%>%mutate(\n",
    "                         chr = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = T)$V1),\n",
    "                         pos_alt_ref = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = TRUE)$V2),\n",
    "                         pos = map_dbl(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE)$V1),\n",
    "                         alt = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V2),\n",
    "                         ref = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V3))\n",
    "    \n",
    "    snps_tb = snps_tb%>%filter(str_detect(ref, \"[ACTG]\") & str_detect(alt, \"[ACTG]\"))\n",
    "    output_vcf = create_vcf(\n",
    "            chrom = snps_tb$chr,\n",
    "             pos = snps_tb$pos,\n",
    "             ea = snps_tb$alt,\n",
    "             nea = snps_tb$ref,\n",
    "             effect = snps_tb%>%select(contains(\"coef\"))%>%as.matrix ,\n",
    "             pip = snps_tb%>%select(contains(\"pip\"))%>%as.matrix,\n",
    "             cs = snps_tb%>%select(contains(\"cs\"))%>%as.matrix,\n",
    "             name = names(susie_list))\n",
    "    VariantAnnotation::writeVcf(output_vcf,${_output:nr},index = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-harvest",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mv_susie_2]\n",
    "input: group_with = \"genoFile\"\n",
    "output: f\"{_input:n}.vcf.bgz\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:nn}.stdout\", stderr = f\"{_output:nn}.stderr\", container = container, entrypoint = entrypoint\n",
    "   ## Define create_vcf function\n",
    "           create_vcf = function (chrom, pos, nea, ea, snp = NULL, ea_af = NULL, effect = NULL, \n",
    "        se = NULL, pval = NULL, name = NULL,cs = NULL, pip = NULL) \n",
    "    {\n",
    "        stopifnot(length(chrom) == length(pos))\n",
    "        if (is.null(snp)) {\n",
    "            snp <- paste0(chrom, \":\", pos)\n",
    "        }\n",
    "        snp <- paste0(chrom, \":\", pos)\n",
    "        nsnp <- length(chrom)\n",
    "        gen <- list()\n",
    "        ## Setupt data content for each sample column\n",
    "        if (!is.null(ea_af)) \n",
    "            gen[[\"AF\"]] <- matrix(ea_af, nsnp)\n",
    "        if (!is.null(effect)) \n",
    "            gen[[\"ES\"]] <- matrix(effect, nsnp)\n",
    "        if (!is.null(se)) \n",
    "            gen[[\"SE\"]] <- matrix(se, nsnp)\n",
    "        if (!is.null(pval)) \n",
    "            gen[[\"LP\"]] <- matrix(-log10(pval), nsnp)\n",
    "        if (!is.null(cs)) \n",
    "            gen[[\"CS\"]] <- matrix(cs, nsnp)\n",
    "        if (!is.null(pip)) \n",
    "            gen[[\"PIP\"]] <- matrix(pip, nsnp)\n",
    "        gen <- S4Vectors::SimpleList(gen)\n",
    "        \n",
    "      ## Setup snps info for the fix columns\n",
    "        gr <- GenomicRanges::GRanges(chrom, IRanges::IRanges(start = pos, \n",
    "            end = pos + pmax(nchar(nea), nchar(ea)) - 1, names = snp))\n",
    "         coldata <- S4Vectors::DataFrame(Studies = name, row.names = name)\n",
    "    ## Setup header informations\n",
    "        hdr <- VariantAnnotation::VCFHeader(header = IRanges::DataFrameList(fileformat = S4Vectors::DataFrame(Value = \"VCFv4.2\", \n",
    "            row.names = \"fileformat\")), sample = name)\n",
    "        VariantAnnotation::geno(hdr) <- S4Vectors::DataFrame(Number = c(\"A\", \n",
    "            \"A\", \"A\", \"A\", \"A\", \"A\"), Type = c(\"Float\", \"Float\", \n",
    "            \"Float\", \"Float\", \"Float\", \"Float\"), Description = c(\"Effect size estimate relative to the alternative allele\", \n",
    "            \"Standard error of effect size estimate\", \"-log10 p-value for effect estimate\",  \n",
    "            \"Alternate allele frequency in the association study\",\n",
    "            \"The CS this variate are captured, 0 indicates not in any cs\", \"The posterior inclusion probability to a CS\"), \n",
    "            row.names = c(\"ES\", \"SE\", \"LP\", \"AF\", \"CS\", \"PIP\"))\n",
    "      ## Save only the meta information in the sample columns \n",
    "        VariantAnnotation::geno(hdr) <- subset(VariantAnnotation::geno(hdr), \n",
    "            rownames(VariantAnnotation::geno(hdr)) %in% names(gen))\n",
    "      ## Save VCF \n",
    "        vcf <- VariantAnnotation::VCF(rowRanges = gr, colData = coldata, \n",
    "            exptData = list(header = hdr), geno = gen)\n",
    "        VariantAnnotation::alt(vcf) <- Biostrings::DNAStringSetList(as.list(ea))\n",
    "        VariantAnnotation::ref(vcf) <- Biostrings::DNAStringSet(nea)\n",
    "      ## Add fixed values\n",
    "        VariantAnnotation::fixed(vcf)$FILTER <- \"PASS\"\n",
    "          return(sort(vcf))\n",
    "        }\n",
    "    library(\"susieR\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "    \n",
    "    # Get list of cs snps\n",
    "    res = readRDS(${_input:r})\n",
    "    output_snps = tibble( snps = res$variable_name[which(res$pip >= 0)], snps_index = which((res$pip >= 0))  )\n",
    "    output_snps = output_snps%>%mutate( cs = map(snps_index,~which(res$sets$cs %in% .x))%>%as.numeric%>%replace_na(0),\n",
    "                             pip = map_dbl(snps_index,~(res$pip[.x])),\n",
    "                     chr = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = T)$V1),\n",
    "                     pos_alt_ref = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = TRUE)$V2),\n",
    "                     pos = map_dbl(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE)$V1),\n",
    "                     alt = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V2),\n",
    "                     ref = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V3))\n",
    "    \n",
    "    effect_mtr = res$coef[output_snps$snps_index+1]%>%as.matrix\n",
    "    colnames(effect_mtr) = \"${name}\"\n",
    "    rownames(effect_mtr) = output_snps$snps\n",
    "    cs_mtr = effect_mtr\n",
    "    for(i in 1:nrow(cs_mtr)) cs_mtr[i,] =  output_snps$cs[[i]]  \n",
    "    pip_mtr = effect_mtr\n",
    "    for(i in 1:nrow(pip_mtr)) pip_mtr[i,] =  output_snps$pip[[i]]  \n",
    "    \n",
    "    output_vcf = create_vcf(\n",
    "           chrom = output_snps$chr,\n",
    "            pos = output_snps$pos,\n",
    "            ea = output_snps$alt,\n",
    "            nea = output_snps$ref,\n",
    "            effect = effect_mtr ,\n",
    "            pip = pip_mtr,\n",
    "            cs = cs_mtr,\n",
    "            name = colnames(effect_mtr)\n",
    "              )\n",
    "    VariantAnnotation::writeVcf(output_vcf,${_output:nr},index = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd0a65-ac69-4106-b48c-463b6525a671",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Cis-window analysis Result consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a0d94c-b049-4f71-948e-9520e66ecba9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Result: first 3 col are chr start end, 4th column is region ID, 5th col are original file names, 6 and 7 col the consolidated file name\n",
    "# 8 col containing all the condition names comma split, to indicate what's available inside of RDS file on 6 col\n",
    "# 9 col containing the condition names has at least one top loci\n",
    "[cis_results_export_1]\n",
    "# per chunk we process at most 200 datasets\n",
    "parameter: per_chunk = 200\n",
    "# Region list should have last column being region name. \n",
    "# Meta-data will be written to this column\n",
    "parameter:region_list=path()\n",
    "parameter:file_path=''\n",
    "parameter:prefix=list\n",
    "parameter:suffix=str\n",
    "parameter: condition_meta = path()\n",
    "import pandas as pd\n",
    "region = pd.read_csv(region_list, delim_whitespace='\\t')\n",
    "# Function to create list of formatted strings for each row\n",
    "def create_formatted_list(row):\n",
    "    formatted_list = [f\"{file_path}/{p}.{row['gene_id']}.{suffix}\" for p in prefix]\n",
    "    return formatted_list\n",
    "# Apply the function to each row\n",
    "region['original_data'] = region.apply(create_formatted_list, axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def group_by_region(lst, partition):\n",
    "    # from itertools import accumulate\n",
    "    # partition = [len(x) for x in partition]\n",
    "    # Compute the cumulative sums once\n",
    "    # cumsum_vector = list(accumulate(partition))\n",
    "    # Use slicing based on the cumulative sums\n",
    "    # return [lst[(cumsum_vector[i-1] if i > 0 else 0):cumsum_vector[i]] for i in range(len(partition))]\n",
    "    return partition\n",
    "\n",
    "def filter_existing_paths(row):\n",
    "    existing_paths = [path for path in row if os.path.exists(path)]\n",
    "    return existing_paths\n",
    "\n",
    "region['original_data'] = region['original_data'].apply(filter_existing_paths)\n",
    "region = region[region['original_data'].map(bool)]\n",
    "regional_data = {\n",
    "    'meta': [(row['#chr'], row['start'], row['end'], row['gene_id']) for _, row in region.iterrows()],\n",
    "    'data': [(row['original_data']) for _, row in region.iterrows()]\n",
    "}\n",
    "\n",
    "meta_info = regional_data['meta']\n",
    "\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f\"{cwd}/{name}_cache/{name}_batch{_index+1}.tsv\"\n",
    "task: trunk_workers = job_size, walltime = walltime, trunk_size = 1, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    library(tidyverse)\n",
    "    # check top_loci existing or not\n",
    "    has_rows <- function(df) {\n",
    "      !is.null(df) && nrow(df) > 0\n",
    "    }\n",
    "    \n",
    "    # function to filter the cs with all variants pip < 0.05\n",
    "    update_and_filter_cs_ids <- function(df) {\n",
    "      cs_columns <- grep(\"^cs_coverage\", names(df), value = TRUE)\n",
    "      df$cs_all_non_zero_orig <- ifelse(rowSums(df[cs_columns] == 0) == length(cs_columns), FALSE, TRUE)\n",
    "      for (cs_column in cs_columns) {\n",
    "        unique_cs_ids <- unique(df[[cs_column]])  \n",
    "        for (cs_id in unique_cs_ids) {\n",
    "          if (cs_id > 0) {\n",
    "            pip_check <- df[df[[cs_column]] == cs_id, \"pip\"] < 0.05\n",
    "            if (all(pip_check, na.rm = TRUE)) {\n",
    "              df[[cs_column]] <- ifelse(df[[cs_column]] == cs_id, 0, df[[cs_column]])\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      # Filter out rows where all cs_coverage columns are 0 and cs_all_non_zero_orig is TRUE\n",
    "      df <- df %>% filter(!(cs_all_non_zero_orig & rowSums(df[cs_columns] == 0) == length(cs_columns)))\n",
    "      # Remove the helper column\n",
    "      df <- select(df, -cs_all_non_zero_orig)\n",
    "      return(df)\n",
    "    }\n",
    "  \n",
    "    # function to decide run update_and_filter_cs_ids or not\n",
    "    process_top_loci <- function(data_frame) {\n",
    "      if (!is.null(data_frame) && nrow(data_frame) > 0) {\n",
    "        return(update_and_filter_cs_ids(data_frame))\n",
    "      } else {\n",
    "        return(data_frame)\n",
    "      }\n",
    "    }\n",
    "  \n",
    "    # Process each path and collect results\n",
    "    orig_files = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[0:len(_input)//2+1]])})\n",
    "    meta <- read_delim(\"${condition_meta}\", col_names = F)\n",
    "     # Extract info from each RDS file\n",
    "    results <- list()\n",
    "    gene = \"${_meta_info[3]}\"\n",
    "    \n",
    "    # Post Processing: Extracting info\n",
    "    results[[gene]] <- list() # Initialize an empty list to store results\n",
    "    for(i in seq_along(orig_files)) {\n",
    "      rds_path <- orig_files[i]\n",
    "      dat <- readRDS(rds_path)\n",
    "      qtl_type <- sub(\"(\\\\.*?)\\\\..*\", \"\\\\1\", basename(rds_path)) %>% sub(\".*?_\", \"\\\\1\", .)\n",
    "\n",
    "      temp_list <- list() # Temporary list to store inner results\n",
    "      for(j in seq_along(names(dat[[1]]))) {\n",
    "        condition <- names(dat[[1]])[j]\n",
    "        dat_con <- dat[[1]][[condition]]\n",
    "        qtl_con <- meta %>% filter(X1 == condition) %>% pull(X2)\n",
    "        if (length(qtl_con) == 0) {\n",
    "          qtl_con <- condition\n",
    "          message(\"No matching entries found. qtl_con has been set to the condition value.\")\n",
    "        }\n",
    "        con_top_loci <- ifelse(has_rows(dat_con$top_loci) || has_rows(dat_con$preset_top_loci), qtl_con, NA)\n",
    "    \n",
    "        temp_list[[j]] <- list(\n",
    "          region_info = dat_con$region_info,\n",
    "          top_loci = process_top_loci(dat_con$top_loci),\n",
    "          preset_top_loci = process_top_loci(dat_con$preset_variants_result$top_loci),\n",
    "          pip = dat_con$susie_result_trimmed$pip,\n",
    "          variant_names = dat_con$variant_names,\n",
    "          CV_table = dat_con$twas_cv_result$performance,\n",
    "          sumstats = dat_con$sumstats,\n",
    "          qtl_con = qtl_con,\n",
    "          con_top_loci = con_top_loci\n",
    "        )\n",
    "      }\n",
    "      results[[gene]][[i]] <- temp_list\n",
    "    }\n",
    "    results[[gene]] <- unlist(results[[gene]], recursive = FALSE)\n",
    "\n",
    "    #Setting names and restructuring results[[gene]]\n",
    "    names(results[[gene]]) <- map_chr(results[[gene]], \"qtl_con\")\n",
    "    results[[gene]] <- map(results[[gene]], ~ .x[-which(names(.x) == \"qtl_con\")])\n",
    "  \n",
    "    res <- res_sum <- cons_top_loci <- list()\n",
    "    res[[gene]] <- lapply(results[[gene]], function(element) { element[c('region_info', 'top_loci', 'preset_top_loci', 'pip', 'variant_names', 'CV_table')] })\n",
    "    res_sum[[gene]] <- lapply(results[[gene]], function(element) { element[c(\"variant_names\", \"sumstats\")] })\n",
    "    cons_top_loci[[gene]] <- lapply(results[[gene]], function(element) {\n",
    "      tmp <- element[[\"con_top_loci\"]]  # Directly access 'con_top_loci'\n",
    "      if (!is.na(tmp))  return(tmp) else return(NULL)  \n",
    "    }) %>% compact()  # Use 'compact' to remove NULLs, assuming 'results' has the correct structure  \n",
    " \n",
    "    combine_data = paste0(\"${_output:add}\",\"/\",\"${name}\", \".\", gene, \".cis_results_db.export.rds\")\n",
    "    combine_data_sumstats = paste0(\"${_output:add}\",\"/\",\"${name}\", \".\", gene, \".cis_results_db.export_sumstats.rds\")\n",
    "    saveRDS(res, combine_data)\n",
    "    saveRDS(res_sum, combine_data_sumstats)\n",
    "\n",
    "    meta = data.frame(chr=\"${_meta_info[0]}\", start=\"${_meta_info[1]}\", end=\"${_meta_info[2]}\", gene_id=\"${_meta_info[3]}\", \n",
    "                      original_data = paste(basename(orig_files), collapse = \", \"), combined_data = basename(combine_data), combined_data_sumstats = basename(combine_data_sumstats), \n",
    "                      conditions = paste(names(results[[gene]]), collapse = \",\"), conditions_top_loci = cons_top_loci %>% unlist %>% na.omit %>% as.character %>% paste(., collapse = ','))\n",
    "    write_delim(meta, \"${_output}\", delim = '\\t')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9544df-cce9-47c4-a44e-b81cd2ed8f72",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_results_export_2]\n",
    "input: group_by = 'all'\n",
    "output: f\"{cwd}/{name}.cis_results_db.tsv\" \n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "bash: expand = \"{ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    input_path=$(echo ${_input[0]:adr}| sed 's/^\\$//')\n",
    "    output_file=$(echo ${_output:r}|sed 's/^\\$//g')\n",
    "\n",
    "    for file in $input_path/*.tsv; do\n",
    "      if [ \"$file\" == \"$(echo $input_path/*.tsv | cut -d' ' -f1)\" ]; then\n",
    "        head -n 1 \"$file\"| sed 's/^chr/#chr/' > $output_file\n",
    "      fi\n",
    "\n",
    "      tail -n +2 \"$file\" >> $output_file\n",
    "    done\n",
    "    rm -rf $input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753185c2-0c82-4842-bd64-0c86152f2599",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## GWAS results consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0a4301-af94-4fbe-9766-9006ae8b3359",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gwas_results_export_1]\n",
    "# per chunk we process at most 200 datasets\n",
    "# Region list should have last column being region name. \n",
    "# Meta-data will be written to this column\n",
    "parameter:gwas_methods=['single_effect_regression', 'noqc', 'qc_impute', 'qc_only', 'conditional_regression_noqc', 'conditional_regression_qc_impute', 'conditional_regression_qc_only']\n",
    "parameter:coverages=[\"cs_coverage_0.95\", \"cs_coverage_0.7\", \"cs_coverage_0.5\"]\n",
    "parameter: rds_files = paths\n",
    "input: rds_files, group_by = 1\n",
    "output: f\"{cwd}/gwas_export/{_input:bn}.export.rds\"\n",
    "task: trunk_workers = job_size, walltime = walltime, trunk_size = 1, mem = mem, cores = numThreads, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\",stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "    library(dplyr)\n",
    "    \n",
    "    # Function to check if a dataframe has rows\n",
    "    has_rows <- function(df) {\n",
    "      !is.null(df) && nrow(df) > 0\n",
    "    }\n",
    "   \n",
    "    # function to filter the cs with all variants pip < 0.05, if a CS has anything > 0.05 we keep the entire CS with other variants in it\n",
    "    update_and_filter_cs_ids <- function(df) {\n",
    "      cs_columns <- grep(\"^cs_coverage\", names(df), value = TRUE)\n",
    "      df$cs_all_non_zero_orig <- ifelse(rowSums(df[cs_columns] == 0) == length(cs_columns), FALSE, TRUE)\n",
    "      for (cs_column in cs_columns) {\n",
    "        unique_cs_ids <- unique(df[[cs_column]])  \n",
    "        for (cs_id in unique_cs_ids) {\n",
    "          if (cs_id > 0) {\n",
    "            pip_check <- df[df[[cs_column]] == cs_id, \"pip\"] < 0.05\n",
    "            if (all(pip_check, na.rm = TRUE)) {\n",
    "              df[[cs_column]] <- ifelse(df[[cs_column]] == cs_id, 0, df[[cs_column]])\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      # Filter out rows where all cs_coverage columns are 0 and cs_all_non_zero_orig is TRUE\n",
    "      df <- df %>% filter(!(cs_all_non_zero_orig & rowSums(df[cs_columns] == 0) == length(cs_columns)))\n",
    "      # Remove the helper column\n",
    "      df <- select(df, -cs_all_non_zero_orig)\n",
    "      return(df)\n",
    "    }\n",
    "   \n",
    "     # Process coverage data\n",
    "    process_coverage <- function(dat, coverage) {\n",
    "      df <- data.frame(variants = character())\n",
    "        for (m in methods) {\n",
    "            if (has_rows(dat[[m]]$top_loci)) {\n",
    "                # process top loci first\n",
    "                top_loci_table <- update_and_filter_cs_ids(dat[[m]]$top_loci)\n",
    "                tmp <- data.frame(variant_id = top_loci_table$variant_id,\n",
    "                                  m_value = top_loci_table[[coverage]])\n",
    "                colnames(tmp) <- c(\"variants\", m)\n",
    "\n",
    "                # Filter rows where m_value > 0 to get the cs variants\n",
    "                tmp <- tmp %>% filter(.data[[m]] > 0)\n",
    "\n",
    "                if (nrow(df) == 0) {\n",
    "                    df <- tmp\n",
    "                } else {\n",
    "                    df <- merge(df, tmp, by = \"variants\", all = TRUE)\n",
    "                }\n",
    "            } else {\n",
    "                if (nrow(df) == 0) {\n",
    "                    # If df has no rows yet, create a placeholder to enable column assignment\n",
    "                    df <- data.frame(variants = NA)\n",
    "                }\n",
    "                df[[m]] <- 0  # Assign 0 to the entire column if there are no rows in dat[[m]]$top_loci\n",
    "            }\n",
    "        }\n",
    "      df <- df %>% filter(!(is.na(variants)))\n",
    "      # Replace NA values with 0\n",
    "      df[is.na(df)] <- 0\n",
    "      if(nrow(df) > 0) return(df) else return(NULL)\n",
    "    }\n",
    "\n",
    "    # Process pip data\n",
    "\n",
    "    process_pip <- function(dat) {\n",
    "      pip <- data.frame(variants = character())\n",
    "      for (m in methods) {\n",
    "        if (!is.null(dat[[m]]$susie_result_trimmed)) {\n",
    "          tmp <- data.frame(dat[[m]]$susie_result_trimmed$pip, dat[[m]]$variant_names)\n",
    "          colnames(tmp) <- c(m, \"variants\")\n",
    "          pip <- if (nrow(pip) > 0) merge(pip, tmp, by = \"variants\", all = TRUE) else tmp\n",
    "        } else {\n",
    "            if (nrow(pip) == 0) {\n",
    "                # If df has no rows yet, create a placeholder to enable column assignment\n",
    "                pip <- data.frame(variants = NA)\n",
    "            }\n",
    "            pip[[m]] <- 0  # Assign 0 to the entire column if there are no rows in dat[[m]]$top_loci\n",
    "        }\n",
    "      }\n",
    "      pip <- pip %>% filter(!(is.na(variants)))\n",
    "      return(pip)\n",
    "    }\n",
    "\n",
    "\n",
    "    process_others <- function(dat) {\n",
    "      top_locis_Others <- data.frame(variants = character())\n",
    "      for (m in methods) {\n",
    "        if (has_rows(dat[[m]]$top_loci)) {\n",
    "          # Dynamically generate filtering expression based on 'coverages'\n",
    "          coverage_conditions <- sapply(coverages, function(cov) paste0(cov, \" == 0\"))\n",
    "          condition_expr <- paste(coverage_conditions, collapse = \" & \")\n",
    "\n",
    "          # Use 'eval' and 'parse' to apply the dynamically generated filter condition\n",
    "          vars <- dat[[m]]$top_loci %>%\n",
    "            filter(eval(parse(text=condition_expr))) %>%\n",
    "            pull(variant_id)\n",
    "\n",
    "          if (length(vars) > 0) {\n",
    "            tmp <- data.frame(variants = vars)\n",
    "            tmp[[m]] <- 0 # Set coverage to 0 for these variants\n",
    "            # Merge with existing data, ensuring all variants are included\n",
    "            top_locis_Others <- if(nrow(top_locis_Others) == 0) tmp else merge(top_locis_Others, tmp, by = \"variants\", all = TRUE)\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      top_locis_Others[is.na(top_locis_Others)] <- 0\n",
    "      if(nrow(top_locis_Others) > 0) return(top_locis_Others) else return(NULL)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Function to extract numeric values from coverage strings\n",
    "    extract_coverage_value <- function(coverage_string) {\n",
    "      # Use gsub to remove all non-numeric characters, converting the result to numeric\n",
    "      as.numeric(gsub(\"[^0-9.]\", \"\", coverage_string))\n",
    "    }\n",
    "\n",
    "    # Processing\n",
    "    methods <- c(${\",\".join(['\"%s\"' % x for x in gwas_methods])})\n",
    "    coverages <-  c(${\",\".join(['\"%s\"' % x for x in coverages])})\n",
    "    ad <- readRDS(${_input:r})\n",
    "    datas <- names(ad)\n",
    "    res <- list()\n",
    "    report_top_loci <- c()\n",
    "\n",
    "    for (data_name in datas) {\n",
    "      dat <- ad[[data_name]]\n",
    "      coverage_results <- list()\n",
    "\n",
    "      for (coverage in coverages) {\n",
    "        cov <- extract_coverage_value(coverage)\n",
    "        table_name <- paste0(\"top_loci_\", cov*100)\n",
    "        coverage_results[[table_name]] <- process_coverage(dat, coverage)\n",
    "        report_top_loci <- c(report_top_loci, table_name)\n",
    "      }\n",
    "\n",
    "      pip <- process_pip(dat)\n",
    "      others <- process_others(dat) # Process \"CS Others\"\n",
    "      report_top_loci <- c(report_top_loci, \"top_loci_others\")\n",
    "      # Store all results, including special handling for PIP\n",
    "      res[[data_name]] <- c(coverage_results, list(pip = pip %>% select(-variants), variants = pip$variants, top_loci_others = others))\n",
    "    }\n",
    "    writeLines(report_top_loci %>% unique, paste0(${_output:adr}, \"/report_top_loci\"))  \n",
    "    saveRDS(res, ${_output:r})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a485f0-941b-4f17-95a7-f04da0e12d21",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#get union of step1\n",
    "#1200 blocks costed ~2mins with in one for loop\n",
    "[gwas_results_export_2]\n",
    "input: group_by = 'all'\n",
    "output: f\"{cwd}/{name}.union_export.tsv.gz\" \n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    library(plyr)\n",
    "    library(tidyverse)\n",
    "    library(data.table)\n",
    "\n",
    "    # Assuming extract_coverage_value is correctly defined elsewhere\n",
    "    extract_coverage_value <- function(coverage) {\n",
    "      as.numeric(gsub(\"cs_coverage_\", \"\", coverage))\n",
    "    }\n",
    "\n",
    "    files <- c(${\",\".join(['\"%s\"' % x.absolute() for x in _input])})\n",
    "    table_list <- readLines(paste0(${_input[0]:adr}, \"/report_top_loci\"))\n",
    "    combined_data <- data.frame()\n",
    "\n",
    "\n",
    "    for (file in files) {\n",
    "        res <- readRDS(file)\n",
    "        print(file)\n",
    "        for (name in names(res)) {\n",
    "            dat <- res[[name]]\n",
    "            top_loci_tmp <- data.frame()\n",
    "            pip_tmp <- dat$pip\n",
    "            if(nrow(pip_tmp) > 0){\n",
    "                colnames(pip_tmp) <- paste0('pip_', colnames(pip_tmp))\n",
    "                pip_tmp[[\"variants\"]] <- dat$variants\n",
    "                pip_tmp[[\"study\"]] <- name\n",
    "\n",
    "                for (i in seq_along(table_list)) {\n",
    "                    if (table_list[i] %in% names(dat)) {\n",
    "                        tmp <- dat[[table_list[i]]]\n",
    "                        if (!is.null(tmp)) {\n",
    "                            colnames(tmp)[2:ncol(tmp)] <- paste0(\"cs_\",colnames(tmp)[2:ncol(tmp)])\n",
    "                            tmp[[\"coverage\"]] <- table_list[i]\n",
    "                            top_loci_tmp <- rbind.fill(top_loci_tmp, tmp)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                # Merge top_loci_tmp with pip_tmp based on \"variants\"\n",
    "                if(nrow(top_loci_tmp) > 0 && nrow(pip_tmp)>0){\n",
    "                    tmp_merged <- merge(top_loci_tmp, pip_tmp, by = \"variants\", all.x = TRUE)\n",
    "                    tmp_merged[[\"block\"]] <- basename(file)%>%str_split(.,\"[.]\",simplify=T)%>%.[1]\n",
    "                    combined_data <- rbind.fill(combined_data, tmp_merged)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    fwrite(combined_data, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a563cfe-7cff-4536-b440-c34126e7a192",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overlap QTL and GWAS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860a8e7-60ba-4c06-b1fa-80075b463392",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[overlap_qtl_gwas_1]\n",
    "parameter: gwas_methods=['single_effect_regression', 'noqc', 'qc_impute', 'qc_only', 'conditional_regression_noqc', 'conditional_regression_qc_impute', 'conditional_regression_qc_only']\n",
    "parameter: gwas_coverage_values = [0.95, 0.7, 0.5, -1] # use '-1' means others here \n",
    "parameter: qtl_coverage_values = [0.95, 0.7, 0.5, -1]# use '-1' means others here \n",
    "parameter: per_chunk = 100\n",
    "parameter: qtl_files = paths\n",
    "parameter: gwas_union_file = path\n",
    "input: qtl_files, group_by = per_chunk\n",
    "output: f\"{cwd}/gwas_qtl/{name}_gwas_batch{_index+1}.tsv\" \n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    library(tidyverse)\n",
    "    library(plyr)\n",
    "    library(data.table)\n",
    "\n",
    "    # Function to change the coverage values to corresponding table name\n",
    "    process_cov_values <- function(raw_cov_values, data) {\n",
    "      # exclude 'others' first\n",
    "      cov_values <- raw_cov_values[raw_cov_values != -1 ] %>% as.numeric\n",
    "      if (data == 'gwas'){\n",
    "        if (any(cov_values < 1)) cov_values <- paste0('top_loci_', cov_values * 100) else cov_values <- paste0('top_loci_', cov_values)\n",
    "        # add others back\n",
    "      } else if (data == 'qtl') {\n",
    "        if (any(cov_values > 1)) cov_values <- paste0('cs_coverage_', round(cov_values / 100, 2)) else cov_values <- paste0('cs_coverage_', cov_values)\n",
    "      }\n",
    "      if ( -1 %in% raw_cov_values) {\n",
    "        cov_values <- c(cov_values, \"top_loci_others\")\n",
    "      }\n",
    "      return(cov_values)\n",
    "    }\n",
    "\n",
    "    # Function to add 'chr' in variants\n",
    "    add_chr_prefix <- function(var) {\n",
    "      if (any(grepl(\"chr\", var))) {\n",
    "        var <- var\n",
    "      } else {\n",
    "        var <- paste0(\"chr\", var)\n",
    "      }\n",
    "      return(var)\n",
    "    }\n",
    "\n",
    "    # Function to check if a dataframe has rows\n",
    "    has_rows <- function(df) {\n",
    "      !is.null(df) && nrow(df) > 0\n",
    "    }\n",
    "\n",
    "    # Function to filter QTL top loci table\n",
    "    filter_qtl_loci <- function(dat_top_loci, qtl_cov_values, cov_prefix = \"cs_\") {\n",
    "      # Identify columns that start with the specified prefix\n",
    "      cov_values <- colnames(dat_top_loci) %>% .[str_detect(., paste0(\"^\", cov_prefix))]\n",
    "\n",
    "      # Add temporary columns for row sums of qtl_cov_values and cov_values\n",
    "      dat_top_loci <- dat_top_loci %>%\n",
    "        mutate(rowSum_qtl = rowSums(select(., all_of(qtl_cov_values[qtl_cov_values!='top_loci_others'])), na.rm = TRUE),\n",
    "               rowSum_cov = rowSums(select(., all_of(cov_values)), na.rm = TRUE))\n",
    "\n",
    "      # Filter rows based on specified conditions\n",
    "      dat_top_loci_filtered <- dat_top_loci %>%\n",
    "        filter(\n",
    "          if ('top_loci_others' %in% qtl_cov_values & length(qtl_cov_values) == 1) {\n",
    "            # If qtl_cov_values contains only 'others', select rows where cov_values sum to 0\n",
    "            rowSum_cov == 0\n",
    "          } else if ('top_loci_others' %in% qtl_cov_values) {\n",
    "            # If 'others' is in qtl_cov_values, select rows where cov_values sum to 0 or qtl_cov_values sum > 0\n",
    "            rowSum_cov == 0 | rowSum_qtl > 0\n",
    "          } else {\n",
    "            # If 'others' is not in qtl_cov_values, select rows where qtl_cov_values sum > 0\n",
    "            rowSum_qtl > 0\n",
    "          }\n",
    "        ) %>%\n",
    "        select(-rowSum_qtl, -rowSum_cov) # Remove the temporary sum columns\n",
    "\n",
    "      return(dat_top_loci_filtered)\n",
    "    }\n",
    "\n",
    "    # Function to filter GWAS top loci table\n",
    "    filter_gwas_loci <- function(gwas, gwas_cov_values, gwas_methods) {\n",
    "      # Load the GWAS data from the given file path\n",
    "      gwas <- gwas %>%\n",
    "        # Initial filter based on coverage values specified\n",
    "        filter(coverage %in% gwas_cov_values) %>%\n",
    "        # Calculate the sum of the specified methods, ignoring NA\n",
    "        mutate(rowSum = rowSums(select(., all_of(gwas_methods)), na.rm = TRUE))\n",
    "\n",
    "      # Apply conditional filtering based on 'top_loci_others'\n",
    "      if ('top_loci_others' %in% gwas_cov_values) {\n",
    "        if (length(gwas_cov_values) == 1) {\n",
    "          # Only 'top_loci_others' is in gwas_cov_values\n",
    "          gwas <- gwas %>% filter(rowSum == 0 | coverage == 'top_loci_others')\n",
    "        } else {\n",
    "          # 'top_loci_others' and other values are in gwas_cov_values\n",
    "          gwas <- gwas %>% filter(rowSum > 0 | coverage == 'top_loci_others')\n",
    "        }\n",
    "      } else {\n",
    "        # 'top_loci_others' not in gwas_cov_values\n",
    "        gwas <- gwas %>% filter(rowSum > 0)\n",
    "      }\n",
    "\n",
    "      # Remove the temporary rowSum column before returning\n",
    "      gwas <- gwas %>% select(-rowSum)\n",
    "\n",
    "      return(gwas)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Process GWAS data\n",
    "    process_gwas_data <- function(gwas) {\n",
    "      gwas %>%\n",
    "        pivot_longer(cols = starts_with(\"cs_\"), names_to = \"method\", values_to = \"value\") %>%\n",
    "        mutate(method = str_remove(method, \"cs_\")) %>%\n",
    "        pivot_wider(names_from = coverage, values_from = value) %>%\n",
    "        split(.$study)\n",
    "    }\n",
    "\n",
    "    # Process each GWAS subset\n",
    "    process_gwas_subset <- function(df) {\n",
    "      cs_columns <-  names(df) %>% .[grep(\"^top_loci\",.)]\n",
    "      base_columns <- c(\"variants\", \"study\", \"block\", \"method\", cs_columns) ##FIXME: should be cleaner\n",
    "      methods <- unique(df$method)\n",
    "\n",
    "      lapply(methods, function(m) {\n",
    "        pip_columns <- grep(paste0(\"^pip_\", m), names(df), value = TRUE)\n",
    "        selected_columns <- c(base_columns, pip_columns)\n",
    "\n",
    "        df %>%\n",
    "          filter(method == m) %>%\n",
    "          select(all_of(selected_columns)) %>%\n",
    "          rename_with(~ ifelse(. %in% pip_columns, \"pip\", .), .cols = everything())\n",
    "      }) |>\n",
    "        setNames(methods)\n",
    "    }\n",
    "\n",
    "    # Combine all GWAS subsets\n",
    "    combine_gwas_data <- function(gwas_list) {\n",
    "      do.call(rbind, lapply(gwas_list, bind_rows)) %>%\n",
    "        dplyr::rename(variant_id = variants, region = block)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Process column names\n",
    "    process_column_names <- function(col_names) {\n",
    "      col_names %>% .[grep(\"^cs\",.)] %>%\n",
    "        map_chr(function(name) {\n",
    "          parts <- str_split(name, \"_\", simplify = TRUE)\n",
    "          if (ncol(parts) >= 2) {\n",
    "            # Assuming the last part is what we want after \"cs_\"\n",
    "            part <- parts[, ncol(parts)]\n",
    "            # Replace this line with the actual processing you intend, e.g., process_cov_values(part, data = 'gwas')\n",
    "            return(part)\n",
    "          } else {\n",
    "            # Fallback or error handling if the expected structure is not present\n",
    "            return(NA) # Or some other appropriate action\n",
    "          }\n",
    "        })\n",
    "    }\n",
    "\n",
    "    # Process a single QTL\n",
    "    # Adjusted process_single_qtl to reflect above changes\n",
    "    process_single_qtl <- function(qtl_study, study_name, region_name) {\n",
    "      top_loci_cols <- names(qtl_study)[grep(\"top_loci\", names(qtl_study))]\n",
    "\n",
    "      map_df(top_loci_cols, function(col_name) {\n",
    "        current_col <- qtl_study[[col_name]]\n",
    "\n",
    "        if(!is.null(current_col) && nrow(current_col) > 0){\n",
    "          new_colnames <- process_column_names(colnames(current_col))%>% process_cov_values(., data = 'gwas')\n",
    "          # Ensure colnames are correctly assigned back to current_col\n",
    "          colnames(current_col)[grep(\"^cs_\", colnames(current_col))] <- new_colnames\n",
    "\n",
    "          tmp_col <- current_col %>%\n",
    "            select(all_of(c(\"pip\", \"variant_id\", new_colnames))) %>%\n",
    "            mutate(\n",
    "              top_loci_others = ifelse(rowSums(select(., starts_with(\"top_loci\"))) == 0, 0, NA),\n",
    "              method = col_name,\n",
    "              study = study_name,\n",
    "              region = region_name\n",
    "            )\n",
    "\n",
    "          return(tmp_col)\n",
    "        } else {\n",
    "          return(tibble()) # Return an empty tibble if there's no data to avoid NULLs\n",
    "        }\n",
    "      }) %>%\n",
    "        bind_rows()\n",
    "    }\n",
    "\n",
    "    # Define functions for repetitive tasks\n",
    "    process_qtl_data <- function(qtl_path, gwas, gwas_cov_values, qtl_cov_values) {\n",
    "      qtl <- readRDS(qtl_path)\n",
    "\n",
    "      qtl_var <- unlist(lapply(qtl[[1]], function(gene_data) {\n",
    "        if (has_rows(gene_data$top_loci)) {\n",
    "          dat_top_loci <- filter_qtl_loci(gene_data$top_loci, qtl_cov_values = qtl_cov_values, cov_prefix = \"cs_\")\n",
    "          return(dat_top_loci$variant_id)\n",
    "        }\n",
    "        return(character(0))\n",
    "      }))\n",
    "\n",
    "      gwas$variants <- if(any(grepl(\"chr\", qtl_var))) add_chr_prefix(gwas$variants) else gsub(\"chr\", \"\", gwas$variants)\n",
    "\n",
    "      gwas_sub <- gwas %>% filter(variants %in% qtl_var) \n",
    "      gwas_list <- process_gwas_data(gwas_sub)\n",
    "\n",
    "      meta <- data.frame(gene = names(qtl), qtl_combine = basename(qtl_path), qtl_gwas_overlap = NA)\n",
    "\n",
    "      if (length(gwas_list) > 0 && any(sapply(gwas_list, nrow) > 0)) {\n",
    "        processed_gwas_list <- lapply(gwas_list, process_gwas_subset)\n",
    "        gwas_combined_df <- combine_gwas_data(processed_gwas_list)\n",
    "\n",
    "        qtl_df <- map2_df(qtl[[1]], names(qtl[[1]]), ~process_single_qtl(.x, .y, names(qtl)[1]))\n",
    "        # save rds\n",
    "        qtl[[1]] <- c(qtl[[1]], processed_gwas_list)\n",
    "        new_qtl_path <-  paste0(${_output:dr},\"/\",gsub(\".rds\",\".overlapped.gwas.rds\",basename(qtl_path)))\n",
    "        saveRDS(qtl, new_qtl_path)\n",
    "\n",
    "        all_df <- rbind.fill(gwas_combined_df, qtl_df)\n",
    "        cols_to_update <- grep(\"^top_loci(?!_others$)\", colnames(all_df), perl = TRUE)\n",
    "        all_df[, cols_to_update] <- lapply(all_df[, cols_to_update], function(x) ifelse(is.na(x), 0, x))\n",
    "        fwrite(all_df, gsub(\".rds\",\".csv\",new_qtl_path))\n",
    "\n",
    "        meta$qtl_gwas_overlap <- basename(new_qtl_path)\n",
    "      }\n",
    "      return(meta)\n",
    "    }\n",
    "\n",
    "    # Processing\n",
    "    # load gwas data\n",
    "    # load selection conditions \n",
    "    gwas_methods <- c(${\",\".join(['\"%s\"' % x  for x in gwas_methods])}) %>% paste0(\"cs_\", .)\n",
    "    gwas_cov_values <- c(${\",\".join([str(x)  for x in gwas_coverage_values])}) %>% process_cov_values(., data = 'gwas')\n",
    "    qtl_cov_values <- c(${\",\".join([str(x)  for x in qtl_coverage_values])}) %>% process_cov_values(., data = 'qtl')\n",
    "    \n",
    "    # subset the gwas processed top loci table  \n",
    "    gwas <- fread(${gwas_union_file:r}) %>% filter_gwas_loci(., gwas_cov_values, gwas_methods)\n",
    "  \n",
    "    # load qtl data\n",
    "    qtl_paths <-  c(${\",\".join(['\"%s\"' % x.absolute() for x in _input])})\n",
    "    \n",
    "    # main processing\n",
    "    results <- lapply(qtl_paths, process_qtl_data, gwas = gwas, gwas_cov_values = gwas_cov_values, qtl_cov_values = qtl_cov_values)\n",
    "\n",
    "    # Combine all meta data\n",
    "    meta_all <- bind_rows(results)\n",
    "\n",
    "    write_delim(meta_all, \"${_output}\", delim = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d6a0f-b09f-4b09-92ee-8fe8b9f1905e",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[overlap_qtl_gwas_2]\n",
    "input: group_by = 'all'\n",
    "output: f\"{cwd}/{name}.overlapped.gwas.tsv\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '16G', cores = 1, tags = f'{_output:bn}'\n",
    "bash: expand = \"{ }\", container = container, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', entrypoint=entrypoint\n",
    "    input_path=$(echo ${_input[0]:adr}| sed 's/^\\$//')\n",
    "    output_meta_file=$(echo ${_output:ar}|sed 's/^\\$//g')\n",
    "    output_export_file=$(echo \"$output_meta_file\" | sed 's/.tsv$/.export.csv/')\n",
    "\n",
    "     for file in $input_path/*.csv; do\n",
    "      if [ \"$file\" == \"$(echo $input_path/*.csv | cut -d' ' -f1)\" ]; then\n",
    "        head -n 1 \"$file\" > $output_export_file\n",
    "      fi\n",
    "\n",
    "      tail -n +2 \"$file\" >> $output_export_file\n",
    "    done\n",
    "\n",
    "    for file in $input_path/*.tsv; do\n",
    "      if [ \"$file\" == \"$(echo $input_path/*.tsv | cut -d' ' -f1)\" ]; then\n",
    "        head -n 1 \"$file\" > $output_meta_file\n",
    "      fi\n",
    "\n",
    "      tail -n +2 \"$file\" >> $output_meta_file\n",
    "    done\n",
    "\n",
    "    rm -rf $input_path/*.tsv\n",
    "    rm -rf $input_path/*.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
